{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from ML2_lib import models\n",
    "from ML2_lib import SGDByTorch\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from ML2_lib import format_data\n",
    "from ML2_lib import RV_SGD_Torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/3.8.6/envs/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "data_transform = transforms.ToTensor()\n",
    "\n",
    "# 学習データを読み込む DataLoader を作成する。\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=True, transform=data_transform, download=True\n",
    ")\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=True\n",
    ")\n",
    "\n",
    "# テストデータを読み込む DataLoader を作成する。\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=False, transform=data_transform, download=True\n",
    ")\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=1, shuffle=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/3.8.6/envs/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:62: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/Users/naoki/.pyenv/versions/3.8.6/envs/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/naoki/.pyenv/versions/3.8.6/envs/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/Users/naoki/.pyenv/versions/3.8.6/envs/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "model = models.FF_L1(w_num=784,c_num=10,unit_num=512)\n",
    "X_train, y_train, X_test, y_test = format_data.FashionMNIST_data().return_data()\n",
    "X_train, X_valid = train_test_split(X_train, test_size=0.1, shuffle=False)\n",
    "y_train, y_valid = train_test_split(y_train, test_size=0.1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML/GD/ML2_lib/SGDByTorch.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0\n",
      "[[   5    0    0    1    0    0    0    0   14  980]\n",
      " [   0    0    0    1    0    1    0    0    5  993]\n",
      " [   3    0    0    0    2    0    0    0    1  994]\n",
      " [   0    0    0    1    2    0    0    0    4  993]\n",
      " [   4    0    0    0    1    0    0    0    4  991]\n",
      " [  53    0    0    5   12    2    0    2   55  871]\n",
      " [   2    0    0    2    3    0    0    0   11  982]\n",
      " [  16    0    0    3    6    0    0    0   45  930]\n",
      " [   2    0    0    1    0    1    0    0    3  993]\n",
      " [   0    0    0    0    0    0    0    0    0 1000]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.01      0.01      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.07      0.00      0.00      1000\n",
      "           4       0.04      0.00      0.00      1000\n",
      "           5       0.50      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.02      0.00      0.01      1000\n",
      "           9       0.10      1.00      0.19      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.08      0.10      0.02     10000\n",
      "weighted avg       0.08      0.10      0.02     10000\n",
      "\n",
      "正解率 : 0.1012\n",
      "test loss : 2.30952787399292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/3.8.6/envs/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/3.8.6/envs/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/3.8.6/envs/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/ML/GD/ML2_lib/SGDByTorch.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 1000\n",
      "[[879  15  28  48   3   1   9   1  16   0]\n",
      " [ 17 930  14  29   8   0   0   0   2   0]\n",
      " [ 29   3 787  12 157   1   4   0   7   0]\n",
      " [ 95  39  19 815  22   0   4   0   6   0]\n",
      " [  2  21 525  86 355   0   4   0   7   0]\n",
      " [  1   0   1   3   0 685   0 187  13 110]\n",
      " [315   8 498  27 108   0  22   0  22   0]\n",
      " [  0   0   0   0   0 106   0 831   0  63]\n",
      " [  4   2  55   9   0  10   5  13 901   1]\n",
      " [  2   0   0   1   1  53   0  32   1 910]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.88      0.75      1000\n",
      "           1       0.91      0.93      0.92      1000\n",
      "           2       0.41      0.79      0.54      1000\n",
      "           3       0.79      0.81      0.80      1000\n",
      "           4       0.54      0.35      0.43      1000\n",
      "           5       0.80      0.69      0.74      1000\n",
      "           6       0.46      0.02      0.04      1000\n",
      "           7       0.78      0.83      0.81      1000\n",
      "           8       0.92      0.90      0.91      1000\n",
      "           9       0.84      0.91      0.87      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.68     10000\n",
      "weighted avg       0.71      0.71      0.68     10000\n",
      "\n",
      "正解率 : 0.7115\n",
      "test loss : 0.8233721852302551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML/GD/ML2_lib/SGDByTorch.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 2000\n",
      "[[654  10   8 132   5   2 150   0  39   0]\n",
      " [  0 912  12  59  10   0   5   0   2   0]\n",
      " [  4   2 535  16 288   1 117   0  37   0]\n",
      " [ 13  12   0 886  14   1  65   0   9   0]\n",
      " [  0   3 132  84 704   0  52   0  25   0]\n",
      " [  1   0   0   3   0 753   0 165  16  62]\n",
      " [ 96   2 117  99 297   0 321   0  68   0]\n",
      " [  0   0   0   0   0  24   0 916   0  60]\n",
      " [  1   2   8  11   2   3  11  10 951   1]\n",
      " [  0   0   0   2   0  10   0  91   2 895]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.65      0.74      1000\n",
      "           1       0.97      0.91      0.94      1000\n",
      "           2       0.66      0.54      0.59      1000\n",
      "           3       0.69      0.89      0.77      1000\n",
      "           4       0.53      0.70      0.61      1000\n",
      "           5       0.95      0.75      0.84      1000\n",
      "           6       0.45      0.32      0.37      1000\n",
      "           7       0.77      0.92      0.84      1000\n",
      "           8       0.83      0.95      0.89      1000\n",
      "           9       0.88      0.90      0.89      1000\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.76      0.75      0.75     10000\n",
      "weighted avg       0.76      0.75      0.75     10000\n",
      "\n",
      "正解率 : 0.7527\n",
      "test loss : 0.6934191584587097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML/GD/ML2_lib/SGDByTorch.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 3000\n",
      "[[781   4   4  45   0   1 144   0  20   1]\n",
      " [  3 917   6  40   1   0  31   0   2   0]\n",
      " [ 20   0 476   4   7   1 471   0  21   0]\n",
      " [ 46   9   0 758   0   1 180   0   5   1]\n",
      " [  0   3 149  26  15   0 798   0   9   0]\n",
      " [  1   0   0   2   0 800   0  61   9 127]\n",
      " [166   2  68  17   2   4 699   0  42   0]\n",
      " [  0   0   0   0   0  59   0 840   0 101]\n",
      " [  1   1   0   7   0   9  33   5 943   1]\n",
      " [  0   0   0   0   0   3   0  43   1 953]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      1000\n",
      "           1       0.98      0.92      0.95      1000\n",
      "           2       0.68      0.48      0.56      1000\n",
      "           3       0.84      0.76      0.80      1000\n",
      "           4       0.60      0.01      0.03      1000\n",
      "           5       0.91      0.80      0.85      1000\n",
      "           6       0.30      0.70      0.42      1000\n",
      "           7       0.89      0.84      0.86      1000\n",
      "           8       0.90      0.94      0.92      1000\n",
      "           9       0.80      0.95      0.87      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.77      0.72      0.70     10000\n",
      "weighted avg       0.77      0.72      0.70     10000\n",
      "\n",
      "正解率 : 0.7182\n",
      "test loss : 0.7130498886108398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML/GD/ML2_lib/SGDByTorch.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 4000\n",
      "[[721  21   9  59  14   4 141   0  31   0]\n",
      " [  0 944   3  33  17   0   1   0   2   0]\n",
      " [  7   3 463   7 361   2 125   0  32   0]\n",
      " [ 25  26   1 789  95   1  54   0   8   1]\n",
      " [  0   6  38  19 901   0  25   0  11   0]\n",
      " [  0   0   0   1   0 894   0  36  13  56]\n",
      " [130  11  68  26 392   2 319   0  52   0]\n",
      " [  0   0   0   0   0  86   0 738   5 171]\n",
      " [  0   1   0   7   7   4  16   2 961   2]\n",
      " [  0   0   0   0   0  26   0  14   1 959]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77      1000\n",
      "           1       0.93      0.94      0.94      1000\n",
      "           2       0.80      0.46      0.59      1000\n",
      "           3       0.84      0.79      0.81      1000\n",
      "           4       0.50      0.90      0.65      1000\n",
      "           5       0.88      0.89      0.89      1000\n",
      "           6       0.47      0.32      0.38      1000\n",
      "           7       0.93      0.74      0.82      1000\n",
      "           8       0.86      0.96      0.91      1000\n",
      "           9       0.81      0.96      0.88      1000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.78      0.77      0.76     10000\n",
      "weighted avg       0.78      0.77      0.76     10000\n",
      "\n",
      "正解率 : 0.7689\n",
      "test loss : 0.6526411771774292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML/GD/ML2_lib/SGDByTorch.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 5000\n",
      "[[585  34   8  32   1   5 302   0  33   0]\n",
      " [  0 955  11  24   4   0   4   0   2   0]\n",
      " [  2   6 637   6 158   2 158   0  31   0]\n",
      " [ 12  44   3 761  29   1 137   0  12   1]\n",
      " [  0   7 183  33 643   2 111   0  21   0]\n",
      " [  0   0   0   1   0 830   0  96   6  67]\n",
      " [ 61  14 124  15 111   3 612   0  60   0]\n",
      " [  0   0   0   0   0  27   0 887   0  86]\n",
      " [  0   1   5   3   2   7  13   5 963   1]\n",
      " [  0   0   0   0   0   8   0  47   1 944]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.58      0.70      1000\n",
      "           1       0.90      0.95      0.93      1000\n",
      "           2       0.66      0.64      0.65      1000\n",
      "           3       0.87      0.76      0.81      1000\n",
      "           4       0.68      0.64      0.66      1000\n",
      "           5       0.94      0.83      0.88      1000\n",
      "           6       0.46      0.61      0.52      1000\n",
      "           7       0.86      0.89      0.87      1000\n",
      "           8       0.85      0.96      0.90      1000\n",
      "           9       0.86      0.94      0.90      1000\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.80      0.78      0.78     10000\n",
      "weighted avg       0.80      0.78      0.78     10000\n",
      "\n",
      "正解率 : 0.7817\n",
      "test loss : 0.6072929501533508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML/GD/ML2_lib/SGDByTorch.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 6000\n",
      "[[911   3  18   9   5   1  16   0  36   1]\n",
      " [ 25 935  11  20   7   0   0   0   2   0]\n",
      " [ 26   1 664   4 236   1  19   0  49   0]\n",
      " [194  10  17 672  53   1  40   0  13   0]\n",
      " [  8   1  84  15 842   0  24   0  26   0]\n",
      " [  1   0   0   2   0 851   0  75  11  60]\n",
      " [316   2 172   9 228   0 192   0  81   0]\n",
      " [  0   0   0   0   0  29   0 927   0  44]\n",
      " [  5   1   4   2   4   3   4   4 972   1]\n",
      " [  0   0   0   0   0   4   0  69   2 925]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.91      0.73      1000\n",
      "           1       0.98      0.94      0.96      1000\n",
      "           2       0.68      0.66      0.67      1000\n",
      "           3       0.92      0.67      0.78      1000\n",
      "           4       0.61      0.84      0.71      1000\n",
      "           5       0.96      0.85      0.90      1000\n",
      "           6       0.65      0.19      0.30      1000\n",
      "           7       0.86      0.93      0.89      1000\n",
      "           8       0.82      0.97      0.89      1000\n",
      "           9       0.90      0.93      0.91      1000\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.80      0.79      0.77     10000\n",
      "weighted avg       0.80      0.79      0.77     10000\n",
      "\n",
      "正解率 : 0.7891\n",
      "test loss : 0.6059273481369019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML/GD/ML2_lib/SGDByTorch.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 7000\n",
      "[[594   4   9  39   4   1 331   0  17   1]\n",
      " [  0 938   9  26  10   0  15   0   2   0]\n",
      " [  3   1 476   3 296   1 208   0  12   0]\n",
      " [ 16   6   2 726  37   1 208   0   3   1]\n",
      " [  0   1  36  10 753   0 195   0   5   0]\n",
      " [  1   0   0   1   0 780   0  80   8 130]\n",
      " [ 63   2  70  21 125   1 688   0  30   0]\n",
      " [  0   0   0   0   0  17   0 869   0 114]\n",
      " [  0   1   5   3   3   2  35   5 945   1]\n",
      " [  0   0   0   0   0   1   0  35   1 963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.59      0.71      1000\n",
      "           1       0.98      0.94      0.96      1000\n",
      "           2       0.78      0.48      0.59      1000\n",
      "           3       0.88      0.73      0.79      1000\n",
      "           4       0.61      0.75      0.68      1000\n",
      "           5       0.97      0.78      0.86      1000\n",
      "           6       0.41      0.69      0.51      1000\n",
      "           7       0.88      0.87      0.87      1000\n",
      "           8       0.92      0.94      0.93      1000\n",
      "           9       0.80      0.96      0.87      1000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.81      0.77      0.78     10000\n",
      "weighted avg       0.81      0.77      0.78     10000\n",
      "\n",
      "正解率 : 0.7732\n",
      "test loss : 0.611962080001831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML/GD/ML2_lib/SGDByTorch.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-1b32cabc29a8>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mhoge\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSGDByTorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSGDTorch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mhoge\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlearn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mclass_num\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mY_test\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ML/GD/ML2_lib/SGDByTorch.py\u001B[0m in \u001B[0;36mlearn\u001B[0;34m(self, x, y, model, class_num, X_test, Y_test, early_stopping)\u001B[0m\n\u001B[1;32m     46\u001B[0m                 \u001B[0mY_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLongTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mY_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m                     \u001B[0my_test_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m                     \u001B[0mtestloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnll_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m                     \u001B[0mprediction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my_test_pred\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.8.6/envs/ML2/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ML/GD/ML2_lib/models.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     45\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfc1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfc2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.8.6/envs/ML2/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.8.6/envs/ML2/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 96\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     97\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.8.6/envs/ML2/lib/python3.8/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1845\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mhas_torch_function_variadic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1846\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1847\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1848\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1849\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "hoge = SGDByTorch.SGDTorch(lr=0.01)\n",
    "hoge.learn(x=X_train,y=y_train, model=model,class_num=10,X_test=X_test,Y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "60000"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}