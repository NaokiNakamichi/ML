{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ML2_lib import models\n",
    "from ML2_lib import SGDByTorch\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from ML2_lib import format_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "name_path = \"data/adult/adult_classification.names\"\n",
    "train_path = \"data/adult/adult_classification.csv\"\n",
    "test_path = \"data/adult/adult_classification.test\"\n",
    "hoge = format_data.Format(train_path=train_path,name_path=name_path,test_path=test_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = hoge.data_return()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "w_dim = X_train.shape[1]\n",
    "class_num = int(max(y_train) + 1)\n",
    "unit_num = 3\n",
    "model = models.FF_L1(w_num=w_dim,c_num=class_num,unit_num=unit_num)\n",
    "model.parameter_init()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "hoge = SGDByTorch.SGDTorchCheck(lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8078, -1.6792,  2.4937, -3.2598, -3.0604,  4.1096,  2.3836,  2.1304,\n",
      "          3.6929, -3.9543, -2.0841, -2.5153,  4.4997, -1.6595,  0.9357, -0.3736,\n",
      "          3.7437, -2.9544, -3.3773,  0.2689, -1.4086, -3.3300,  4.9459, -4.7989,\n",
      "          2.8488, -1.8427,  0.2930,  2.6649,  2.0100, -4.4815, -3.7244,  2.5313,\n",
      "          3.0074, -1.5526, -2.9805,  0.4755, -4.3595,  1.0036, -1.6910, -2.6179,\n",
      "         -0.4078,  4.8491, -0.4655, -1.4968, -0.2680,  0.7112, -2.2656, -1.0763,\n",
      "         -2.3708, -1.2081,  3.8591,  3.6657, -1.4626,  4.0611, -2.9869, -4.8180,\n",
      "         -0.7989,  4.7597,  0.4161,  3.4598, -2.4248, -1.2179, -1.8563,  2.6349,\n",
      "          2.4566, -0.6418, -3.8300,  3.2236,  4.4094, -1.0305,  4.3939,  2.5363,\n",
      "          2.7898, -2.9250, -3.2847, -1.9174,  3.1557,  2.6810,  0.6469,  1.4864,\n",
      "         -2.5366, -1.5552, -0.7450, -4.3142,  3.7220,  2.9184,  3.1247,  2.7051,\n",
      "         -4.0018, -1.2595,  2.8166,  2.6927, -3.4882,  4.6850,  0.5103,  2.2678,\n",
      "         -0.2523,  3.6585,  3.3893,  3.0505, -2.3886, -0.7287,  1.1712,  3.6796],\n",
      "        [ 4.2027,  3.9337, -0.5838,  3.9471,  0.9173,  2.4902,  0.7066, -2.8307,\n",
      "          3.1132,  0.4608, -3.0386,  4.3030,  2.5994,  1.0042,  3.1703,  3.8747,\n",
      "          0.2669, -2.3789, -2.9796, -3.3709,  2.8079, -3.5778, -4.4377,  4.4230,\n",
      "          1.1860, -4.4308, -4.7819, -2.5317, -1.4090,  3.5122,  1.3088,  4.7209,\n",
      "         -2.7817, -0.1783, -0.0306, -3.6857,  3.9928,  2.1571,  2.8379, -2.7662,\n",
      "         -3.6306, -0.4773, -3.4043, -4.5250, -0.4207, -4.0655,  4.5286, -2.5969,\n",
      "         -4.4652,  3.5117,  2.8990, -3.2052, -2.5824,  2.9318, -4.1269,  0.5799,\n",
      "          4.7504, -2.0766, -1.2382,  1.7088,  1.0247,  2.2485, -4.9876,  1.8395,\n",
      "          3.3684, -4.9486,  0.1192, -2.0609,  4.4272, -1.8702,  2.6472, -4.5532,\n",
      "          4.3002,  1.7044,  2.0987, -4.8266, -1.8528,  1.3447, -0.2412,  2.9675,\n",
      "         -1.9163,  3.2083,  3.7507,  2.5495, -2.1632, -2.2139,  1.7908, -0.8856,\n",
      "          0.8291, -0.8177,  1.1668, -0.4810,  0.1174,  4.7639,  1.4558,  3.9828,\n",
      "          2.2176,  0.5728,  3.4012,  0.2046, -0.1507,  4.8723, -4.8963,  2.9687],\n",
      "        [-4.5888,  2.7576,  1.6984,  4.4917,  2.5777, -1.7258, -2.5783, -3.9624,\n",
      "          2.3917, -4.8148,  3.9571, -4.5341,  4.3887, -0.0827,  1.6460, -3.0673,\n",
      "          1.2846,  2.0376, -4.0719,  3.1344, -2.3431,  4.4007, -1.6321,  4.0301,\n",
      "         -4.3147, -1.7726,  4.2470,  3.2918,  1.1104, -0.4133, -2.7109,  2.9746,\n",
      "         -1.7995,  3.7475, -4.8267,  0.0501,  4.2889, -3.2178,  0.6878,  2.3700,\n",
      "          1.7712, -3.7604,  4.0218, -3.7456, -2.1137,  0.6955,  2.3473, -1.8586,\n",
      "         -2.0154,  0.4199,  3.2727,  3.7012, -1.1120, -4.0737,  0.1876,  3.5353,\n",
      "          0.3695,  3.4707, -1.0520, -1.7934,  3.0088, -4.2631,  2.0673,  1.8574,\n",
      "         -0.3942, -3.6362,  2.6381,  1.1929, -4.7084, -2.8375, -2.1087,  3.1270,\n",
      "         -0.0340,  3.0273, -4.4232,  2.7632, -4.7943, -3.2696, -0.0454,  2.6107,\n",
      "          4.6727, -0.7085, -4.6525,  1.8097,  3.1315, -1.0454, -2.6624,  3.8328,\n",
      "         -3.3889, -0.5583,  0.0325,  2.8571,  4.2406,  1.0035,  3.7559,  0.4239,\n",
      "         -0.6239,  0.4242, -0.7870,  2.2848,  3.6746,  1.6337,  3.9526,  1.1533]])), ('fc1.bias', tensor([ 0.0000e+00, -1.0052e-13, -1.4457e-13])), ('fc2.weight', tensor([[-4.5398,  0.7303,  3.4987],\n",
      "        [-2.0027,  1.0159,  1.4612]])), ('fc2.bias', tensor([ 0.0000e+00, -9.8940e-14]))])\n",
      "[[6663 4697]\n",
      " [2581 1119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.59      0.65     11360\n",
      "           1       0.19      0.30      0.24      3700\n",
      "\n",
      "    accuracy                           0.52     15060\n",
      "   macro avg       0.46      0.44      0.44     15060\n",
      "weighted avg       0.59      0.52      0.55     15060\n",
      "\n",
      "正解率 : 0.5167330677290837\n",
      "test loss : 5.353183269500732\n",
      "step : 1000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8189, -1.7003,  2.4271, -3.2563, -3.0539,  4.0643,  2.3847,  2.1115,\n",
      "          3.5412, -3.9486, -2.0748, -2.5156,  4.4997, -1.6583,  0.9139, -0.3767,\n",
      "          3.7415, -2.9551, -3.3796,  0.2618, -1.4038, -3.3181,  4.9161, -4.7935,\n",
      "          2.7217, -1.8221,  0.2929,  2.6808,  1.9894, -4.4939, -3.7244,  2.5852,\n",
      "          2.9924, -1.7124, -2.9917,  0.4652, -4.3512,  1.0020, -1.6959, -2.5678,\n",
      "         -0.4123,  4.7875, -0.4775, -1.5626, -0.2702,  0.7062, -2.2630, -1.1142,\n",
      "         -2.3733, -1.2258,  3.9030,  3.5963, -1.4642,  3.9454, -3.0070, -4.8100,\n",
      "         -0.8034,  4.7544,  0.3374,  3.4541, -2.4853, -1.3313, -1.8976,  2.6350,\n",
      "          2.4590, -0.6418, -3.8300,  3.2177,  4.4077, -1.0305,  4.3920,  2.5343,\n",
      "          2.7898, -2.9276, -3.2847, -1.9181,  3.1528,  2.6810,  0.6493,  1.4864,\n",
      "         -2.5366, -1.5557, -0.7466, -4.3142,  3.7220,  2.9148,  3.1243,  2.7051,\n",
      "         -4.0066, -1.2595,  2.8166,  2.6927, -3.4882,  4.6804,  0.5115,  2.2649,\n",
      "         -0.2523,  3.6577,  3.3888,  3.0508, -2.3886, -0.8517,  1.1712,  3.6790],\n",
      "        [ 4.2015,  3.9335, -0.5849,  3.9469,  0.9170,  2.4890,  0.7061, -2.8305,\n",
      "          3.1126,  0.4601, -3.0383,  4.3025,  2.5994,  1.0041,  3.1696,  3.8751,\n",
      "          0.2669, -2.3789, -2.9797, -3.3710,  2.8076, -3.5778, -4.4379,  4.4229,\n",
      "          1.1857, -4.4308, -4.7819, -2.5321, -1.4090,  3.5120,  1.3088,  4.7158,\n",
      "         -2.7818, -0.1751, -0.0309, -3.6852,  3.9919,  2.1570,  2.8368, -2.7674,\n",
      "         -3.6305, -0.4771, -3.4038, -4.5239, -0.4205, -4.0647,  4.5288, -2.5968,\n",
      "         -4.4659,  3.5109,  2.8950, -3.2029, -2.5824,  2.9334, -4.1276,  0.5788,\n",
      "          4.7504, -2.0764, -1.2378,  1.7089,  1.0223,  2.2501, -4.9911,  1.8395,\n",
      "          3.3685, -4.9486,  0.1192, -2.0611,  4.4272, -1.8702,  2.6472, -4.5532,\n",
      "          4.3002,  1.7044,  2.0987, -4.8266, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9163,  3.2083,  3.7507,  2.5495, -2.1631, -2.2137,  1.7909, -0.8856,\n",
      "          0.8291, -0.8177,  1.1668, -0.4810,  0.1174,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5730,  3.4012,  0.2046, -0.1507,  4.8698, -4.8963,  2.9688],\n",
      "        [-4.6142,  2.7588,  1.6767,  4.4880,  2.5700, -1.7366, -2.5867, -3.9578,\n",
      "          2.4280, -4.8284,  3.9438, -4.5398,  4.3887, -0.0834,  1.6606, -3.0668,\n",
      "          1.2850,  2.0382, -4.0747,  3.1379, -2.3505,  4.3888, -1.6222,  4.0161,\n",
      "         -4.2726, -1.7953,  4.2471,  3.2798,  1.1101, -0.4182, -2.7109,  2.8976,\n",
      "         -1.7960,  3.8246, -4.8258,  0.0503,  4.2764, -3.2178,  0.6830,  2.3204,\n",
      "          1.7741, -3.7224,  4.0213, -3.7196, -2.1133,  0.6780,  2.3438, -1.8450,\n",
      "         -2.0156,  0.4274,  3.2182,  3.7257, -1.1140, -4.0195,  0.1857,  3.5149,\n",
      "          0.3719,  3.4746, -1.0231, -1.7913,  2.9714, -4.2464,  2.0505,  1.8573,\n",
      "         -0.3960, -3.6362,  2.6381,  1.1974, -4.7072, -2.8375, -2.1074,  3.1287,\n",
      "         -0.0340,  3.0291, -4.4232,  2.7636, -4.7937, -3.2696, -0.0474,  2.6107,\n",
      "          4.6727, -0.7085, -4.6527,  1.8097,  3.1316, -1.0448, -2.6623,  3.8328,\n",
      "         -3.3893, -0.5583,  0.0325,  2.8571,  4.2402,  1.0068,  3.7554,  0.4259,\n",
      "         -0.6239,  0.4245, -0.7868,  2.2846,  3.6746,  1.6209,  3.9526,  1.1536]])), ('fc1.bias', tensor([-1.5472e-01, -1.7926e-03, -1.1446e-04])), ('fc2.weight', tensor([[-3.5034,  0.8854,  2.5717],\n",
      "        [-3.0392,  0.8608,  2.3882]])), ('fc2.bias', tensor([ 0.0820, -0.0820]))])\n",
      "[[7382 3978]\n",
      " [2134 1566]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71     11360\n",
      "           1       0.28      0.42      0.34      3700\n",
      "\n",
      "    accuracy                           0.59     15060\n",
      "   macro avg       0.53      0.54      0.52     15060\n",
      "weighted avg       0.65      0.59      0.62     15060\n",
      "\n",
      "正解率 : 0.5941567065073041\n",
      "test loss : 0.9539287090301514\n",
      "step : 2000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8192, -1.7013,  2.4239, -3.2559, -3.0537,  4.0624,  2.3845,  2.1107,\n",
      "          3.5348, -3.9481, -2.0745, -2.5153,  4.4997, -1.6585,  0.9134, -0.3767,\n",
      "          3.7415, -2.9551, -3.3796,  0.2618, -1.4035, -3.3181,  4.9157, -4.7935,\n",
      "          2.7172, -1.8216,  0.2929,  2.6809,  1.9879, -4.4949, -3.7244,  2.5882,\n",
      "          2.9918, -1.7192, -2.9919,  0.4644, -4.3512,  1.0019, -1.6964, -2.5673,\n",
      "         -0.4124,  4.7855, -0.4781, -1.5653, -0.2702,  0.7056, -2.2632, -1.1142,\n",
      "         -2.3736, -1.2257,  3.9053,  3.5918, -1.4644,  3.9409, -3.0071, -4.8093,\n",
      "         -0.8032,  4.7525,  0.3343,  3.4540, -2.4869, -1.3351, -1.9003,  2.6350,\n",
      "          2.4591, -0.6423, -3.8300,  3.2176,  4.4075, -1.0305,  4.3920,  2.5343,\n",
      "          2.7898, -2.9276, -3.2847, -1.9181,  3.1528,  2.6810,  0.6493,  1.4864,\n",
      "         -2.5366, -1.5560, -0.7466, -4.3142,  3.7220,  2.9150,  3.1238,  2.7051,\n",
      "         -4.0069, -1.2595,  2.8166,  2.6927, -3.4882,  4.6803,  0.5115,  2.2649,\n",
      "         -0.2523,  3.6577,  3.3888,  3.0508, -2.3886, -0.8564,  1.1712,  3.6790],\n",
      "        [ 4.2005,  3.9336, -0.5860,  3.9463,  0.9167,  2.4885,  0.7061, -2.8307,\n",
      "          3.1139,  0.4591, -3.0387,  4.3026,  2.5994,  1.0043,  3.1700,  3.8752,\n",
      "          0.2669, -2.3789, -2.9795, -3.3709,  2.8070, -3.5780, -4.4388,  4.4228,\n",
      "          1.1868, -4.4317, -4.7819, -2.5323, -1.4085,  3.5131,  1.3088,  4.7102,\n",
      "         -2.7817, -0.1715, -0.0306, -3.6847,  3.9921,  2.1570,  2.8367, -2.7690,\n",
      "         -3.6305, -0.4766, -3.4035, -4.5225, -0.4204, -4.0656,  4.5289, -2.5971,\n",
      "         -4.4659,  3.5108,  2.8908, -3.2004, -2.5822,  2.9353, -4.1267,  0.5775,\n",
      "          4.7504, -2.0764, -1.2370,  1.7089,  1.0214,  2.2522, -4.9933,  1.8395,\n",
      "          3.3685, -4.9486,  0.1192, -2.0611,  4.4273, -1.8702,  2.6472, -4.5532,\n",
      "          4.3002,  1.7045,  2.0987, -4.8266, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9163,  3.2083,  3.7507,  2.5495, -2.1632, -2.2138,  1.7910, -0.8856,\n",
      "          0.8293, -0.8177,  1.1668, -0.4810,  0.1174,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5730,  3.4012,  0.2047, -0.1507,  4.8693, -4.8963,  2.9688],\n",
      "        [-4.6156,  2.7588,  1.6754,  4.4875,  2.5698, -1.7376, -2.5868, -3.9576,\n",
      "          2.4288, -4.8295,  3.9431, -4.5397,  4.3887, -0.0833,  1.6608, -3.0668,\n",
      "          1.2850,  2.0383, -4.0746,  3.1379, -2.3512,  4.3886, -1.6222,  4.0160,\n",
      "         -4.2722, -1.7963,  4.2471,  3.2797,  1.1102, -0.4176, -2.7109,  2.8925,\n",
      "         -1.7958,  3.8276, -4.8258,  0.0505,  4.2765, -3.2178,  0.6827,  2.3186,\n",
      "          1.7741, -3.7218,  4.0214, -3.7186, -2.1133,  0.6775,  2.3440, -1.8455,\n",
      "         -2.0154,  0.4272,  3.2143,  3.7275, -1.1140, -4.0179,  0.1862,  3.5137,\n",
      "          0.3719,  3.4752, -1.0224, -1.7912,  2.9689, -4.2458,  2.0488,  1.8573,\n",
      "         -0.3961, -3.6360,  2.6381,  1.1974, -4.7072, -2.8375, -2.1074,  3.1287,\n",
      "         -0.0340,  3.0291, -4.4232,  2.7636, -4.7937, -3.2696, -0.0474,  2.6107,\n",
      "          4.6727, -0.7084, -4.6528,  1.8097,  3.1316, -1.0450, -2.6622,  3.8328,\n",
      "         -3.3892, -0.5583,  0.0325,  2.8572,  4.2402,  1.0069,  3.7554,  0.4259,\n",
      "         -0.6239,  0.4245, -0.7868,  2.2846,  3.6746,  1.6195,  3.9526,  1.1536]])), ('fc1.bias', tensor([-0.1612, -0.0019, -0.0013])), ('fc2.weight', tensor([[-3.2702,  0.9278,  2.4689],\n",
      "        [-3.2724,  0.8184,  2.4910]])), ('fc2.bias', tensor([ 0.1514, -0.1514]))])\n",
      "[[10875   485]\n",
      " [ 3590   110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84     11360\n",
      "           1       0.18      0.03      0.05      3700\n",
      "\n",
      "    accuracy                           0.73     15060\n",
      "   macro avg       0.47      0.49      0.45     15060\n",
      "weighted avg       0.61      0.73      0.65     15060\n",
      "\n",
      "正解率 : 0.7294156706507304\n",
      "test loss : 0.6074063777923584\n",
      "step : 3000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8189, -1.7014,  2.4236, -3.2558, -3.0536,  4.0621,  2.3845,  2.1105,\n",
      "          3.5334, -3.9478, -2.0745, -2.5154,  4.4997, -1.6586,  0.9133, -0.3767,\n",
      "          3.7414, -2.9551, -3.3796,  0.2616, -1.4035, -3.3181,  4.9160, -4.7935,\n",
      "          2.7163, -1.8213,  0.2929,  2.6812,  1.9872, -4.4951, -3.7244,  2.5900,\n",
      "          2.9916, -1.7217, -2.9920,  0.4643, -4.3516,  1.0019, -1.6964, -2.5664,\n",
      "         -0.4126,  4.7849, -0.4784, -1.5659, -0.2702,  0.7057, -2.2633, -1.1142,\n",
      "         -2.3736, -1.2256,  3.9069,  3.5904, -1.4646,  3.9396, -3.0073, -4.8092,\n",
      "         -0.8033,  4.7523,  0.3339,  3.4539, -2.4873, -1.3360, -1.9006,  2.6350,\n",
      "          2.4591, -0.6423, -3.8300,  3.2175,  4.4074, -1.0305,  4.3919,  2.5342,\n",
      "          2.7898, -2.9276, -3.2847, -1.9182,  3.1528,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5366, -1.5560, -0.7465, -4.3142,  3.7220,  2.9150,  3.1238,  2.7051,\n",
      "         -4.0069, -1.2595,  2.8166,  2.6927, -3.4882,  4.6803,  0.5115,  2.2649,\n",
      "         -0.2523,  3.6577,  3.3888,  3.0508, -2.3886, -0.8572,  1.1711,  3.6790],\n",
      "        [ 4.1993,  3.9336, -0.5873,  3.9459,  0.9164,  2.4879,  0.7058, -2.8305,\n",
      "          3.1148,  0.4584, -3.0386,  4.3025,  2.5994,  1.0046,  3.1703,  3.8754,\n",
      "          0.2669, -2.3788, -2.9791, -3.3707,  2.8066, -3.5781, -4.4402,  4.4225,\n",
      "          1.1879, -4.4324, -4.7819, -2.5329, -1.4074,  3.5146,  1.3088,  4.7040,\n",
      "         -2.7816, -0.1678, -0.0301, -3.6842,  3.9931,  2.1570,  2.8369, -2.7707,\n",
      "         -3.6299, -0.4759, -3.4031, -4.5213, -0.4204, -4.0669,  4.5288, -2.5975,\n",
      "         -4.4660,  3.5105,  2.8854, -3.1985, -2.5816,  2.9374, -4.1250,  0.5767,\n",
      "          4.7505, -2.0763, -1.2361,  1.7090,  1.0202,  2.2548, -4.9958,  1.8395,\n",
      "          3.3684, -4.9486,  0.1192, -2.0611,  4.4273, -1.8702,  2.6472, -4.5532,\n",
      "          4.3002,  1.7044,  2.0986, -4.8266, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9163,  3.2083,  3.7507,  2.5495, -2.1632, -2.2138,  1.7910, -0.8856,\n",
      "          0.8293, -0.8177,  1.1668, -0.4810,  0.1173,  4.7642,  1.4557,  3.9829,\n",
      "          2.2176,  0.5730,  3.4011,  0.2047, -0.1507,  4.8692, -4.8963,  2.9688],\n",
      "        [-4.6163,  2.7585,  1.6739,  4.4874,  2.5697, -1.7387, -2.5869, -3.9576,\n",
      "          2.4269, -4.8296,  3.9428, -4.5400,  4.3887, -0.0833,  1.6608, -3.0668,\n",
      "          1.2849,  2.0382, -4.0747,  3.1379, -2.3512,  4.3885, -1.6226,  4.0160,\n",
      "         -4.2729, -1.7966,  4.2471,  3.2796,  1.1097, -0.4177, -2.7109,  2.8911,\n",
      "         -1.7958,  3.8269, -4.8258,  0.0504,  4.2763, -3.2178,  0.6824,  2.3184,\n",
      "          1.7739, -3.7220,  4.0210, -3.7187, -2.1133,  0.6769,  2.3440, -1.8454,\n",
      "         -2.0155,  0.4270,  3.2129,  3.7269, -1.1141, -4.0179,  0.1860,  3.5137,\n",
      "          0.3719,  3.4750, -1.0225, -1.7912,  2.9668, -4.2461,  2.0468,  1.8573,\n",
      "         -0.3961, -3.6360,  2.6381,  1.1974, -4.7072, -2.8375, -2.1074,  3.1287,\n",
      "         -0.0340,  3.0291, -4.4233,  2.7636, -4.7937, -3.2696, -0.0474,  2.6108,\n",
      "          4.6727, -0.7084, -4.6528,  1.8096,  3.1316, -1.0450, -2.6622,  3.8328,\n",
      "         -3.3893, -0.5583,  0.0325,  2.8572,  4.2402,  1.0068,  3.7554,  0.4259,\n",
      "         -0.6239,  0.4245, -0.7869,  2.2846,  3.6746,  1.6175,  3.9526,  1.1536]])), ('fc1.bias', tensor([-0.1624, -0.0019, -0.0036])), ('fc2.weight', tensor([[-3.2941,  0.8936,  2.4472],\n",
      "        [-3.2485,  0.8527,  2.5127]])), ('fc2.bias', tensor([ 0.2195, -0.2195]))])\n",
      "[[6603 4757]\n",
      " [1446 2254]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.58      0.68     11360\n",
      "           1       0.32      0.61      0.42      3700\n",
      "\n",
      "    accuracy                           0.59     15060\n",
      "   macro avg       0.57      0.60      0.55     15060\n",
      "weighted avg       0.70      0.59      0.62     15060\n",
      "\n",
      "正解率 : 0.5881142098273573\n",
      "test loss : 0.6673538684844971\n",
      "step : 4000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8190, -1.7016,  2.4231, -3.2557, -3.0536,  4.0617,  2.3845,  2.1105,\n",
      "          3.5322, -3.9478, -2.0744, -2.5154,  4.4997, -1.6586,  0.9131, -0.3767,\n",
      "          3.7414, -2.9551, -3.3797,  0.2615, -1.4034, -3.3181,  4.9161, -4.7934,\n",
      "          2.7161, -1.8214,  0.2929,  2.6812,  1.9865, -4.4953, -3.7244,  2.5900,\n",
      "          2.9916, -1.7227, -2.9921,  0.4643, -4.3517,  1.0019, -1.6964, -2.5662,\n",
      "         -0.4127,  4.7846, -0.4786, -1.5661, -0.2702,  0.7057, -2.2633, -1.1145,\n",
      "         -2.3737, -1.2258,  3.9069,  3.5897, -1.4646,  3.9391, -3.0073, -4.8091,\n",
      "         -0.8033,  4.7523,  0.3336,  3.4538, -2.4881, -1.3364, -1.9014,  2.6350,\n",
      "          2.4591, -0.6423, -3.8300,  3.2175,  4.4074, -1.0305,  4.3919,  2.5342,\n",
      "          2.7898, -2.9276, -3.2847, -1.9182,  3.1528,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5366, -1.5560, -0.7465, -4.3142,  3.7220,  2.9150,  3.1238,  2.7051,\n",
      "         -4.0069, -1.2595,  2.8166,  2.6927, -3.4882,  4.6803,  0.5115,  2.2649,\n",
      "         -0.2523,  3.6577,  3.3888,  3.0508, -2.3886, -0.8582,  1.1711,  3.6790],\n",
      "        [ 4.1986,  3.9336, -0.5881,  3.9457,  0.9162,  2.4873,  0.7057, -2.8304,\n",
      "          3.1148,  0.4583, -3.0385,  4.3022,  2.5994,  1.0047,  3.1706,  3.8755,\n",
      "          0.2669, -2.3787, -2.9790, -3.3706,  2.8063, -3.5780, -4.4412,  4.4223,\n",
      "          1.1882, -4.4328, -4.7819, -2.5332, -1.4066,  3.5154,  1.3088,  4.6998,\n",
      "         -2.7816, -0.1651, -0.0299, -3.6840,  3.9938,  2.1570,  2.8362, -2.7719,\n",
      "         -3.6296, -0.4758, -3.4027, -4.5204, -0.4203, -4.0678,  4.5288, -2.5972,\n",
      "         -4.4663,  3.5106,  2.8817, -3.1970, -2.5815,  2.9390, -4.1244,  0.5763,\n",
      "          4.7504, -2.0763, -1.2356,  1.7091,  1.0194,  2.2568, -4.9981,  1.8395,\n",
      "          3.3684, -4.9486,  0.1192, -2.0610,  4.4273, -1.8702,  2.6472, -4.5531,\n",
      "          4.3002,  1.7044,  2.0986, -4.8266, -1.8526,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9163,  3.2083,  3.7506,  2.5495, -2.1632, -2.2137,  1.7910, -0.8856,\n",
      "          0.8294, -0.8177,  1.1668, -0.4810,  0.1173,  4.7641,  1.4557,  3.9829,\n",
      "          2.2176,  0.5730,  3.4011,  0.2047, -0.1507,  4.8686, -4.8962,  2.9688],\n",
      "        [-4.6170,  2.7583,  1.6728,  4.4873,  2.5696, -1.7395, -2.5869, -3.9576,\n",
      "          2.4255, -4.8296,  3.9426, -4.5401,  4.3887, -0.0835,  1.6607, -3.0668,\n",
      "          1.2849,  2.0381, -4.0747,  3.1378, -2.3513,  4.3885, -1.6228,  4.0161,\n",
      "         -4.2732, -1.7968,  4.2471,  3.2795,  1.1092, -0.4177, -2.7109,  2.8892,\n",
      "         -1.7958,  3.8270, -4.8259,  0.0505,  4.2762, -3.2178,  0.6819,  2.3177,\n",
      "          1.7739, -3.7220,  4.0210, -3.7186, -2.1133,  0.6766,  2.3441, -1.8453,\n",
      "         -2.0158,  0.4269,  3.2111,  3.7268, -1.1141, -4.0178,  0.1860,  3.5136,\n",
      "          0.3719,  3.4750, -1.0225, -1.7912,  2.9650, -4.2461,  2.0449,  1.8573,\n",
      "         -0.3961, -3.6360,  2.6381,  1.1974, -4.7072, -2.8374, -2.1074,  3.1286,\n",
      "         -0.0340,  3.0291, -4.4233,  2.7635, -4.7937, -3.2696, -0.0474,  2.6108,\n",
      "          4.6727, -0.7084, -4.6527,  1.8097,  3.1316, -1.0451, -2.6622,  3.8328,\n",
      "         -3.3893, -0.5583,  0.0325,  2.8572,  4.2402,  1.0068,  3.7554,  0.4259,\n",
      "         -0.6239,  0.4245, -0.7869,  2.2846,  3.6746,  1.6157,  3.9526,  1.1536]])), ('fc1.bias', tensor([-0.1636, -0.0022, -0.0055])), ('fc2.weight', tensor([[-3.2786,  0.9135,  2.4664],\n",
      "        [-3.2639,  0.8327,  2.4935]])), ('fc2.bias', tensor([ 0.2869, -0.2869]))])\n",
      "[[11260   100]\n",
      " [ 3670    30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.86     11360\n",
      "           1       0.23      0.01      0.02      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.49      0.50      0.44     15060\n",
      "weighted avg       0.63      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.749667994687915\n",
      "test loss : 0.579686164855957\n",
      "step : 5000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8194, -1.7017,  2.4225, -3.2558, -3.0536,  4.0614,  2.3846,  2.1103,\n",
      "          3.5319, -3.9479, -2.0745, -2.5154,  4.4997, -1.6587,  0.9131, -0.3767,\n",
      "          3.7415, -2.9551, -3.3796,  0.2616, -1.4034, -3.3180,  4.9158, -4.7934,\n",
      "          2.7159, -1.8214,  0.2929,  2.6810,  1.9864, -4.4952, -3.7244,  2.5886,\n",
      "          2.9917, -1.7221, -2.9921,  0.4644, -4.3517,  1.0019, -1.6965, -2.5665,\n",
      "         -0.4128,  4.7845, -0.4786, -1.5659, -0.2702,  0.7051, -2.2632, -1.1144,\n",
      "         -2.3737, -1.2258,  3.9056,  3.5901, -1.4646,  3.9393, -3.0072, -4.8092,\n",
      "         -0.8033,  4.7524,  0.3336,  3.4538, -2.4888, -1.3363, -1.9022,  2.6350,\n",
      "          2.4592, -0.6423, -3.8300,  3.2175,  4.4074, -1.0305,  4.3919,  2.5342,\n",
      "          2.7898, -2.9276, -3.2847, -1.9182,  3.1528,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5366, -1.5560, -0.7465, -4.3142,  3.7220,  2.9151,  3.1238,  2.7051,\n",
      "         -4.0070, -1.2595,  2.8166,  2.6927, -3.4882,  4.6803,  0.5115,  2.2649,\n",
      "         -0.2523,  3.6577,  3.3888,  3.0508, -2.3886, -0.8591,  1.1711,  3.6790],\n",
      "        [ 4.1974,  3.9335, -0.5892,  3.9453,  0.9158,  2.4865,  0.7057, -2.8306,\n",
      "          3.1147,  0.4576, -3.0384,  4.3024,  2.5994,  1.0047,  3.1708,  3.8756,\n",
      "          0.2670, -2.3787, -2.9790, -3.3707,  2.8065, -3.5779, -4.4419,  4.4220,\n",
      "          1.1888, -4.4335, -4.7819, -2.5334, -1.4067,  3.5158,  1.3088,  4.6959,\n",
      "         -2.7816, -0.1626, -0.0297, -3.6839,  3.9942,  2.1570,  2.8362, -2.7728,\n",
      "         -3.6294, -0.4756, -3.4024, -4.5196, -0.4203, -4.0691,  4.5286, -2.5974,\n",
      "         -4.4663,  3.5105,  2.8784, -3.1960, -2.5812,  2.9404, -4.1239,  0.5755,\n",
      "          4.7504, -2.0761, -1.2356,  1.7092,  1.0184,  2.2577, -4.9998,  1.8395,\n",
      "          3.3684, -4.9486,  0.1192, -2.0610,  4.4273, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7044,  2.0986, -4.8266, -1.8526,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9163,  3.2083,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8856,\n",
      "          0.8296, -0.8177,  1.1668, -0.4810,  0.1173,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5731,  3.4011,  0.2047, -0.1507,  4.8675, -4.8962,  2.9688],\n",
      "        [-4.6175,  2.7580,  1.6713,  4.4875,  2.5696, -1.7405, -2.5868, -3.9576,\n",
      "          2.4230, -4.8294,  3.9422, -4.5401,  4.3887, -0.0835,  1.6606, -3.0668,\n",
      "          1.2849,  2.0381, -4.0748,  3.1378, -2.3514,  4.3882, -1.6232,  4.0161,\n",
      "         -4.2740, -1.7968,  4.2471,  3.2796,  1.1082, -0.4181, -2.7109,  2.8895,\n",
      "         -1.7959,  3.8247, -4.8260,  0.0504,  4.2757, -3.2178,  0.6813,  2.3180,\n",
      "          1.7736, -3.7222,  4.0206, -3.7190, -2.1133,  0.6764,  2.3441, -1.8455,\n",
      "         -2.0158,  0.4267,  3.2111,  3.7253, -1.1144, -4.0186,  0.1856,  3.5138,\n",
      "          0.3718,  3.4749, -1.0226, -1.7912,  2.9626, -4.2468,  2.0429,  1.8573,\n",
      "         -0.3961, -3.6360,  2.6381,  1.1974, -4.7072, -2.8374, -2.1074,  3.1286,\n",
      "         -0.0340,  3.0291, -4.4233,  2.7635, -4.7937, -3.2696, -0.0474,  2.6108,\n",
      "          4.6727, -0.7084, -4.6527,  1.8097,  3.1316, -1.0451, -2.6622,  3.8328,\n",
      "         -3.3894, -0.5583,  0.0325,  2.8572,  4.2402,  1.0068,  3.7554,  0.4259,\n",
      "         -0.6239,  0.4245, -0.7868,  2.2846,  3.6746,  1.6133,  3.9526,  1.1535]])), ('fc1.bias', tensor([-0.1643, -0.0029, -0.0081])), ('fc2.weight', tensor([[-3.2595,  0.9230,  2.4579],\n",
      "        [-3.2830,  0.8232,  2.5020]])), ('fc2.bias', tensor([ 0.3437, -0.3437]))])\n",
      "[[11162   198]\n",
      " [ 3644    56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85     11360\n",
      "           1       0.22      0.02      0.03      3700\n",
      "\n",
      "    accuracy                           0.74     15060\n",
      "   macro avg       0.49      0.50      0.44     15060\n",
      "weighted avg       0.62      0.74      0.65     15060\n",
      "\n",
      "正解率 : 0.7448871181938911\n",
      "test loss : 0.5930057764053345\n",
      "step : 6000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8198, -1.7017,  2.4220, -3.2559, -3.0536,  4.0611,  2.3845,  2.1101,\n",
      "          3.5320, -3.9479, -2.0747, -2.5154,  4.4997, -1.6587,  0.9132, -0.3767,\n",
      "          3.7415, -2.9551, -3.3796,  0.2616, -1.4034, -3.3180,  4.9154, -4.7935,\n",
      "          2.7160, -1.8217,  0.2929,  2.6809,  1.9865, -4.4952, -3.7244,  2.5872,\n",
      "          2.9917, -1.7212, -2.9920,  0.4644, -4.3516,  1.0019, -1.6965, -2.5668,\n",
      "         -0.4127,  4.7846, -0.4783, -1.5656, -0.2702,  0.7046, -2.2632, -1.1146,\n",
      "         -2.3737, -1.2258,  3.9042,  3.5906, -1.4645,  3.9399, -3.0072, -4.8093,\n",
      "         -0.8033,  4.7524,  0.3337,  3.4538, -2.4893, -1.3359, -1.9028,  2.6349,\n",
      "          2.4592, -0.6422, -3.8300,  3.2175,  4.4074, -1.0305,  4.3918,  2.5342,\n",
      "          2.7898, -2.9276, -3.2847, -1.9182,  3.1528,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5366, -1.5560, -0.7465, -4.3142,  3.7220,  2.9151,  3.1238,  2.7051,\n",
      "         -4.0069, -1.2595,  2.8166,  2.6927, -3.4881,  4.6803,  0.5115,  2.2649,\n",
      "         -0.2523,  3.6577,  3.3888,  3.0508, -2.3886, -0.8595,  1.1711,  3.6790],\n",
      "        [ 4.1965,  3.9334, -0.5905,  3.9450,  0.9157,  2.4857,  0.7055, -2.8306,\n",
      "          3.1144,  0.4572, -3.0386,  4.3023,  2.5994,  1.0049,  3.1710,  3.8757,\n",
      "          0.2670, -2.3786, -2.9791, -3.3706,  2.8064, -3.5781, -4.4426,  4.4218,\n",
      "          1.1889, -4.4342, -4.7819, -2.5335, -1.4065,  3.5162,  1.3088,  4.6923,\n",
      "         -2.7816, -0.1608, -0.0296, -3.6838,  3.9943,  2.1570,  2.8357, -2.7736,\n",
      "         -3.6293, -0.4754, -3.4020, -4.5190, -0.4203, -4.0702,  4.5286, -2.5974,\n",
      "         -4.4663,  3.5105,  2.8755, -3.1950, -2.5810,  2.9415, -4.1236,  0.5749,\n",
      "          4.7504, -2.0761, -1.2355,  1.7092,  1.0172,  2.2584, -5.0015,  1.8395,\n",
      "          3.3684, -4.9486,  0.1192, -2.0610,  4.4274, -1.8702,  2.6472, -4.5531,\n",
      "          4.3002,  1.7044,  2.0986, -4.8266, -1.8526,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9163,  3.2083,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8855,\n",
      "          0.8296, -0.8177,  1.1668, -0.4810,  0.1173,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5731,  3.4011,  0.2047, -0.1507,  4.8666, -4.8962,  2.9688],\n",
      "        [-4.6179,  2.7576,  1.6699,  4.4876,  2.5696, -1.7415, -2.5868, -3.9578,\n",
      "          2.4204, -4.8292,  3.9417, -4.5401,  4.3887, -0.0839,  1.6604, -3.0668,\n",
      "          1.2848,  2.0381, -4.0749,  3.1378, -2.3515,  4.3879, -1.6236,  4.0162,\n",
      "         -4.2747, -1.7965,  4.2471,  3.2797,  1.1072, -0.4189, -2.7109,  2.8898,\n",
      "         -1.7960,  3.8225, -4.8260,  0.0503,  4.2753, -3.2178,  0.6808,  2.3179,\n",
      "          1.7733, -3.7223,  4.0201, -3.7195, -2.1133,  0.6765,  2.3441, -1.8459,\n",
      "         -2.0159,  0.4265,  3.2114,  3.7238, -1.1148, -4.0195,  0.1852,  3.5139,\n",
      "          0.3718,  3.4746, -1.0230, -1.7913,  2.9605, -4.2479,  2.0411,  1.8573,\n",
      "         -0.3961, -3.6360,  2.6381,  1.1974, -4.7072, -2.8374, -2.1074,  3.1286,\n",
      "         -0.0340,  3.0291, -4.4233,  2.7634, -4.7937, -3.2696, -0.0474,  2.6108,\n",
      "          4.6727, -0.7084, -4.6527,  1.8097,  3.1316, -1.0451, -2.6622,  3.8328,\n",
      "         -3.3894, -0.5583,  0.0325,  2.8572,  4.2402,  1.0067,  3.7554,  0.4259,\n",
      "         -0.6239,  0.4244, -0.7868,  2.2846,  3.6746,  1.6108,  3.9526,  1.1535]])), ('fc1.bias', tensor([-0.1646, -0.0040, -0.0110])), ('fc2.weight', tensor([[-3.2544,  0.9219,  2.4373],\n",
      "        [-3.2881,  0.8243,  2.5226]])), ('fc2.bias', tensor([ 0.3966, -0.3966]))])\n",
      "[[10082  1278]\n",
      " [ 3352   348]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.81     11360\n",
      "           1       0.21      0.09      0.13      3700\n",
      "\n",
      "    accuracy                           0.69     15060\n",
      "   macro avg       0.48      0.49      0.47     15060\n",
      "weighted avg       0.62      0.69      0.65     15060\n",
      "\n",
      "正解率 : 0.6925630810092962\n",
      "test loss : 0.591562807559967\n",
      "step : 7000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8199, -1.7019,  2.4215, -3.2559, -3.0536,  4.0607,  2.3845,  2.1100,\n",
      "          3.5313, -3.9479, -2.0747, -2.5154,  4.4997, -1.6587,  0.9131, -0.3767,\n",
      "          3.7415, -2.9551, -3.3796,  0.2616, -1.4035, -3.3180,  4.9151, -4.7935,\n",
      "          2.7157, -1.8217,  0.2929,  2.6809,  1.9865, -4.4952, -3.7244,  2.5867,\n",
      "          2.9917, -1.7215, -2.9920,  0.4644, -4.3517,  1.0019, -1.6967, -2.5668,\n",
      "         -0.4127,  4.7846, -0.4784, -1.5656, -0.2702,  0.7044, -2.2632, -1.1147,\n",
      "         -2.3738, -1.2258,  3.9037,  3.5905, -1.4645,  3.9397, -3.0072, -4.8093,\n",
      "         -0.8033,  4.7523,  0.3336,  3.4538, -2.4899, -1.3361, -1.9035,  2.6349,\n",
      "          2.4592, -0.6422, -3.8300,  3.2175,  4.4074, -1.0305,  4.3918,  2.5342,\n",
      "          2.7898, -2.9276, -3.2847, -1.9182,  3.1528,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5366, -1.5560, -0.7465, -4.3142,  3.7220,  2.9151,  3.1238,  2.7051,\n",
      "         -4.0069, -1.2595,  2.8166,  2.6927, -3.4882,  4.6803,  0.5115,  2.2649,\n",
      "         -0.2523,  3.6577,  3.3888,  3.0508, -2.3886, -0.8602,  1.1711,  3.6790],\n",
      "        [ 4.1957,  3.9333, -0.5918,  3.9448,  0.9155,  2.4851,  0.7052, -2.8309,\n",
      "          3.1152,  0.4567, -3.0384,  4.3020,  2.5994,  1.0051,  3.1714,  3.8758,\n",
      "          0.2670, -2.3786, -2.9788, -3.3705,  2.8062, -3.5778, -4.4437,  4.4215,\n",
      "          1.1896, -4.4349, -4.7819, -2.5339, -1.4062,  3.5170,  1.3088,  4.6876,\n",
      "         -2.7815, -0.1579, -0.0293, -3.6836,  3.9949,  2.1570,  2.8354, -2.7743,\n",
      "         -3.6290, -0.4751, -3.4018, -4.5183, -0.4203, -4.0710,  4.5282, -2.5979,\n",
      "         -4.4665,  3.5106,  2.8715, -3.1931, -2.5808,  2.9430, -4.1228,  0.5741,\n",
      "          4.7506, -2.0762, -1.2351,  1.7093,  1.0162,  2.2601, -5.0036,  1.8395,\n",
      "          3.3684, -4.9486,  0.1193, -2.0610,  4.4274, -1.8702,  2.6472, -4.5531,\n",
      "          4.3002,  1.7044,  2.0987, -4.8265, -1.8526,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9163,  3.2082,  3.7506,  2.5495, -2.1632, -2.2137,  1.7910, -0.8855,\n",
      "          0.8297, -0.8177,  1.1668, -0.4809,  0.1173,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5731,  3.4011,  0.2047, -0.1507,  4.8659, -4.8962,  2.9688],\n",
      "        [-4.6181,  2.7573,  1.6689,  4.4877,  2.5697, -1.7424, -2.5866, -3.9577,\n",
      "          2.4178, -4.8289,  3.9411, -4.5400,  4.3887, -0.0840,  1.6599, -3.0669,\n",
      "          1.2848,  2.0381, -4.0751,  3.1376, -2.3517,  4.3876, -1.6232,  4.0163,\n",
      "         -4.2756, -1.7962,  4.2471,  3.2797,  1.1061, -0.4195, -2.7109,  2.8907,\n",
      "         -1.7960,  3.8197, -4.8260,  0.0502,  4.2742, -3.2178,  0.6807,  2.3183,\n",
      "          1.7730, -3.7226,  4.0198, -3.7199, -2.1134,  0.6763,  2.3442, -1.8460,\n",
      "         -2.0158,  0.4264,  3.2121,  3.7219, -1.1149, -4.0205,  0.1847,  3.5141,\n",
      "          0.3717,  3.4742, -1.0233, -1.7913,  2.9587, -4.2489,  2.0396,  1.8573,\n",
      "         -0.3961, -3.6361,  2.6381,  1.1974, -4.7072, -2.8374, -2.1074,  3.1286,\n",
      "         -0.0340,  3.0292, -4.4233,  2.7634, -4.7937, -3.2696, -0.0474,  2.6108,\n",
      "          4.6727, -0.7085, -4.6528,  1.8096,  3.1316, -1.0450, -2.6622,  3.8328,\n",
      "         -3.3895, -0.5583,  0.0325,  2.8571,  4.2401,  1.0067,  3.7554,  0.4259,\n",
      "         -0.6239,  0.4243, -0.7868,  2.2846,  3.6746,  1.6088,  3.9525,  1.1536]])), ('fc1.bias', tensor([-0.1654, -0.0044, -0.0136])), ('fc2.weight', tensor([[-3.2706,  0.9084,  2.4849],\n",
      "        [-3.2719,  0.8379,  2.4750]])), ('fc2.bias', tensor([ 0.4389, -0.4389]))])\n",
      "[[11360     0]\n",
      " [ 3700     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     11360\n",
      "           1       0.00      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.38      0.50      0.43     15060\n",
      "weighted avg       0.57      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.7543160690571049\n",
      "test loss : 0.6057242751121521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 8000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8199, -1.7020,  2.4208, -3.2558, -3.0535,  4.0603,  2.3844,  2.1102,\n",
      "          3.5294, -3.9478, -2.0748, -2.5153,  4.4997, -1.6587,  0.9129, -0.3767,\n",
      "          3.7414, -2.9551, -3.3797,  0.2616, -1.4035, -3.3180,  4.9153, -4.7935,\n",
      "          2.7146, -1.8216,  0.2929,  2.6811,  1.9857, -4.4954, -3.7244,  2.5879,\n",
      "          2.9915, -1.7239, -2.9921,  0.4643, -4.3521,  1.0019, -1.6969, -2.5664,\n",
      "         -0.4127,  4.7841, -0.4787, -1.5662, -0.2703,  0.7046, -2.2631, -1.1150,\n",
      "         -2.3739, -1.2257,  3.9049,  3.5889, -1.4647,  3.9386, -3.0073, -4.8093,\n",
      "         -0.8033,  4.7521,  0.3331,  3.4537, -2.4907, -1.3372, -1.9040,  2.6349,\n",
      "          2.4592, -0.6423, -3.8301,  3.2175,  4.4074, -1.0305,  4.3918,  2.5342,\n",
      "          2.7898, -2.9276, -3.2847, -1.9182,  3.1528,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5366, -1.5560, -0.7465, -4.3142,  3.7220,  2.9150,  3.1238,  2.7051,\n",
      "         -4.0070, -1.2595,  2.8166,  2.6927, -3.4882,  4.6803,  0.5114,  2.2648,\n",
      "         -0.2523,  3.6577,  3.3888,  3.0508, -2.3886, -0.8614,  1.1710,  3.6790],\n",
      "        [ 4.1949,  3.9332, -0.5929,  3.9445,  0.9152,  2.4844,  0.7049, -2.8314,\n",
      "          3.1160,  0.4565, -3.0384,  4.3020,  2.5994,  1.0054,  3.1717,  3.8758,\n",
      "          0.2671, -2.3786, -2.9788, -3.3703,  2.8062, -3.5779, -4.4449,  4.4213,\n",
      "          1.1905, -4.4357, -4.7819, -2.5344, -1.4055,  3.5182,  1.3087,  4.6827,\n",
      "         -2.7814, -0.1549, -0.0292, -3.6833,  3.9955,  2.1570,  2.8351, -2.7755,\n",
      "         -3.6289, -0.4747, -3.4015, -4.5173, -0.4202, -4.0717,  4.5280, -2.5979,\n",
      "         -4.4667,  3.5105,  2.8671, -3.1910, -2.5807,  2.9445, -4.1219,  0.5736,\n",
      "          4.7506, -2.0761, -1.2346,  1.7094,  1.0152,  2.2621, -5.0059,  1.8395,\n",
      "          3.3684, -4.9486,  0.1193, -2.0610,  4.4274, -1.8702,  2.6472, -4.5531,\n",
      "          4.3002,  1.7044,  2.0987, -4.8265, -1.8526,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2082,  3.7506,  2.5495, -2.1632, -2.2137,  1.7910, -0.8855,\n",
      "          0.8299, -0.8177,  1.1668, -0.4809,  0.1173,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5732,  3.4011,  0.2047, -0.1507,  4.8654, -4.8962,  2.9688],\n",
      "        [-4.6186,  2.7569,  1.6674,  4.4878,  2.5697, -1.7434, -2.5867, -3.9576,\n",
      "          2.4152, -4.8288,  3.9408, -4.5401,  4.3887, -0.0842,  1.6597, -3.0669,\n",
      "          1.2848,  2.0380, -4.0751,  3.1375, -2.3517,  4.3874, -1.6232,  4.0163,\n",
      "         -4.2765, -1.7962,  4.2471,  3.2799,  1.1049, -0.4199, -2.7109,  2.8913,\n",
      "         -1.7961,  3.8169, -4.8261,  0.0501,  4.2734, -3.2178,  0.6804,  2.3183,\n",
      "          1.7728, -3.7230,  4.0193, -3.7203, -2.1134,  0.6763,  2.3443, -1.8465,\n",
      "         -2.0158,  0.4264,  3.2126,  3.7196, -1.1150, -4.0212,  0.1843,  3.5143,\n",
      "          0.3717,  3.4740, -1.0236, -1.7914,  2.9564, -4.2501,  2.0379,  1.8572,\n",
      "         -0.3961, -3.6361,  2.6381,  1.1974, -4.7072, -2.8375, -2.1074,  3.1286,\n",
      "         -0.0340,  3.0292, -4.4233,  2.7634, -4.7937, -3.2696, -0.0474,  2.6108,\n",
      "          4.6727, -0.7085, -4.6528,  1.8096,  3.1316, -1.0450, -2.6622,  3.8328,\n",
      "         -3.3896, -0.5583,  0.0325,  2.8571,  4.2400,  1.0067,  3.7554,  0.4258,\n",
      "         -0.6239,  0.4243, -0.7868,  2.2846,  3.6746,  1.6063,  3.9525,  1.1536]])), ('fc1.bias', tensor([-0.1670, -0.0046, -0.0165])), ('fc2.weight', tensor([[-3.2852,  0.9171,  2.4814],\n",
      "        [-3.2574,  0.8292,  2.4785]])), ('fc2.bias', tensor([ 0.4885, -0.4885]))])\n",
      "[[11360     0]\n",
      " [ 3700     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     11360\n",
      "           1       0.00      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.38      0.50      0.43     15060\n",
      "weighted avg       0.57      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.7543160690571049\n",
      "test loss : 0.6087082028388977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 9000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8199, -1.7021,  2.4204, -3.2557, -3.0535,  4.0600,  2.3844,  2.1102,\n",
      "          3.5283, -3.9478, -2.0746, -2.5153,  4.4997, -1.6587,  0.9129, -0.3768,\n",
      "          3.7414, -2.9551, -3.3797,  0.2616, -1.4035, -3.3180,  4.9153, -4.7935,\n",
      "          2.7143, -1.8217,  0.2929,  2.6812,  1.9855, -4.4954, -3.7244,  2.5882,\n",
      "          2.9915, -1.7250, -2.9921,  0.4643, -4.3522,  1.0019, -1.6970, -2.5664,\n",
      "         -0.4127,  4.7838, -0.4789, -1.5663, -0.2703,  0.7044, -2.2631, -1.1148,\n",
      "         -2.3739, -1.2258,  3.9052,  3.5882, -1.4647,  3.9382, -3.0073, -4.8092,\n",
      "         -0.8033,  4.7520,  0.3330,  3.4537, -2.4914, -1.3377, -1.9045,  2.6349,\n",
      "          2.4592, -0.6423, -3.8301,  3.2175,  4.4074, -1.0305,  4.3918,  2.5341,\n",
      "          2.7898, -2.9276, -3.2847, -1.9182,  3.1528,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5366, -1.5560, -0.7465, -4.3142,  3.7219,  2.9150,  3.1239,  2.7051,\n",
      "         -4.0071, -1.2595,  2.8166,  2.6927, -3.4882,  4.6803,  0.5114,  2.2648,\n",
      "         -0.2523,  3.6577,  3.3888,  3.0508, -2.3886, -0.8621,  1.1710,  3.6790],\n",
      "        [ 4.1940,  3.9331, -0.5944,  3.9442,  0.9151,  2.4837,  0.7048, -2.8315,\n",
      "          3.1158,  0.4563, -3.0385,  4.3015,  2.5994,  1.0054,  3.1718,  3.8758,\n",
      "          0.2671, -2.3785, -2.9787, -3.3703,  2.8060, -3.5777, -4.4463,  4.4211,\n",
      "          1.1910, -4.4362, -4.7819, -2.5347, -1.4051,  3.5189,  1.3087,  4.6790,\n",
      "         -2.7814, -0.1532, -0.0291, -3.6832,  3.9954,  2.1570,  2.8353, -2.7769,\n",
      "         -3.6287, -0.4746, -3.4012, -4.5168, -0.4202, -4.0726,  4.5281, -2.5978,\n",
      "         -4.4668,  3.5105,  2.8641, -3.1901, -2.5805,  2.9456, -4.1214,  0.5728,\n",
      "          4.7507, -2.0760, -1.2344,  1.7094,  1.0137,  2.2627, -5.0076,  1.8395,\n",
      "          3.3683, -4.9486,  0.1193, -2.0611,  4.4274, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7044,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2082,  3.7506,  2.5495, -2.1632, -2.2137,  1.7910, -0.8855,\n",
      "          0.8300, -0.8177,  1.1668, -0.4809,  0.1173,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5732,  3.4011,  0.2047, -0.1507,  4.8642, -4.8962,  2.9688],\n",
      "        [-4.6188,  2.7566,  1.6664,  4.4880,  2.5697, -1.7443, -2.5865, -3.9576,\n",
      "          2.4119, -4.8286,  3.9409, -4.5400,  4.3887, -0.0844,  1.6594, -3.0669,\n",
      "          1.2847,  2.0378, -4.0753,  3.1374, -2.3518,  4.3873, -1.6227,  4.0163,\n",
      "         -4.2773, -1.7962,  4.2471,  3.2801,  1.1038, -0.4204, -2.7109,  2.8923,\n",
      "         -1.7962,  3.8140, -4.8262,  0.0500,  4.2729, -3.2178,  0.6801,  2.3190,\n",
      "          1.7725, -3.7235,  4.0188, -3.7208, -2.1134,  0.6761,  2.3442, -1.8466,\n",
      "         -2.0159,  0.4262,  3.2135,  3.7174, -1.1152, -4.0223,  0.1840,  3.5145,\n",
      "          0.3716,  3.4739, -1.0235, -1.7914,  2.9538, -4.2512,  2.0363,  1.8572,\n",
      "         -0.3961, -3.6361,  2.6381,  1.1974, -4.7073, -2.8375, -2.1074,  3.1286,\n",
      "         -0.0340,  3.0291, -4.4234,  2.7634, -4.7938, -3.2696, -0.0474,  2.6108,\n",
      "          4.6727, -0.7085, -4.6528,  1.8096,  3.1316, -1.0450, -2.6621,  3.8328,\n",
      "         -3.3898, -0.5583,  0.0325,  2.8571,  4.2399,  1.0067,  3.7554,  0.4259,\n",
      "         -0.6239,  0.4243, -0.7868,  2.2846,  3.6746,  1.6041,  3.9525,  1.1536]])), ('fc1.bias', tensor([-0.1679, -0.0057, -0.0192])), ('fc2.weight', tensor([[-3.2887,  0.8772,  2.4506],\n",
      "        [-3.2539,  0.8691,  2.5093]])), ('fc2.bias', tensor([ 0.5298, -0.5298]))])\n",
      "[[10334  1026]\n",
      " [ 2915   785]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84     11360\n",
      "           1       0.43      0.21      0.28      3700\n",
      "\n",
      "    accuracy                           0.74     15060\n",
      "   macro avg       0.61      0.56      0.56     15060\n",
      "weighted avg       0.69      0.74      0.70     15060\n",
      "\n",
      "正解率 : 0.7383134130146083\n",
      "test loss : 0.5711709260940552\n",
      "step : 10000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8197, -1.7023,  2.4197, -3.2555, -3.0534,  4.0596,  2.3843,  2.1101,\n",
      "          3.5269, -3.9477, -2.0746, -2.5152,  4.4997, -1.6586,  0.9128, -0.3768,\n",
      "          3.7414, -2.9551, -3.3797,  0.2615, -1.4035, -3.3181,  4.9153, -4.7935,\n",
      "          2.7131, -1.8215,  0.2929,  2.6813,  1.9850, -4.4956, -3.7244,  2.5891,\n",
      "          2.9914, -1.7269, -2.9922,  0.4642, -4.3526,  1.0019, -1.6972, -2.5657,\n",
      "         -0.4128,  4.7836, -0.4794, -1.5670, -0.2704,  0.7045, -2.2632, -1.1150,\n",
      "         -2.3738, -1.2258,  3.9061,  3.5868, -1.4648,  3.9373, -3.0074, -4.8092,\n",
      "         -0.8033,  4.7518,  0.3326,  3.4536, -2.4923, -1.3386, -1.9050,  2.6349,\n",
      "          2.4592, -0.6423, -3.8301,  3.2175,  4.4074, -1.0304,  4.3918,  2.5341,\n",
      "          2.7897, -2.9276, -3.2847, -1.9182,  3.1527,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5366, -1.5560, -0.7464, -4.3142,  3.7219,  2.9150,  3.1239,  2.7051,\n",
      "         -4.0071, -1.2595,  2.8166,  2.6927, -3.4884,  4.6803,  0.5114,  2.2647,\n",
      "         -0.2523,  3.6576,  3.3888,  3.0507, -2.3886, -0.8634,  1.1710,  3.6790],\n",
      "        [ 4.1929,  3.9329, -0.5956,  3.9440,  0.9149,  2.4829,  0.7046, -2.8320,\n",
      "          3.1155,  0.4561, -3.0384,  4.3016,  2.5994,  1.0055,  3.1718,  3.8759,\n",
      "          0.2671, -2.3785, -2.9786, -3.3702,  2.8060, -3.5778, -4.4468,  4.4209,\n",
      "          1.1912, -4.4367, -4.7819, -2.5350, -1.4052,  3.5191,  1.3087,  4.6756,\n",
      "         -2.7813, -0.1514, -0.0289, -3.6831,  3.9958,  2.1570,  2.8352, -2.7778,\n",
      "         -3.6286, -0.4743, -3.4010, -4.5162, -0.4201, -4.0735,  4.5279, -2.5981,\n",
      "         -4.4670,  3.5104,  2.8610, -3.1893, -2.5804,  2.9465, -4.1209,  0.5724,\n",
      "          4.7506, -2.0760, -1.2340,  1.7094,  1.0123,  2.2636, -5.0096,  1.8395,\n",
      "          3.3683, -4.9486,  0.1193, -2.0611,  4.4274, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7044,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2082,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8855,\n",
      "          0.8300, -0.8177,  1.1668, -0.4809,  0.1173,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5732,  3.4012,  0.2047, -0.1507,  4.8633, -4.8962,  2.9688],\n",
      "        [-4.6190,  2.7562,  1.6652,  4.4881,  2.5698, -1.7453, -2.5866, -3.9574,\n",
      "          2.4088, -4.8283,  3.9407, -4.5400,  4.3887, -0.0845,  1.6593, -3.0670,\n",
      "          1.2847,  2.0378, -4.0754,  3.1372, -2.3519,  4.3871, -1.6227,  4.0164,\n",
      "         -4.2787, -1.7956,  4.2470,  3.2802,  1.1024, -0.4211, -2.7109,  2.8930,\n",
      "         -1.7962,  3.8113, -4.8263,  0.0499,  4.2723, -3.2178,  0.6796,  2.3196,\n",
      "          1.7723, -3.7237,  4.0180, -3.7214, -2.1135,  0.6762,  2.3442, -1.8468,\n",
      "         -2.0160,  0.4259,  3.2141,  3.7153, -1.1153, -4.0232,  0.1834,  3.5147,\n",
      "          0.3716,  3.4739, -1.0237, -1.7914,  2.9512, -4.2523,  2.0345,  1.8572,\n",
      "         -0.3961, -3.6361,  2.6381,  1.1973, -4.7073, -2.8374, -2.1074,  3.1286,\n",
      "         -0.0341,  3.0291, -4.4234,  2.7634, -4.7938, -3.2696, -0.0474,  2.6108,\n",
      "          4.6727, -0.7084, -4.6527,  1.8096,  3.1316, -1.0450, -2.6621,  3.8328,\n",
      "         -3.3900, -0.5583,  0.0325,  2.8571,  4.2398,  1.0067,  3.7554,  0.4258,\n",
      "         -0.6239,  0.4243, -0.7868,  2.2846,  3.6746,  1.6015,  3.9525,  1.1536]])), ('fc1.bias', tensor([-0.1695, -0.0068, -0.0221])), ('fc2.weight', tensor([[-3.2818,  0.8910,  2.4524],\n",
      "        [-3.2607,  0.8553,  2.5075]])), ('fc2.bias', tensor([ 0.5688, -0.5688]))])\n",
      "[[11252   108]\n",
      " [ 3641    59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86     11360\n",
      "           1       0.35      0.02      0.03      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.55      0.50      0.44     15060\n",
      "weighted avg       0.66      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.7510624169986719\n",
      "test loss : 0.5462544560432434\n",
      "step : 11000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8197, -1.7024,  2.4194, -3.2555, -3.0533,  4.0594,  2.3845,  2.1102,\n",
      "          3.5257, -3.9476, -2.0748, -2.5151,  4.4997, -1.6587,  0.9126, -0.3768,\n",
      "          3.7414, -2.9552, -3.3797,  0.2614, -1.4034, -3.3181,  4.9152, -4.7934,\n",
      "          2.7126, -1.8212,  0.2929,  2.6815,  1.9846, -4.4955, -3.7244,  2.5897,\n",
      "          2.9914, -1.7282, -2.9923,  0.4642, -4.3526,  1.0019, -1.6973, -2.5652,\n",
      "         -0.4130,  4.7833, -0.4796, -1.5675, -0.2704,  0.7047, -2.2631, -1.1152,\n",
      "         -2.3740, -1.2257,  3.9067,  3.5862, -1.4649,  3.9366, -3.0075, -4.8092,\n",
      "         -0.8033,  4.7519,  0.3323,  3.4535, -2.4928, -1.3394, -1.9051,  2.6348,\n",
      "          2.4591, -0.6423, -3.8300,  3.2175,  4.4074, -1.0304,  4.3917,  2.5341,\n",
      "          2.7897, -2.9276, -3.2847, -1.9182,  3.1527,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5366, -1.5560, -0.7464, -4.3142,  3.7219,  2.9150,  3.1239,  2.7051,\n",
      "         -4.0071, -1.2595,  2.8166,  2.6927, -3.4883,  4.6803,  0.5114,  2.2647,\n",
      "         -0.2523,  3.6576,  3.3888,  3.0507, -2.3886, -0.8639,  1.1710,  3.6790],\n",
      "        [ 4.1921,  3.9327, -0.5968,  3.9439,  0.9148,  2.4821,  0.7042, -2.8323,\n",
      "          3.1154,  0.4559, -3.0384,  4.3014,  2.5994,  1.0056,  3.1719,  3.8759,\n",
      "          0.2671, -2.3785, -2.9786, -3.3701,  2.8059, -3.5779, -4.4475,  4.4207,\n",
      "          1.1913, -4.4371, -4.7819, -2.5351, -1.4053,  3.5194,  1.3087,  4.6726,\n",
      "         -2.7812, -0.1501, -0.0288, -3.6831,  3.9956,  2.1570,  2.8349, -2.7788,\n",
      "         -3.6285, -0.4741, -3.4009, -4.5158, -0.4201, -4.0740,  4.5277, -2.5980,\n",
      "         -4.4670,  3.5104,  2.8584, -3.1887, -2.5803,  2.9472, -4.1205,  0.5720,\n",
      "          4.7506, -2.0760, -1.2338,  1.7095,  1.0108,  2.2641, -5.0114,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0611,  4.4274, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7043,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2081,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8855,\n",
      "          0.8300, -0.8177,  1.1668, -0.4809,  0.1173,  4.7641,  1.4558,  3.9828,\n",
      "          2.2176,  0.5732,  3.4012,  0.2047, -0.1507,  4.8618, -4.8962,  2.9688],\n",
      "        [-4.6188,  2.7558,  1.6644,  4.4884,  2.5701, -1.7460, -2.5863, -3.9571,\n",
      "          2.4049, -4.8278,  3.9403, -4.5396,  4.3887, -0.0849,  1.6587, -3.0670,\n",
      "          1.2847,  2.0376, -4.0755,  3.1370, -2.3520,  4.3870, -1.6223,  4.0166,\n",
      "         -4.2798, -1.7950,  4.2470,  3.2803,  1.1011, -0.4218, -2.7109,  2.8955,\n",
      "         -1.7963,  3.8069, -4.8263,  0.0499,  4.2715, -3.2178,  0.6786,  2.3205,\n",
      "          1.7720, -3.7242,  4.0174, -3.7222, -2.1135,  0.6765,  2.3443, -1.8468,\n",
      "         -2.0159,  0.4256,  3.2161,  3.7124, -1.1156, -4.0249,  0.1830,  3.5151,\n",
      "          0.3715,  3.4738, -1.0241, -1.7916,  2.9491, -4.2538,  2.0331,  1.8572,\n",
      "         -0.3961, -3.6361,  2.6381,  1.1973, -4.7073, -2.8375, -2.1075,  3.1286,\n",
      "         -0.0341,  3.0292, -4.4234,  2.7634, -4.7938, -3.2696, -0.0474,  2.6108,\n",
      "          4.6727, -0.7084, -4.6527,  1.8096,  3.1316, -1.0450, -2.6621,  3.8328,\n",
      "         -3.3902, -0.5583,  0.0325,  2.8571,  4.2398,  1.0067,  3.7554,  0.4257,\n",
      "         -0.6239,  0.4243, -0.7868,  2.2846,  3.6746,  1.5992,  3.9524,  1.1536]])), ('fc1.bias', tensor([-0.1703, -0.0081, -0.0249])), ('fc2.weight', tensor([[-3.2567,  0.8961,  2.4484],\n",
      "        [-3.2859,  0.8502,  2.5115]])), ('fc2.bias', tensor([ 0.6097, -0.6097]))])\n",
      "[[11277    83]\n",
      " [ 3682    18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.86     11360\n",
      "           1       0.18      0.00      0.01      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.47      0.50      0.43     15060\n",
      "weighted avg       0.61      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.75\n",
      "test loss : 0.5541496276855469\n",
      "step : 12000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8199, -1.7025,  2.4189, -3.2555, -3.0533,  4.0590,  2.3844,  2.1102,\n",
      "          3.5249, -3.9476, -2.0750, -2.5151,  4.4997, -1.6588,  0.9125, -0.3769,\n",
      "          3.7414, -2.9552, -3.3797,  0.2614, -1.4035, -3.3181,  4.9155, -4.7935,\n",
      "          2.7121, -1.8212,  0.2929,  2.6814,  1.9842, -4.4956, -3.7244,  2.5897,\n",
      "          2.9913, -1.7289, -2.9924,  0.4641, -4.3528,  1.0019, -1.6975, -2.5647,\n",
      "         -0.4130,  4.7831, -0.4799, -1.5676, -0.2704,  0.7044, -2.2631, -1.1154,\n",
      "         -2.3739, -1.2258,  3.9064,  3.5856, -1.4649,  3.9364, -3.0075, -4.8091,\n",
      "         -0.8033,  4.7518,  0.3322,  3.4535, -2.4936, -1.3396, -1.9059,  2.6348,\n",
      "          2.4591, -0.6423, -3.8300,  3.2174,  4.4074, -1.0304,  4.3917,  2.5341,\n",
      "          2.7898, -2.9276, -3.2847, -1.9182,  3.1527,  2.6810,  0.6493,  1.4864,\n",
      "         -2.5366, -1.5560, -0.7464, -4.3142,  3.7219,  2.9150,  3.1238,  2.7051,\n",
      "         -4.0071, -1.2596,  2.8166,  2.6927, -3.4883,  4.6803,  0.5114,  2.2646,\n",
      "         -0.2523,  3.6576,  3.3888,  3.0507, -2.3886, -0.8647,  1.1710,  3.6790],\n",
      "        [ 4.1913,  3.9325, -0.5979,  3.9437,  0.9146,  2.4815,  0.7039, -2.8325,\n",
      "          3.1152,  0.4556, -3.0385,  4.3011,  2.5994,  1.0057,  3.1720,  3.8759,\n",
      "          0.2671, -2.3784, -2.9786, -3.3701,  2.8059, -3.5778, -4.4480,  4.4205,\n",
      "          1.1910, -4.4374, -4.7819, -2.5352, -1.4054,  3.5200,  1.3087,  4.6695,\n",
      "         -2.7812, -0.1490, -0.0287, -3.6831,  3.9954,  2.1570,  2.8346, -2.7795,\n",
      "         -3.6285, -0.4739, -3.4006, -4.5156, -0.4201, -4.0746,  4.5277, -2.5979,\n",
      "         -4.4671,  3.5103,  2.8559, -3.1877, -2.5803,  2.9477, -4.1202,  0.5716,\n",
      "          4.7507, -2.0761, -1.2338,  1.7094,  1.0097,  2.2646, -5.0131,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0611,  4.4274, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7043,  2.0986, -4.8265, -1.8526,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2082,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8855,\n",
      "          0.8300, -0.8177,  1.1668, -0.4809,  0.1173,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5732,  3.4012,  0.2047, -0.1507,  4.8607, -4.8962,  2.9688],\n",
      "        [-4.6189,  2.7554,  1.6634,  4.4887,  2.5704, -1.7471, -2.5860, -3.9565,\n",
      "          2.4007, -4.8275,  3.9395, -4.5393,  4.3887, -0.0851,  1.6582, -3.0672,\n",
      "          1.2845,  2.0373, -4.0758,  3.1369, -2.3521,  4.3867, -1.6223,  4.0170,\n",
      "         -4.2816, -1.7938,  4.2470,  3.2805,  1.0996, -0.4227, -2.7109,  2.8983,\n",
      "         -1.7965,  3.8020, -4.8264,  0.0497,  4.2703, -3.2178,  0.6776,  2.3214,\n",
      "          1.7715, -3.7246,  4.0165, -3.7228, -2.1136,  0.6776,  2.3444, -1.8478,\n",
      "         -2.0157,  0.4257,  3.2183,  3.7089, -1.1157, -4.0268,  0.1823,  3.5157,\n",
      "          0.3715,  3.4737, -1.0243, -1.7916,  2.9460, -4.2558,  2.0317,  1.8572,\n",
      "         -0.3961, -3.6362,  2.6381,  1.1974, -4.7073, -2.8375, -2.1076,  3.1286,\n",
      "         -0.0340,  3.0293, -4.4234,  2.7632, -4.7938, -3.2696, -0.0474,  2.6108,\n",
      "          4.6727, -0.7084, -4.6527,  1.8097,  3.1315, -1.0450, -2.6622,  3.8328,\n",
      "         -3.3902, -0.5583,  0.0325,  2.8571,  4.2398,  1.0066,  3.7554,  0.4257,\n",
      "         -0.6239,  0.4243, -0.7868,  2.2846,  3.6746,  1.5960,  3.9524,  1.1536]])), ('fc1.bias', tensor([-0.1713, -0.0093, -0.0284])), ('fc2.weight', tensor([[-3.3032,  0.8667,  2.4572],\n",
      "        [-3.2393,  0.8796,  2.5027]])), ('fc2.bias', tensor([ 0.6467, -0.6467]))])\n",
      "[[10622   738]\n",
      " [ 3009   691]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85     11360\n",
      "           1       0.48      0.19      0.27      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.63      0.56      0.56     15060\n",
      "weighted avg       0.71      0.75      0.71     15060\n",
      "\n",
      "正解率 : 0.751195219123506\n",
      "test loss : 0.5588831305503845\n",
      "step : 13000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8195, -1.7027,  2.4185, -3.2554, -3.0531,  4.0586,  2.3846,  2.1103,\n",
      "          3.5233, -3.9476, -2.0752, -2.5149,  4.4997, -1.6588,  0.9123, -0.3770,\n",
      "          3.7414, -2.9552, -3.3798,  0.2613, -1.4035, -3.3181,  4.9154, -4.7935,\n",
      "          2.7114, -1.8208,  0.2929,  2.6816,  1.9835, -4.4957, -3.7244,  2.5914,\n",
      "          2.9912, -1.7315, -2.9925,  0.4640, -4.3530,  1.0019, -1.6977, -2.5641,\n",
      "         -0.4131,  4.7828, -0.4802, -1.5682, -0.2705,  0.7048, -2.2630, -1.1158,\n",
      "         -2.3740, -1.2260,  3.9079,  3.5841, -1.4650,  3.9349, -3.0076, -4.8088,\n",
      "         -0.8034,  4.7514,  0.3319,  3.4534, -2.4942, -1.3409, -1.9060,  2.6348,\n",
      "          2.4591, -0.6423, -3.8301,  3.2174,  4.4073, -1.0304,  4.3917,  2.5342,\n",
      "          2.7898, -2.9276, -3.2847, -1.9182,  3.1527,  2.6810,  0.6493,  1.4864,\n",
      "         -2.5366, -1.5560, -0.7464, -4.3142,  3.7219,  2.9149,  3.1238,  2.7051,\n",
      "         -4.0072, -1.2596,  2.8166,  2.6927, -3.4885,  4.6803,  0.5114,  2.2646,\n",
      "         -0.2523,  3.6576,  3.3888,  3.0507, -2.3886, -0.8657,  1.1709,  3.6791],\n",
      "        [ 4.1904,  3.9324, -0.5993,  3.9435,  0.9142,  2.4807,  0.7037, -2.8328,\n",
      "          3.1148,  0.4554, -3.0382,  4.3008,  2.5994,  1.0058,  3.1722,  3.8760,\n",
      "          0.2671, -2.3783, -2.9786, -3.3701,  2.8059, -3.5778, -4.4491,  4.4202,\n",
      "          1.1911, -4.4381, -4.7819, -2.5354, -1.4050,  3.5206,  1.3087,  4.6658,\n",
      "         -2.7812, -0.1473, -0.0287, -3.6830,  3.9955,  2.1570,  2.8347, -2.7806,\n",
      "         -3.6283, -0.4737, -3.4004, -4.5151, -0.4201, -4.0757,  4.5277, -2.5980,\n",
      "         -4.4673,  3.5104,  2.8529, -3.1867, -2.5802,  2.9487, -4.1198,  0.5708,\n",
      "          4.7507, -2.0761, -1.2338,  1.7095,  1.0083,  2.2653, -5.0149,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0611,  4.4274, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7043,  2.0986, -4.8265, -1.8526,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2081,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8855,\n",
      "          0.8301, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5732,  3.4012,  0.2047, -0.1507,  4.8594, -4.8962,  2.9687],\n",
      "        [-4.6188,  2.7549,  1.6623,  4.4890,  2.5708, -1.7481, -2.5857, -3.9560,\n",
      "          2.3968, -4.8269,  3.9383, -4.5389,  4.3887, -0.0855,  1.6579, -3.0675,\n",
      "          1.2845,  2.0371, -4.0759,  3.1367, -2.3521,  4.3864, -1.6221,  4.0173,\n",
      "         -4.2829, -1.7928,  4.2470,  3.2807,  1.0977, -0.4236, -2.7109,  2.9014,\n",
      "         -1.7966,  3.7968, -4.8266,  0.0495,  4.2696, -3.2178,  0.6765,  2.3223,\n",
      "          1.7710, -3.7250,  4.0159, -3.7239, -2.1136,  0.6784,  2.3447, -1.8482,\n",
      "         -2.0159,  0.4252,  3.2205,  3.7057, -1.1160, -4.0291,  0.1815,  3.5168,\n",
      "          0.3714,  3.4733, -1.0246, -1.7917,  2.9435, -4.2575,  2.0300,  1.8572,\n",
      "         -0.3960, -3.6362,  2.6379,  1.1973, -4.7073, -2.8375, -2.1076,  3.1286,\n",
      "         -0.0340,  3.0294, -4.4234,  2.7632, -4.7938, -3.2696, -0.0474,  2.6108,\n",
      "          4.6726, -0.7084, -4.6527,  1.8097,  3.1315, -1.0451, -2.6622,  3.8328,\n",
      "         -3.3903, -0.5583,  0.0325,  2.8570,  4.2396,  1.0066,  3.7554,  0.4256,\n",
      "         -0.6239,  0.4243, -0.7868,  2.2846,  3.6746,  1.5933,  3.9523,  1.1537]])), ('fc1.bias', tensor([-0.1727, -0.0105, -0.0317])), ('fc2.weight', tensor([[-3.2546,  0.8688,  2.4636],\n",
      "        [-3.2879,  0.8775,  2.4963]])), ('fc2.bias', tensor([ 0.6884, -0.6884]))])\n",
      "[[11360     0]\n",
      " [ 3700     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     11360\n",
      "           1       0.00      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.38      0.50      0.43     15060\n",
      "weighted avg       0.57      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.7543160690571049\n",
      "test loss : 0.5494250059127808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 14000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8193, -1.7029,  2.4181, -3.2553, -3.0530,  4.0584,  2.3848,  2.1103,\n",
      "          3.5216, -3.9475, -2.0751, -2.5147,  4.4997, -1.6589,  0.9120, -0.3770,\n",
      "          3.7414, -2.9553, -3.3798,  0.2612, -1.4036, -3.3181,  4.9157, -4.7935,\n",
      "          2.7108, -1.8203,  0.2929,  2.6816,  1.9829, -4.4956, -3.7244,  2.5924,\n",
      "          2.9911, -1.7336, -2.9925,  0.4638, -4.3535,  1.0019, -1.6979, -2.5638,\n",
      "         -0.4132,  4.7825, -0.4803, -1.5686, -0.2705,  0.7053, -2.2629, -1.1160,\n",
      "         -2.3740, -1.2264,  3.9090,  3.5827, -1.4650,  3.9342, -3.0076, -4.8089,\n",
      "         -0.8035,  4.7512,  0.3316,  3.4535, -2.4947, -1.3418, -1.9063,  2.6348,\n",
      "          2.4591, -0.6424, -3.8301,  3.2174,  4.4073, -1.0304,  4.3917,  2.5341,\n",
      "          2.7898, -2.9276, -3.2847, -1.9183,  3.1527,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5366, -1.5560, -0.7464, -4.3142,  3.7219,  2.9149,  3.1238,  2.7051,\n",
      "         -4.0072, -1.2596,  2.8166,  2.6927, -3.4885,  4.6802,  0.5114,  2.2646,\n",
      "         -0.2523,  3.6576,  3.3888,  3.0507, -2.3886, -0.8665,  1.1709,  3.6791],\n",
      "        [ 4.1893,  3.9321, -0.6009,  3.9433,  0.9141,  2.4797,  0.7035, -2.8330,\n",
      "          3.1146,  0.4549, -3.0384,  4.3005,  2.5994,  1.0059,  3.1722,  3.8760,\n",
      "          0.2671, -2.3783, -2.9785, -3.3700,  2.8059, -3.5778, -4.4501,  4.4200,\n",
      "          1.1911, -4.4384, -4.7819, -2.5357, -1.4051,  3.5207,  1.3087,  4.6627,\n",
      "         -2.7811, -0.1462, -0.0286, -3.6828,  3.9957,  2.1570,  2.8343, -2.7812,\n",
      "         -3.6283, -0.4736, -3.4004, -4.5149, -0.4200, -4.0767,  4.5275, -2.5982,\n",
      "         -4.4674,  3.5104,  2.8502, -3.1861, -2.5802,  2.9493, -4.1196,  0.5705,\n",
      "          4.7508, -2.0760, -1.2337,  1.7095,  1.0065,  2.2657, -5.0171,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0611,  4.4274, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7043,  2.0986, -4.8265, -1.8526,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2081,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8855,\n",
      "          0.8302, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4558,  3.9828,\n",
      "          2.2176,  0.5732,  3.4012,  0.2047, -0.1507,  4.8576, -4.8962,  2.9687],\n",
      "        [-4.6185,  2.7546,  1.6618,  4.4893,  2.5710, -1.7486, -2.5855, -3.9557,\n",
      "          2.3930, -4.8263,  3.9383, -4.5387,  4.3887, -0.0857,  1.6575, -3.0674,\n",
      "          1.2844,  2.0370, -4.0761,  3.1364, -2.3522,  4.3861, -1.6216,  4.0174,\n",
      "         -4.2838, -1.7920,  4.2470,  3.2810,  1.0962, -0.4239, -2.7109,  2.9038,\n",
      "         -1.7967,  3.7927, -4.8268,  0.0493,  4.2683, -3.2178,  0.6757,  2.3233,\n",
      "          1.7707, -3.7254,  4.0155, -3.7245, -2.1137,  0.6793,  2.3448, -1.8483,\n",
      "         -2.0160,  0.4249,  3.2227,  3.7029, -1.1162, -4.0304,  0.1809,  3.5170,\n",
      "          0.3713,  3.4730, -1.0249, -1.7918,  2.9418, -4.2589,  2.0290,  1.8572,\n",
      "         -0.3961, -3.6362,  2.6379,  1.1973, -4.7074, -2.8375, -2.1076,  3.1286,\n",
      "         -0.0340,  3.0294, -4.4234,  2.7630, -4.7938, -3.2696, -0.0474,  2.6108,\n",
      "          4.6726, -0.7084, -4.6527,  1.8096,  3.1315, -1.0451, -2.6622,  3.8328,\n",
      "         -3.3905, -0.5583,  0.0325,  2.8570,  4.2395,  1.0066,  3.7553,  0.4255,\n",
      "         -0.6239,  0.4244, -0.7868,  2.2846,  3.6746,  1.5918,  3.9523,  1.1537]])), ('fc1.bias', tensor([-0.1739, -0.0122, -0.0342])), ('fc2.weight', tensor([[-3.2794,  0.8728,  2.4816],\n",
      "        [-3.2631,  0.8735,  2.4783]])), ('fc2.bias', tensor([ 0.7123, -0.7123]))])\n",
      "[[11360     0]\n",
      " [ 3700     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     11360\n",
      "           1       0.00      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.38      0.50      0.43     15060\n",
      "weighted avg       0.57      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.7543160690571049\n",
      "test loss : 0.5614594221115112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 15000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8191, -1.7030,  2.4178, -3.2552, -3.0529,  4.0581,  2.3848,  2.1105,\n",
      "          3.5198, -3.9473, -2.0753, -2.5147,  4.4996, -1.6590,  0.9118, -0.3771,\n",
      "          3.7413, -2.9553, -3.3799,  0.2612, -1.4035, -3.3182,  4.9164, -4.7934,\n",
      "          2.7090, -1.8199,  0.2929,  2.6818,  1.9822, -4.4958, -3.7244,  2.5936,\n",
      "          2.9909, -1.7358, -2.9925,  0.4637, -4.3538,  1.0019, -1.6983, -2.5632,\n",
      "         -0.4136,  4.7821, -0.4810, -1.5691, -0.2705,  0.7060, -2.2630, -1.1160,\n",
      "         -2.3739, -1.2264,  3.9100,  3.5811, -1.4651,  3.9331, -3.0077, -4.8087,\n",
      "         -0.8036,  4.7511,  0.3311,  3.4534, -2.4955, -1.3427, -1.9070,  2.6348,\n",
      "          2.4591, -0.6423, -3.8301,  3.2174,  4.4072, -1.0304,  4.3917,  2.5342,\n",
      "          2.7898, -2.9276, -3.2847, -1.9183,  3.1526,  2.6810,  0.6493,  1.4864,\n",
      "         -2.5366, -1.5560, -0.7465, -4.3142,  3.7219,  2.9148,  3.1238,  2.7051,\n",
      "         -4.0073, -1.2596,  2.8166,  2.6927, -3.4886,  4.6802,  0.5114,  2.2646,\n",
      "         -0.2523,  3.6576,  3.3888,  3.0507, -2.3886, -0.8677,  1.1709,  3.6791],\n",
      "        [ 4.1887,  3.9320, -0.6020,  3.9432,  0.9141,  2.4790,  0.7033, -2.8331,\n",
      "          3.1139,  0.4547, -3.0385,  4.3003,  2.5995,  1.0059,  3.1722,  3.8760,\n",
      "          0.2671, -2.3783, -2.9785, -3.3700,  2.8057, -3.5779, -4.4504,  4.4198,\n",
      "          1.1908, -4.4385, -4.7819, -2.5358, -1.4055,  3.5207,  1.3086,  4.6609,\n",
      "         -2.7811, -0.1460, -0.0286, -3.6827,  3.9954,  2.1570,  2.8341, -2.7817,\n",
      "         -3.6283, -0.4736, -3.4004, -4.5147, -0.4201, -4.0772,  4.5275, -2.5983,\n",
      "         -4.4674,  3.5104,  2.8486, -3.1861, -2.5801,  2.9494, -4.1195,  0.5702,\n",
      "          4.7507, -2.0760, -1.2340,  1.7095,  1.0053,  2.2656, -5.0184,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0611,  4.4274, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7043,  2.0986, -4.8265, -1.8526,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2080,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8855,\n",
      "          0.8301, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4558,  3.9828,\n",
      "          2.2176,  0.5732,  3.4012,  0.2047, -0.1507,  4.8561, -4.8962,  2.9687],\n",
      "        [-4.6183,  2.7543,  1.6611,  4.4895,  2.5711, -1.7492, -2.5856, -3.9553,\n",
      "          2.3899, -4.8258,  3.9381, -4.5387,  4.3887, -0.0859,  1.6572, -3.0675,\n",
      "          1.2844,  2.0369, -4.0762,  3.1362, -2.3521,  4.3858, -1.6209,  4.0177,\n",
      "         -4.2858, -1.7915,  4.2470,  3.2811,  1.0952, -0.4244, -2.7109,  2.9052,\n",
      "         -1.7967,  3.7894, -4.8268,  0.0492,  4.2673, -3.2178,  0.6747,  2.3240,\n",
      "          1.7701, -3.7256,  4.0145, -3.7250, -2.1137,  0.6801,  2.3449, -1.8481,\n",
      "         -2.0159,  0.4246,  3.2240,  3.7004, -1.1164, -4.0315,  0.1806,  3.5171,\n",
      "          0.3713,  3.4728, -1.0253, -1.7918,  2.9399, -4.2601,  2.0276,  1.8572,\n",
      "         -0.3961, -3.6362,  2.6378,  1.1973, -4.7074, -2.8375, -2.1076,  3.1287,\n",
      "         -0.0340,  3.0293, -4.4234,  2.7630, -4.7938, -3.2696, -0.0474,  2.6108,\n",
      "          4.6727, -0.7084, -4.6527,  1.8096,  3.1315, -1.0451, -2.6622,  3.8327,\n",
      "         -3.3906, -0.5583,  0.0325,  2.8570,  4.2394,  1.0066,  3.7553,  0.4254,\n",
      "         -0.6239,  0.4244, -0.7868,  2.2846,  3.6746,  1.5895,  3.9523,  1.1537]])), ('fc1.bias', tensor([-0.1754, -0.0137, -0.0368])), ('fc2.weight', tensor([[-3.2988,  0.8960,  2.4555],\n",
      "        [-3.2437,  0.8503,  2.5044]])), ('fc2.bias', tensor([ 0.7375, -0.7375]))])\n",
      "[[11330    30]\n",
      " [ 3680    20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     11360\n",
      "           1       0.40      0.01      0.01      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.58      0.50      0.43     15060\n",
      "weighted avg       0.67      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.7536520584329349\n",
      "test loss : 0.5399641990661621\n",
      "step : 16000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8183, -1.7033,  2.4176, -3.2550, -3.0527,  4.0577,  2.3852,  2.1106,\n",
      "          3.5166, -3.9469, -2.0749, -2.5147,  4.4996, -1.6591,  0.9115, -0.3772,\n",
      "          3.7413, -2.9553, -3.3799,  0.2609, -1.4034, -3.3183,  4.9178, -4.7933,\n",
      "          2.7073, -1.8195,  0.2928,  2.6822,  1.9806, -4.4961, -3.7244,  2.5967,\n",
      "          2.9908, -1.7401, -2.9927,  0.4636, -4.3542,  1.0019, -1.6986, -2.5623,\n",
      "         -0.4138,  4.7813, -0.4818, -1.5699, -0.2706,  0.7064, -2.2630, -1.1160,\n",
      "         -2.3738, -1.2263,  3.9128,  3.5785, -1.4652,  3.9308, -3.0078, -4.8082,\n",
      "         -0.8035,  4.7512,  0.3306,  3.4533, -2.4970, -1.3441, -1.9074,  2.6348,\n",
      "          2.4590, -0.6423, -3.8301,  3.2173,  4.4072, -1.0304,  4.3916,  2.5342,\n",
      "          2.7898, -2.9276, -3.2847, -1.9183,  3.1526,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5367, -1.5558, -0.7465, -4.3142,  3.7220,  2.9148,  3.1238,  2.7051,\n",
      "         -4.0074, -1.2596,  2.8166,  2.6927, -3.4885,  4.6803,  0.5114,  2.2646,\n",
      "         -0.2523,  3.6577,  3.3889,  3.0507, -2.3886, -0.8693,  1.1708,  3.6791],\n",
      "        [ 4.1877,  3.9318, -0.6036,  3.9430,  0.9138,  2.4781,  0.7030, -2.8334,\n",
      "          3.1140,  0.4541, -3.0386,  4.3002,  2.5995,  1.0060,  3.1725,  3.8761,\n",
      "          0.2672, -2.3783, -2.9785, -3.3697,  2.8055, -3.5779, -4.4518,  4.4195,\n",
      "          1.1910, -4.4389, -4.7818, -2.5359, -1.4053,  3.5210,  1.3086,  4.6572,\n",
      "         -2.7811, -0.1441, -0.0286, -3.6826,  3.9956,  2.1570,  2.8340, -2.7826,\n",
      "         -3.6282, -0.4732, -3.4001, -4.5143, -0.4201, -4.0781,  4.5274, -2.5985,\n",
      "         -4.4677,  3.5101,  2.8454, -3.1852, -2.5800,  2.9505, -4.1191,  0.5697,\n",
      "          4.7507, -2.0762, -1.2338,  1.7095,  1.0039,  2.2664, -5.0205,  1.8395,\n",
      "          3.3683, -4.9486,  0.1193, -2.0611,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7043,  2.0986, -4.8265, -1.8526,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2080,  3.7505,  2.5495, -2.1632, -2.2137,  1.7909, -0.8855,\n",
      "          0.8302, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4558,  3.9828,\n",
      "          2.2176,  0.5731,  3.4012,  0.2047, -0.1507,  4.8547, -4.8962,  2.9687],\n",
      "        [-4.6180,  2.7540,  1.6605,  4.4897,  2.5713, -1.7500, -2.5854, -3.9552,\n",
      "          2.3860, -4.8251,  3.9382, -4.5387,  4.3887, -0.0861,  1.6568, -3.0676,\n",
      "          1.2844,  2.0368, -4.0764,  3.1357, -2.3520,  4.3853, -1.6199,  4.0180,\n",
      "         -4.2872, -1.7910,  4.2470,  3.2814,  1.0936, -0.4248, -2.7109,  2.9077,\n",
      "         -1.7968,  3.7848, -4.8270,  0.0492,  4.2667, -3.2178,  0.6739,  2.3247,\n",
      "          1.7699, -3.7262,  4.0137, -3.7256, -2.1137,  0.6805,  2.3447, -1.8481,\n",
      "         -2.0159,  0.4245,  3.2260,  3.6974, -1.1166, -4.0333,  0.1803,  3.5177,\n",
      "          0.3713,  3.4729, -1.0257, -1.7919,  2.9375, -4.2612,  2.0259,  1.8572,\n",
      "         -0.3962, -3.6362,  2.6378,  1.1972, -4.7074, -2.8374, -2.1077,  3.1287,\n",
      "         -0.0340,  3.0293, -4.4234,  2.7630, -4.7938, -3.2696, -0.0474,  2.6108,\n",
      "          4.6726, -0.7083, -4.6527,  1.8096,  3.1316, -1.0451, -2.6622,  3.8327,\n",
      "         -3.3908, -0.5584,  0.0325,  2.8570,  4.2394,  1.0066,  3.7553,  0.4254,\n",
      "         -0.6239,  0.4244, -0.7868,  2.2846,  3.6746,  1.5872,  3.9523,  1.1537]])), ('fc1.bias', tensor([-0.1773, -0.0150, -0.0396])), ('fc2.weight', tensor([[-3.3008,  0.8702,  2.4720],\n",
      "        [-3.2418,  0.8761,  2.4879]])), ('fc2.bias', tensor([ 0.7685, -0.7685]))])\n",
      "[[11358     2]\n",
      " [ 3700     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     11360\n",
      "           1       0.00      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.38      0.50      0.43     15060\n",
      "weighted avg       0.57      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.7541832669322709\n",
      "test loss : 0.53653883934021\n",
      "step : 17000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8183, -1.7034,  2.4173, -3.2550, -3.0526,  4.0573,  2.3853,  2.1106,\n",
      "          3.5151, -3.9467, -2.0749, -2.5147,  4.4996, -1.6592,  0.9113, -0.3771,\n",
      "          3.7413, -2.9553, -3.3800,  0.2608, -1.4034, -3.3182,  4.9182, -4.7932,\n",
      "          2.7061, -1.8191,  0.2928,  2.6824,  1.9797, -4.4962, -3.7244,  2.5976,\n",
      "          2.9908, -1.7421, -2.9927,  0.4635, -4.3546,  1.0019, -1.6988, -2.5618,\n",
      "         -0.4139,  4.7808, -0.4822, -1.5702, -0.2706,  0.7068, -2.2630, -1.1161,\n",
      "         -2.3739, -1.2263,  3.9136,  3.5771, -1.4652,  3.9301, -3.0079, -4.8081,\n",
      "         -0.8035,  4.7510,  0.3304,  3.4532, -2.4979, -1.3450, -1.9079,  2.6348,\n",
      "          2.4591, -0.6423, -3.8301,  3.2174,  4.4071, -1.0304,  4.3915,  2.5342,\n",
      "          2.7898, -2.9276, -3.2847, -1.9183,  3.1526,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5367, -1.5558, -0.7465, -4.3142,  3.7220,  2.9148,  3.1238,  2.7051,\n",
      "         -4.0075, -1.2596,  2.8166,  2.6927, -3.4885,  4.6803,  0.5114,  2.2646,\n",
      "         -0.2523,  3.6577,  3.3889,  3.0507, -2.3886, -0.8705,  1.1708,  3.6790],\n",
      "        [ 4.1869,  3.9316, -0.6049,  3.9429,  0.9137,  2.4774,  0.7029, -2.8336,\n",
      "          3.1132,  0.4538, -3.0388,  4.3002,  2.5995,  1.0060,  3.1725,  3.8760,\n",
      "          0.2672, -2.3782, -2.9784, -3.3697,  2.8054, -3.5779, -4.4523,  4.4195,\n",
      "          1.1906, -4.4394, -4.7818, -2.5361, -1.4053,  3.5212,  1.3086,  4.6549,\n",
      "         -2.7811, -0.1438, -0.0285, -3.6826,  3.9953,  2.1570,  2.8337, -2.7830,\n",
      "         -3.6283, -0.4734, -3.4000, -4.5141, -0.4201, -4.0786,  4.5274, -2.5987,\n",
      "         -4.4676,  3.5101,  2.8436, -3.1848, -2.5800,  2.9506, -4.1189,  0.5692,\n",
      "          4.7507, -2.0763, -1.2338,  1.7096,  1.0024,  2.2663, -5.0220,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0612,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7043,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2080,  3.7505,  2.5495, -2.1632, -2.2137,  1.7909, -0.8855,\n",
      "          0.8303, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4558,  3.9829,\n",
      "          2.2176,  0.5731,  3.4012,  0.2047, -0.1507,  4.8532, -4.8962,  2.9688],\n",
      "        [-4.6178,  2.7536,  1.6597,  4.4900,  2.5716, -1.7508, -2.5851, -3.9554,\n",
      "          2.3822, -4.8244,  3.9379, -4.5387,  4.3887, -0.0864,  1.6564, -3.0677,\n",
      "          1.2842,  2.0367, -4.0766,  3.1354, -2.3517,  4.3851, -1.6190,  4.0181,\n",
      "         -4.2891, -1.7902,  4.2470,  3.2817,  1.0915, -0.4258, -2.7108,  2.9104,\n",
      "         -1.7969,  3.7802, -4.8272,  0.0490,  4.2659, -3.2178,  0.6728,  2.3262,\n",
      "          1.7693, -3.7269,  4.0126, -3.7264, -2.1138,  0.6808,  2.3447, -1.8480,\n",
      "         -2.0158,  0.4246,  3.2282,  3.6937, -1.1170, -4.0346,  0.1797,  3.5183,\n",
      "          0.3712,  3.4727, -1.0259, -1.7919,  2.9347, -4.2630,  2.0244,  1.8572,\n",
      "         -0.3962, -3.6362,  2.6378,  1.1973, -4.7075, -2.8375, -2.1078,  3.1286,\n",
      "         -0.0340,  3.0293, -4.4234,  2.7630, -4.7938, -3.2696, -0.0475,  2.6108,\n",
      "          4.6726, -0.7083, -4.6528,  1.8096,  3.1317, -1.0451, -2.6622,  3.8327,\n",
      "         -3.3911, -0.5584,  0.0325,  2.8570,  4.2394,  1.0066,  3.7553,  0.4254,\n",
      "         -0.6239,  0.4244, -0.7868,  2.2846,  3.6746,  1.5846,  3.9522,  1.1536]])), ('fc1.bias', tensor([-0.1787, -0.0166, -0.0429])), ('fc2.weight', tensor([[-3.2933,  0.8875,  2.4640],\n",
      "        [-3.2492,  0.8588,  2.4959]])), ('fc2.bias', tensor([ 0.8009, -0.8009]))])\n",
      "[[11360     0]\n",
      " [ 3700     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     11360\n",
      "           1       0.00      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.38      0.50      0.43     15060\n",
      "weighted avg       0.57      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.7543160690571049\n",
      "test loss : 0.5455670356750488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 18000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8181, -1.7035,  2.4168, -3.2548, -3.0526,  4.0570,  2.3854,  2.1106,\n",
      "          3.5136, -3.9467, -2.0747, -2.5147,  4.4996, -1.6593,  0.9112, -0.3771,\n",
      "          3.7412, -2.9552, -3.3800,  0.2608, -1.4033, -3.3182,  4.9182, -4.7932,\n",
      "          2.7054, -1.8192,  0.2928,  2.6827,  1.9792, -4.4962, -3.7244,  2.5981,\n",
      "          2.9907, -1.7435, -2.9928,  0.4635, -4.3547,  1.0019, -1.6987, -2.5620,\n",
      "         -0.4141,  4.7806, -0.4825, -1.5706, -0.2707,  0.7071, -2.2630, -1.1162,\n",
      "         -2.3739, -1.2265,  3.9141,  3.5763, -1.4653,  3.9295, -3.0079, -4.8081,\n",
      "         -0.8036,  4.7510,  0.3300,  3.4532, -2.4984, -1.3456, -1.9083,  2.6348,\n",
      "          2.4591, -0.6423, -3.8302,  3.2174,  4.4071, -1.0304,  4.3915,  2.5342,\n",
      "          2.7898, -2.9276, -3.2847, -1.9183,  3.1526,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5367, -1.5559, -0.7464, -4.3142,  3.7220,  2.9148,  3.1238,  2.7051,\n",
      "         -4.0075, -1.2596,  2.8166,  2.6927, -3.4886,  4.6803,  0.5114,  2.2646,\n",
      "         -0.2523,  3.6577,  3.3889,  3.0507, -2.3886, -0.8714,  1.1708,  3.6790],\n",
      "        [ 4.1863,  3.9314, -0.6060,  3.9428,  0.9135,  2.4767,  0.7027, -2.8335,\n",
      "          3.1119,  0.4538, -3.0388,  4.3001,  2.5995,  1.0059,  3.1725,  3.8760,\n",
      "          0.2672, -2.3782, -2.9784, -3.3697,  2.8053, -3.5779, -4.4529,  4.4194,\n",
      "          1.1902, -4.4396, -4.7818, -2.5362, -1.4053,  3.5211,  1.3087,  4.6535,\n",
      "         -2.7811, -0.1437, -0.0285, -3.6825,  3.9949,  2.1570,  2.8336, -2.7833,\n",
      "         -3.6282, -0.4733, -3.3999, -4.5140, -0.4201, -4.0790,  4.5274, -2.5990,\n",
      "         -4.4677,  3.5099,  2.8424, -3.1849, -2.5800,  2.9507, -4.1190,  0.5690,\n",
      "          4.7507, -2.0763, -1.2339,  1.7095,  1.0011,  2.2659, -5.0231,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0612,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7043,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2080,  3.7505,  2.5495, -2.1632, -2.2137,  1.7909, -0.8855,\n",
      "          0.8302, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4558,  3.9829,\n",
      "          2.2176,  0.5731,  3.4012,  0.2047, -0.1507,  4.8518, -4.8962,  2.9688],\n",
      "        [-4.6172,  2.7534,  1.6594,  4.4904,  2.5718, -1.7513, -2.5849, -3.9551,\n",
      "          2.3795, -4.8239,  3.9373, -4.5387,  4.3887, -0.0866,  1.6561, -3.0677,\n",
      "          1.2841,  2.0365, -4.0766,  3.1352, -2.3518,  4.3848, -1.6179,  4.0183,\n",
      "         -4.2906, -1.7894,  4.2469,  3.2821,  1.0899, -0.4261, -2.7108,  2.9130,\n",
      "         -1.7969,  3.7758, -4.8273,  0.0490,  4.2653, -3.2178,  0.6720,  2.3268,\n",
      "          1.7687, -3.7273,  4.0118, -3.7270, -2.1139,  0.6820,  2.3447, -1.8479,\n",
      "         -2.0158,  0.4243,  3.2297,  3.6910, -1.1172, -4.0360,  0.1793,  3.5194,\n",
      "          0.3711,  3.4724, -1.0261, -1.7919,  2.9331, -4.2639,  2.0231,  1.8572,\n",
      "         -0.3963, -3.6362,  2.6377,  1.1973, -4.7075, -2.8375, -2.1078,  3.1286,\n",
      "         -0.0340,  3.0293, -4.4234,  2.7630, -4.7938, -3.2696, -0.0475,  2.6108,\n",
      "          4.6725, -0.7083, -4.6528,  1.8096,  3.1318, -1.0451, -2.6622,  3.8327,\n",
      "         -3.3914, -0.5583,  0.0325,  2.8570,  4.2394,  1.0066,  3.7553,  0.4254,\n",
      "         -0.6239,  0.4244, -0.7868,  2.2846,  3.6746,  1.5828,  3.9522,  1.1536]])), ('fc1.bias', tensor([-0.1797, -0.0180, -0.0451])), ('fc2.weight', tensor([[-3.2782,  0.8700,  2.4481],\n",
      "        [-3.2643,  0.8763,  2.5118]])), ('fc2.bias', tensor([ 0.8289, -0.8289]))])\n",
      "[[11359     1]\n",
      " [ 3696     4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     11360\n",
      "           1       0.80      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.78      0.50      0.43     15060\n",
      "weighted avg       0.77      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.7545152722443559\n",
      "test loss : 0.5287079811096191\n",
      "step : 19000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8177, -1.7036,  2.4170, -3.2547, -3.0526,  4.0571,  2.3857,  2.1107,\n",
      "          3.5117, -3.9463, -2.0745, -2.5146,  4.4996, -1.6594,  0.9111, -0.3771,\n",
      "          3.7412, -2.9552, -3.3801,  0.2607, -1.4031, -3.3183,  4.9186, -4.7931,\n",
      "          2.7039, -1.8187,  0.2928,  2.6830,  1.9789, -4.4964, -3.7244,  2.6003,\n",
      "          2.9905, -1.7460, -2.9928,  0.4634, -4.3549,  1.0019, -1.6989, -2.5616,\n",
      "         -0.4142,  4.7801, -0.4833, -1.5708, -0.2707,  0.7079, -2.2630, -1.1160,\n",
      "         -2.3737, -1.2266,  3.9161,  3.5747, -1.4655,  3.9284, -3.0080, -4.8079,\n",
      "         -0.8036,  4.7509,  0.3297,  3.4531, -2.4986, -1.3466, -1.9080,  2.6348,\n",
      "          2.4590, -0.6423, -3.8302,  3.2174,  4.4071, -1.0304,  4.3915,  2.5342,\n",
      "          2.7898, -2.9277, -3.2847, -1.9183,  3.1526,  2.6810,  0.6493,  1.4864,\n",
      "         -2.5367, -1.5559, -0.7464, -4.3142,  3.7220,  2.9148,  3.1240,  2.7051,\n",
      "         -4.0076, -1.2596,  2.8166,  2.6927, -3.4886,  4.6802,  0.5114,  2.2646,\n",
      "         -0.2522,  3.6577,  3.3889,  3.0507, -2.3886, -0.8721,  1.1708,  3.6790],\n",
      "        [ 4.1857,  3.9312, -0.6069,  3.9428,  0.9135,  2.4760,  0.7028, -2.8335,\n",
      "          3.1108,  0.4536, -3.0390,  4.3000,  2.5995,  1.0058,  3.1724,  3.8760,\n",
      "          0.2672, -2.3782, -2.9784, -3.3697,  2.8052, -3.5779, -4.4529,  4.4193,\n",
      "          1.1895, -4.4396, -4.7818, -2.5362, -1.4056,  3.5209,  1.3087,  4.6524,\n",
      "         -2.7811, -0.1440, -0.0284, -3.6825,  3.9948,  2.1570,  2.8333, -2.7838,\n",
      "         -3.6282, -0.4734, -3.4000, -4.5141, -0.4201, -4.0792,  4.5274, -2.5990,\n",
      "         -4.4675,  3.5097,  2.8412, -3.1851, -2.5800,  2.9505, -4.1190,  0.5690,\n",
      "          4.7507, -2.0763, -1.2341,  1.7095,  0.9997,  2.2658, -5.0245,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0612,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7043,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2080,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8855,\n",
      "          0.8303, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4558,  3.9828,\n",
      "          2.2176,  0.5731,  3.4012,  0.2047, -0.1507,  4.8502, -4.8962,  2.9688],\n",
      "        [-4.6170,  2.7531,  1.6590,  4.4908,  2.5719, -1.7517, -2.5846, -3.9548,\n",
      "          2.3764, -4.8232,  3.9369, -4.5385,  4.3887, -0.0870,  1.6558, -3.0678,\n",
      "          1.2841,  2.0364, -4.0766,  3.1350, -2.3518,  4.3844, -1.6177,  4.0185,\n",
      "         -4.2920, -1.7885,  4.2469,  3.2824,  1.0890, -0.4271, -2.7108,  2.9158,\n",
      "         -1.7970,  3.7720, -4.8272,  0.0490,  4.2645, -3.2178,  0.6712,  2.3272,\n",
      "          1.7684, -3.7277,  4.0110, -3.7275, -2.1139,  0.6832,  2.3445, -1.8476,\n",
      "         -2.0156,  0.4239,  3.2316,  3.6884, -1.1175, -4.0374,  0.1786,  3.5203,\n",
      "          0.3710,  3.4723, -1.0264, -1.7919,  2.9315, -4.2647,  2.0219,  1.8572,\n",
      "         -0.3963, -3.6362,  2.6377,  1.1974, -4.7075, -2.8375, -2.1078,  3.1287,\n",
      "         -0.0340,  3.0292, -4.4234,  2.7630, -4.7938, -3.2696, -0.0475,  2.6108,\n",
      "          4.6725, -0.7083, -4.6527,  1.8096,  3.1318, -1.0451, -2.6621,  3.8327,\n",
      "         -3.3914, -0.5584,  0.0325,  2.8570,  4.2394,  1.0066,  3.7553,  0.4254,\n",
      "         -0.6239,  0.4243, -0.7868,  2.2846,  3.6746,  1.5808,  3.9521,  1.1536]])), ('fc1.bias', tensor([-0.1805, -0.0196, -0.0471])), ('fc2.weight', tensor([[-3.3094,  0.8861,  2.4520],\n",
      "        [-3.2332,  0.8602,  2.5079]])), ('fc2.bias', tensor([ 0.8458, -0.8458]))])\n",
      "[[11290    70]\n",
      " [ 3627    73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86     11360\n",
      "           1       0.51      0.02      0.04      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.63      0.51      0.45     15060\n",
      "weighted avg       0.70      0.75      0.66     15060\n",
      "\n",
      "正解率 : 0.7545152722443559\n",
      "test loss : 0.5284676551818848\n",
      "step : 20000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8169, -1.7038,  2.4169, -3.2545, -3.0524,  4.0570,  2.3860,  2.1111,\n",
      "          3.5086, -3.9458, -2.0744, -2.5144,  4.4996, -1.6594,  0.9105, -0.3773,\n",
      "          3.7412, -2.9553, -3.3802,  0.2605, -1.4031, -3.3182,  4.9202, -4.7930,\n",
      "          2.7027, -1.8184,  0.2928,  2.6833,  1.9772, -4.4967, -3.7244,  2.6028,\n",
      "          2.9903, -1.7494, -2.9928,  0.4634, -4.3551,  1.0019, -1.6997, -2.5608,\n",
      "         -0.4142,  4.7794, -0.4840, -1.5720, -0.2707,  0.7088, -2.2627, -1.1160,\n",
      "         -2.3737, -1.2266,  3.9184,  3.5725, -1.4656,  3.9266, -3.0081, -4.8076,\n",
      "         -0.8036,  4.7505,  0.3292,  3.4529, -2.4991, -1.3485, -1.9079,  2.6348,\n",
      "          2.4591, -0.6424, -3.8302,  3.2174,  4.4070, -1.0304,  4.3915,  2.5342,\n",
      "          2.7898, -2.9277, -3.2847, -1.9183,  3.1527,  2.6810,  0.6493,  1.4864,\n",
      "         -2.5367, -1.5559, -0.7465, -4.3142,  3.7219,  2.9148,  3.1239,  2.7050,\n",
      "         -4.0077, -1.2596,  2.8166,  2.6927, -3.4887,  4.6802,  0.5114,  2.2646,\n",
      "         -0.2522,  3.6577,  3.3889,  3.0507, -2.3886, -0.8732,  1.1707,  3.6791],\n",
      "        [ 4.1850,  3.9310, -0.6081,  3.9427,  0.9133,  2.4753,  0.7026, -2.8337,\n",
      "          3.1098,  0.4534, -3.0390,  4.2998,  2.5995,  1.0058,  3.1725,  3.8760,\n",
      "          0.2672, -2.3782, -2.9784, -3.3696,  2.8051, -3.5779, -4.4537,  4.4194,\n",
      "          1.1887, -4.4397, -4.7818, -2.5364, -1.4056,  3.5211,  1.3087,  4.6504,\n",
      "         -2.7811, -0.1439, -0.0284, -3.6825,  3.9945,  2.1570,  2.8331, -2.7842,\n",
      "         -3.6282, -0.4734, -3.4000, -4.5141, -0.4201, -4.0796,  4.5273, -2.5992,\n",
      "         -4.4674,  3.5095,  2.8395, -3.1848, -2.5800,  2.9505, -4.1189,  0.5688,\n",
      "          4.7506, -2.0763, -1.2340,  1.7096,  0.9981,  2.2657, -5.0261,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0612,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7043,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2080,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8855,\n",
      "          0.8303, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4558,  3.9828,\n",
      "          2.2176,  0.5731,  3.4012,  0.2047, -0.1507,  4.8486, -4.8962,  2.9687],\n",
      "        [-4.6163,  2.7529,  1.6589,  4.4911,  2.5721, -1.7520, -2.5842, -3.9542,\n",
      "          2.3726, -4.8223,  3.9366, -4.5383,  4.3887, -0.0871,  1.6550, -3.0679,\n",
      "          1.2841,  2.0363, -4.0768,  3.1347, -2.3519,  4.3843, -1.6162,  4.0188,\n",
      "         -4.2933, -1.7879,  4.2469,  3.2827,  1.0874, -0.4277, -2.7108,  2.9180,\n",
      "         -1.7970,  3.7684, -4.8272,  0.0488,  4.2638, -3.2178,  0.6700,  2.3285,\n",
      "          1.7683, -3.7282,  4.0100, -3.7285, -2.1139,  0.6842,  2.3447, -1.8477,\n",
      "         -2.0156,  0.4239,  3.2332,  3.6861, -1.1176, -4.0390,  0.1783,  3.5208,\n",
      "          0.3709,  3.4719, -1.0266, -1.7921,  2.9303, -4.2661,  2.0211,  1.8572,\n",
      "         -0.3963, -3.6362,  2.6377,  1.1974, -4.7075, -2.8375, -2.1078,  3.1287,\n",
      "         -0.0339,  3.0293, -4.4233,  2.7629, -4.7937, -3.2696, -0.0475,  2.6108,\n",
      "          4.6725, -0.7083, -4.6527,  1.8096,  3.1317, -1.0451, -2.6621,  3.8327,\n",
      "         -3.3917, -0.5584,  0.0325,  2.8570,  4.2393,  1.0066,  3.7553,  0.4254,\n",
      "         -0.6239,  0.4243, -0.7868,  2.2846,  3.6746,  1.5792,  3.9520,  1.1537]])), ('fc1.bias', tensor([-0.1821, -0.0212, -0.0493])), ('fc2.weight', tensor([[-3.2936,  0.8703,  2.4106],\n",
      "        [-3.2489,  0.8759,  2.5493]])), ('fc2.bias', tensor([ 0.8622, -0.8622]))])\n",
      "[[7641 3719]\n",
      " [1550 2150]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.67      0.74     11360\n",
      "           1       0.37      0.58      0.45      3700\n",
      "\n",
      "    accuracy                           0.65     15060\n",
      "   macro avg       0.60      0.63      0.60     15060\n",
      "weighted avg       0.72      0.65      0.67     15060\n",
      "\n",
      "正解率 : 0.650132802124834\n",
      "test loss : 0.607919454574585\n",
      "step : 21000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8167, -1.7040,  2.4166, -3.2544, -3.0522,  4.0567,  2.3862,  2.1113,\n",
      "          3.5066, -3.9457, -2.0742, -2.5142,  4.4996, -1.6595,  0.9103, -0.3774,\n",
      "          3.7412, -2.9553, -3.3802,  0.2605, -1.4030, -3.3183,  4.9209, -4.7930,\n",
      "          2.7017, -1.8180,  0.2928,  2.6833,  1.9766, -4.4969, -3.7244,  2.6043,\n",
      "          2.9903, -1.7518, -2.9929,  0.4633, -4.3554,  1.0019, -1.6999, -2.5602,\n",
      "         -0.4144,  4.7789, -0.4846, -1.5725, -0.2707,  0.7091, -2.2626, -1.1161,\n",
      "         -2.3735, -1.2268,  3.9197,  3.5711, -1.4657,  3.9254, -3.0082, -4.8074,\n",
      "         -0.8036,  4.7504,  0.3289,  3.4528, -2.4999, -1.3493, -1.9083,  2.6348,\n",
      "          2.4591, -0.6424, -3.8302,  3.2174,  4.4070, -1.0304,  4.3915,  2.5342,\n",
      "          2.7898, -2.9277, -3.2847, -1.9184,  3.1526,  2.6810,  0.6493,  1.4864,\n",
      "         -2.5367, -1.5559, -0.7465, -4.3141,  3.7219,  2.9148,  3.1240,  2.7050,\n",
      "         -4.0078, -1.2596,  2.8166,  2.6927, -3.4887,  4.6802,  0.5114,  2.2646,\n",
      "         -0.2522,  3.6577,  3.3889,  3.0506, -2.3886, -0.8741,  1.1707,  3.6791],\n",
      "        [ 4.1845,  3.9308, -0.6091,  3.9427,  0.9132,  2.4745,  0.7027, -2.8337,\n",
      "          3.1084,  0.4535, -3.0392,  4.2996,  2.5995,  1.0058,  3.1723,  3.8760,\n",
      "          0.2671, -2.3782, -2.9784, -3.3696,  2.8051, -3.5778, -4.4540,  4.4193,\n",
      "          1.1881, -4.4397, -4.7818, -2.5364, -1.4061,  3.5210,  1.3087,  4.6490,\n",
      "         -2.7811, -0.1441, -0.0284, -3.6825,  3.9941,  2.1570,  2.8327, -2.7846,\n",
      "         -3.6282, -0.4734, -3.3999, -4.5141, -0.4201, -4.0798,  4.5273, -2.5994,\n",
      "         -4.4675,  3.5094,  2.8383, -3.1848, -2.5800,  2.9504, -4.1190,  0.5686,\n",
      "          4.7505, -2.0764, -1.2342,  1.7095,  0.9968,  2.2654, -5.0274,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0612,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3002,  1.7043,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2080,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8855,\n",
      "          0.8303, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4558,  3.9828,\n",
      "          2.2176,  0.5731,  3.4012,  0.2047, -0.1507,  4.8470, -4.8962,  2.9688],\n",
      "        [-4.6162,  2.7524,  1.6583,  4.4914,  2.5723, -1.7528, -2.5839, -3.9539,\n",
      "          2.3685, -4.8217,  3.9364, -4.5380,  4.3886, -0.0875,  1.6543, -3.0681,\n",
      "          1.2840,  2.0362, -4.0769,  3.1346, -2.3520,  4.3842, -1.6154,  4.0191,\n",
      "         -4.2942, -1.7872,  4.2469,  3.2830,  1.0853, -0.4288, -2.7108,  2.9209,\n",
      "         -1.7970,  3.7642, -4.8273,  0.0486,  4.2629, -3.2178,  0.6696,  2.3296,\n",
      "          1.7678, -3.7286,  4.0090, -3.7291, -2.1140,  0.6848,  2.3447, -1.8477,\n",
      "         -2.0156,  0.4235,  3.2350,  3.6832, -1.1178, -4.0407,  0.1776,  3.5220,\n",
      "          0.3708,  3.4718, -1.0270, -1.7922,  2.9283, -4.2670,  2.0193,  1.8572,\n",
      "         -0.3962, -3.6362,  2.6376,  1.1974, -4.7075, -2.8375, -2.1078,  3.1287,\n",
      "         -0.0339,  3.0293, -4.4233,  2.7628, -4.7937, -3.2696, -0.0475,  2.6108,\n",
      "          4.6725, -0.7084, -4.6527,  1.8096,  3.1317, -1.0451, -2.6620,  3.8327,\n",
      "         -3.3918, -0.5584,  0.0325,  2.8570,  4.2393,  1.0066,  3.7551,  0.4254,\n",
      "         -0.6239,  0.4243, -0.7867,  2.2845,  3.6746,  1.5770,  3.9520,  1.1536]])), ('fc1.bias', tensor([-0.1833, -0.0229, -0.0520])), ('fc2.weight', tensor([[-3.2572,  0.8761,  2.4584],\n",
      "        [-3.2853,  0.8702,  2.5015]])), ('fc2.bias', tensor([ 0.8855, -0.8855]))])\n",
      "[[11360     0]\n",
      " [ 3700     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     11360\n",
      "           1       0.00      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.38      0.50      0.43     15060\n",
      "weighted avg       0.57      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.7543160690571049\n",
      "test loss : 0.5600621104240417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 22000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8162, -1.7042,  2.4166, -3.2542, -3.0521,  4.0566,  2.3866,  2.1114,\n",
      "          3.5047, -3.9455, -2.0743, -2.5141,  4.4996, -1.6597,  0.9100, -0.3775,\n",
      "          3.7412, -2.9553, -3.3803,  0.2604, -1.4028, -3.3182,  4.9212, -4.7929,\n",
      "          2.7005, -1.8177,  0.2928,  2.6838,  1.9759, -4.4968, -3.7244,  2.6061,\n",
      "          2.9902, -1.7545, -2.9930,  0.4632, -4.3555,  1.0019, -1.7000, -2.5597,\n",
      "         -0.4145,  4.7784, -0.4850, -1.5728, -0.2707,  0.7098, -2.2627, -1.1163,\n",
      "         -2.3736, -1.2271,  3.9213,  3.5695, -1.4659,  3.9243, -3.0082, -4.8073,\n",
      "         -0.8037,  4.7503,  0.3288,  3.4528, -2.5008, -1.3503, -1.9083,  2.6348,\n",
      "          2.4591, -0.6424, -3.8302,  3.2174,  4.4070, -1.0304,  4.3915,  2.5343,\n",
      "          2.7899, -2.9276, -3.2847, -1.9184,  3.1526,  2.6810,  0.6493,  1.4864,\n",
      "         -2.5367, -1.5560, -0.7465, -4.3141,  3.7218,  2.9148,  3.1240,  2.7051,\n",
      "         -4.0080, -1.2596,  2.8166,  2.6927, -3.4886,  4.6802,  0.5114,  2.2646,\n",
      "         -0.2522,  3.6576,  3.3889,  3.0506, -2.3886, -0.8747,  1.1706,  3.6791],\n",
      "        [ 4.1837,  3.9306, -0.6104,  3.9425,  0.9131,  2.4737,  0.7024, -2.8340,\n",
      "          3.1080,  0.4533, -3.0392,  4.2994,  2.5995,  1.0058,  3.1724,  3.8760,\n",
      "          0.2672, -2.3781, -2.9784, -3.3696,  2.8050, -3.5779, -4.4545,  4.4191,\n",
      "          1.1879, -4.4400, -4.7818, -2.5367, -1.4061,  3.5210,  1.3086,  4.6467,\n",
      "         -2.7811, -0.1433, -0.0284, -3.6825,  3.9941,  2.1570,  2.8325, -2.7851,\n",
      "         -3.6282, -0.4732, -3.3998, -4.5140, -0.4201, -4.0805,  4.5272, -2.5996,\n",
      "         -4.4675,  3.5094,  2.8361, -3.1844, -2.5799,  2.9507, -4.1189,  0.5685,\n",
      "          4.7506, -2.0763, -1.2343,  1.7095,  0.9954,  2.2658, -5.0293,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0612,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3001,  1.7042,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2080,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8856,\n",
      "          0.8304, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4558,  3.9828,\n",
      "          2.2176,  0.5731,  3.4012,  0.2047, -0.1507,  4.8456, -4.8962,  2.9688],\n",
      "        [-4.6151,  2.7521,  1.6580,  4.4919,  2.5726, -1.7533, -2.5832, -3.9537,\n",
      "          2.3639, -4.8208,  3.9359, -4.5378,  4.3886, -0.0878,  1.6538, -3.0682,\n",
      "          1.2840,  2.0360, -4.0770,  3.1344, -2.3521,  4.3839, -1.6149,  4.0196,\n",
      "         -4.2959, -1.7855,  4.2468,  3.2836,  1.0827, -0.4293, -2.7108,  2.9252,\n",
      "         -1.7971,  3.7576, -4.8274,  0.0483,  4.2615, -3.2178,  0.6687,  2.3312,\n",
      "          1.7674, -3.7294,  4.0081, -3.7301, -2.1141,  0.6866,  2.3444, -1.8479,\n",
      "         -2.0157,  0.4229,  3.2389,  3.6791, -1.1182, -4.0430,  0.1766,  3.5226,\n",
      "          0.3708,  3.4718, -1.0271, -1.7923,  2.9253, -4.2696,  2.0188,  1.8571,\n",
      "         -0.3962, -3.6362,  2.6376,  1.1973, -4.7075, -2.8375, -2.1078,  3.1287,\n",
      "         -0.0340,  3.0293, -4.4233,  2.7628, -4.7937, -3.2696, -0.0475,  2.6108,\n",
      "          4.6725, -0.7084, -4.6528,  1.8096,  3.1316, -1.0451, -2.6620,  3.8327,\n",
      "         -3.3922, -0.5584,  0.0325,  2.8570,  4.2394,  1.0066,  3.7551,  0.4254,\n",
      "         -0.6239,  0.4243, -0.7867,  2.2845,  3.6746,  1.5743,  3.9520,  1.1536]])), ('fc1.bias', tensor([-0.1844, -0.0243, -0.0551])), ('fc2.weight', tensor([[-3.3125,  0.8879,  2.4266],\n",
      "        [-3.2300,  0.8583,  2.5333]])), ('fc2.bias', tensor([ 0.9061, -0.9061]))])\n",
      "[[10032  1328]\n",
      " [ 2724   976]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83     11360\n",
      "           1       0.42      0.26      0.33      3700\n",
      "\n",
      "    accuracy                           0.73     15060\n",
      "   macro avg       0.61      0.57      0.58     15060\n",
      "weighted avg       0.70      0.73      0.71     15060\n",
      "\n",
      "正解率 : 0.7309428950863214\n",
      "test loss : 0.5398151278495789\n",
      "step : 23000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8159, -1.7044,  2.4164, -3.2541, -3.0520,  4.0564,  2.3868,  2.1114,\n",
      "          3.5025, -3.9452, -2.0742, -2.5138,  4.4996, -1.6597,  0.9097, -0.3775,\n",
      "          3.7412, -2.9553, -3.3803,  0.2603, -1.4027, -3.3184,  4.9217, -4.7929,\n",
      "          2.6994, -1.8173,  0.2927,  2.6840,  1.9753, -4.4968, -3.7244,  2.6076,\n",
      "          2.9901, -1.7571, -2.9931,  0.4631, -4.3558,  1.0019, -1.7001, -2.5595,\n",
      "         -0.4148,  4.7778, -0.4854, -1.5733, -0.2708,  0.7103, -2.2627, -1.1159,\n",
      "         -2.3737, -1.2272,  3.9228,  3.5679, -1.4659,  3.9231, -3.0083, -4.8072,\n",
      "         -0.8037,  4.7502,  0.3285,  3.4527, -2.5016, -1.3515, -1.9085,  2.6348,\n",
      "          2.4591, -0.6424, -3.8302,  3.2174,  4.4070, -1.0304,  4.3914,  2.5343,\n",
      "          2.7899, -2.9276, -3.2847, -1.9184,  3.1526,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5367, -1.5560, -0.7465, -4.3141,  3.7218,  2.9148,  3.1240,  2.7051,\n",
      "         -4.0081, -1.2597,  2.8166,  2.6927, -3.4887,  4.6802,  0.5113,  2.2645,\n",
      "         -0.2522,  3.6576,  3.3889,  3.0506, -2.3886, -0.8756,  1.1706,  3.6791],\n",
      "        [ 4.1831,  3.9304, -0.6114,  3.9424,  0.9129,  2.4730,  0.7024, -2.8341,\n",
      "          3.1074,  0.4532, -3.0395,  4.2991,  2.5995,  1.0057,  3.1724,  3.8760,\n",
      "          0.2672, -2.3781, -2.9783, -3.3696,  2.8048, -3.5780, -4.4549,  4.4190,\n",
      "          1.1878, -4.4400, -4.7818, -2.5368, -1.4066,  3.5211,  1.3086,  4.6450,\n",
      "         -2.7811, -0.1432, -0.0284, -3.6825,  3.9939,  2.1570,  2.8322, -2.7853,\n",
      "         -3.6283, -0.4732, -3.3998, -4.5138, -0.4201, -4.0810,  4.5272, -2.5998,\n",
      "         -4.4675,  3.5092,  2.8346, -3.1842, -2.5799,  2.9505, -4.1188,  0.5683,\n",
      "          4.7505, -2.0763, -1.2342,  1.7095,  0.9938,  2.2659, -5.0308,  1.8395,\n",
      "          3.3683, -4.9486,  0.1193, -2.0612,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3001,  1.7042,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2080,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8856,\n",
      "          0.8305, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4558,  3.9828,\n",
      "          2.2176,  0.5731,  3.4012,  0.2047, -0.1507,  4.8440, -4.8962,  2.9688],\n",
      "        [-4.6140,  2.7518,  1.6586,  4.4926,  2.5729, -1.7533, -2.5831, -3.9530,\n",
      "          2.3582, -4.8196,  3.9359, -4.5364,  4.3886, -0.0883,  1.6528, -3.0684,\n",
      "          1.2839,  2.0360, -4.0774,  3.1339, -2.3522,  4.3834, -1.6129,  4.0201,\n",
      "         -4.2981, -1.7843,  4.2467,  3.2843,  1.0814, -0.4296, -2.7108,  2.9301,\n",
      "         -1.7972,  3.7512, -4.8275,  0.0481,  4.2598, -3.2178,  0.6681,  2.3330,\n",
      "          1.7664, -3.7302,  4.0068, -3.7312, -2.1141,  0.6883,  2.3444, -1.8468,\n",
      "         -2.0156,  0.4224,  3.2431,  3.6751, -1.1185, -4.0454,  0.1761,  3.5233,\n",
      "          0.3707,  3.4717, -1.0277, -1.7923,  2.9239, -4.2714,  2.0183,  1.8571,\n",
      "         -0.3962, -3.6360,  2.6375,  1.1973, -4.7075, -2.8375, -2.1078,  3.1287,\n",
      "         -0.0339,  3.0293, -4.4233,  2.7628, -4.7937, -3.2696, -0.0475,  2.6107,\n",
      "          4.6725, -0.7084, -4.6528,  1.8096,  3.1316, -1.0451, -2.6619,  3.8327,\n",
      "         -3.3925, -0.5585,  0.0325,  2.8569,  4.2393,  1.0065,  3.7550,  0.4253,\n",
      "         -0.6239,  0.4242, -0.7867,  2.2845,  3.6746,  1.5727,  3.9519,  1.1536]])), ('fc1.bias', tensor([-0.1858, -0.0258, -0.0574])), ('fc2.weight', tensor([[-3.2951,  0.9056,  2.4362],\n",
      "        [-3.2475,  0.8406,  2.5237]])), ('fc2.bias', tensor([ 0.9249, -0.9249]))])\n",
      "[[11259   101]\n",
      " [ 3632    68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86     11360\n",
      "           1       0.40      0.02      0.04      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.58      0.50      0.45     15060\n",
      "weighted avg       0.67      0.75      0.66     15060\n",
      "\n",
      "正解率 : 0.752124833997344\n",
      "test loss : 0.5474472045898438\n",
      "step : 24000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8158, -1.7046,  2.4160, -3.2540, -3.0519,  4.0560,  2.3869,  2.1115,\n",
      "          3.5010, -3.9452, -2.0742, -2.5138,  4.4996, -1.6598,  0.9095, -0.3777,\n",
      "          3.7411, -2.9553, -3.3804,  0.2601, -1.4028, -3.3183,  4.9221, -4.7928,\n",
      "          2.6983, -1.8170,  0.2927,  2.6841,  1.9748, -4.4969, -3.7244,  2.6080,\n",
      "          2.9900, -1.7586, -2.9932,  0.4631, -4.3560,  1.0019, -1.7003, -2.5595,\n",
      "         -0.4150,  4.7774, -0.4858, -1.5736, -0.2708,  0.7105, -2.2627, -1.1158,\n",
      "         -2.3738, -1.2271,  3.9231,  3.5669, -1.4659,  3.9225, -3.0083, -4.8071,\n",
      "         -0.8037,  4.7502,  0.3282,  3.4527, -2.5026, -1.3521, -1.9093,  2.6348,\n",
      "          2.4591, -0.6423, -3.8302,  3.2174,  4.4070, -1.0304,  4.3914,  2.5342,\n",
      "          2.7899, -2.9276, -3.2847, -1.9185,  3.1526,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5367, -1.5560, -0.7465, -4.3141,  3.7218,  2.9148,  3.1240,  2.7051,\n",
      "         -4.0081, -1.2597,  2.8166,  2.6926, -3.4886,  4.6801,  0.5113,  2.2645,\n",
      "         -0.2522,  3.6576,  3.3889,  3.0506, -2.3886, -0.8768,  1.1706,  3.6791],\n",
      "        [ 4.1826,  3.9302, -0.6123,  3.9424,  0.9129,  2.4723,  0.7025, -2.8342,\n",
      "          3.1058,  0.4532, -3.0396,  4.2990,  2.5995,  1.0056,  3.1723,  3.8760,\n",
      "          0.2672, -2.3781, -2.9783, -3.3696,  2.8046, -3.5780, -4.4546,  4.4190,\n",
      "          1.1867, -4.4398, -4.7818, -2.5369, -1.4070,  3.5209,  1.3087,  4.6441,\n",
      "         -2.7811, -0.1436, -0.0284, -3.6825,  3.9935,  2.1570,  2.8316, -2.7853,\n",
      "         -3.6284, -0.4734, -3.4000, -4.5140, -0.4201, -4.0811,  4.5271, -2.5999,\n",
      "         -4.4674,  3.5092,  2.8338, -3.1843, -2.5800,  2.9502, -4.1191,  0.5682,\n",
      "          4.7505, -2.0763, -1.2344,  1.7096,  0.9923,  2.2653, -5.0320,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0612,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3001,  1.7042,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2080,  3.7505,  2.5495, -2.1632, -2.2137,  1.7910, -0.8856,\n",
      "          0.8304, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4558,  3.9828,\n",
      "          2.2176,  0.5731,  3.4012,  0.2047, -0.1507,  4.8424, -4.8962,  2.9688],\n",
      "        [-4.6133,  2.7515,  1.6586,  4.4931,  2.5733, -1.7538, -2.5829, -3.9526,\n",
      "          2.3544, -4.8190,  3.9359, -4.5363,  4.3886, -0.0886,  1.6522, -3.0685,\n",
      "          1.2839,  2.0357, -4.0776,  3.1335, -2.3522,  4.3831, -1.6118,  4.0206,\n",
      "         -4.2998, -1.7833,  4.2466,  3.2847,  1.0799, -0.4305, -2.7108,  2.9325,\n",
      "         -1.7973,  3.7471, -4.8275,  0.0483,  4.2589, -3.2177,  0.6671,  2.3334,\n",
      "          1.7660, -3.7313,  4.0056, -3.7321, -2.1141,  0.6895,  2.3444, -1.8458,\n",
      "         -2.0154,  0.4224,  3.2446,  3.6725, -1.1188, -4.0471,  0.1756,  3.5242,\n",
      "          0.3707,  3.4717, -1.0281, -1.7923,  2.9217, -4.2723,  2.0166,  1.8571,\n",
      "         -0.3963, -3.6360,  2.6375,  1.1973, -4.7075, -2.8375, -2.1078,  3.1286,\n",
      "         -0.0339,  3.0294, -4.4233,  2.7627, -4.7937, -3.2696, -0.0475,  2.6107,\n",
      "          4.6725, -0.7084, -4.6526,  1.8096,  3.1316, -1.0451, -2.6619,  3.8327,\n",
      "         -3.3927, -0.5585,  0.0325,  2.8569,  4.2394,  1.0065,  3.7550,  0.4254,\n",
      "         -0.6239,  0.4242, -0.7867,  2.2844,  3.6746,  1.5708,  3.9519,  1.1536]])), ('fc1.bias', tensor([-0.1872, -0.0275, -0.0599])), ('fc2.weight', tensor([[-3.2806,  0.8727,  2.4458],\n",
      "        [-3.2619,  0.8735,  2.5141]])), ('fc2.bias', tensor([ 0.9493, -0.9493]))])\n",
      "[[11360     0]\n",
      " [ 3700     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     11360\n",
      "           1       0.00      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.38      0.50      0.43     15060\n",
      "weighted avg       0.57      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.7543160690571049\n",
      "test loss : 0.5256876945495605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 25000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8158, -1.7047,  2.4158, -3.2540, -3.0518,  4.0559,  2.3869,  2.1116,\n",
      "          3.4996, -3.9450, -2.0741, -2.5136,  4.4996, -1.6599,  0.9094, -0.3777,\n",
      "          3.7411, -2.9553, -3.3804,  0.2601, -1.4028, -3.3183,  4.9223, -4.7928,\n",
      "          2.6976, -1.8170,  0.2927,  2.6842,  1.9747, -4.4969, -3.7244,  2.6084,\n",
      "          2.9899, -1.7596, -2.9932,  0.4630, -4.3560,  1.0019, -1.7007, -2.5593,\n",
      "         -0.4151,  4.7771, -0.4861, -1.5738, -0.2708,  0.7107, -2.2626, -1.1157,\n",
      "         -2.3737, -1.2272,  3.9235,  3.5662, -1.4660,  3.9220, -3.0083, -4.8071,\n",
      "         -0.8037,  4.7501,  0.3281,  3.4526, -2.5031, -1.3525, -1.9096,  2.6348,\n",
      "          2.4591, -0.6424, -3.8302,  3.2174,  4.4070, -1.0304,  4.3914,  2.5343,\n",
      "          2.7899, -2.9276, -3.2847, -1.9185,  3.1526,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5367, -1.5560, -0.7465, -4.3141,  3.7218,  2.9147,  3.1240,  2.7050,\n",
      "         -4.0081, -1.2597,  2.8166,  2.6926, -3.4886,  4.6801,  0.5113,  2.2645,\n",
      "         -0.2522,  3.6575,  3.3888,  3.0506, -2.3886, -0.8773,  1.1705,  3.6791],\n",
      "        [ 4.1821,  3.9301, -0.6132,  3.9425,  0.9129,  2.4716,  0.7024, -2.8343,\n",
      "          3.1042,  0.4532, -3.0396,  4.2989,  2.5995,  1.0056,  3.1720,  3.8760,\n",
      "          0.2671, -2.3782, -2.9784, -3.3696,  2.8044, -3.5780, -4.4550,  4.4190,\n",
      "          1.1861, -4.4398, -4.7819, -2.5368, -1.4073,  3.5206,  1.3087,  4.6434,\n",
      "         -2.7812, -0.1442, -0.0284, -3.6826,  3.9931,  2.1570,  2.8311, -2.7856,\n",
      "         -3.6283, -0.4733, -3.4000, -4.5140, -0.4201, -4.0810,  4.5271, -2.6002,\n",
      "         -4.4675,  3.5089,  2.8331, -3.1846, -2.5800,  2.9497, -4.1194,  0.5682,\n",
      "          4.7505, -2.0764, -1.2345,  1.7095,  0.9909,  2.2647, -5.0331,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0612,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3001,  1.7042,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2080,  3.7505,  2.5495, -2.1632, -2.2136,  1.7910, -0.8856,\n",
      "          0.8304, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5731,  3.4011,  0.2047, -0.1507,  4.8409, -4.8962,  2.9688],\n",
      "        [-4.6123,  2.7512,  1.6593,  4.4935,  2.5738, -1.7538, -2.5824, -3.9518,\n",
      "          2.3491, -4.8175,  3.9355, -4.5355,  4.3886, -0.0891,  1.6516, -3.0687,\n",
      "          1.2837,  2.0355, -4.0778,  3.1332, -2.3523,  4.3826, -1.6100,  4.0212,\n",
      "         -4.3020, -1.7824,  4.2465,  3.2854,  1.0790, -0.4313, -2.7108,  2.9367,\n",
      "         -1.7973,  3.7421, -4.8276,  0.0480,  4.2582, -3.2177,  0.6653,  2.3347,\n",
      "          1.7654, -3.7322,  4.0046, -3.7328, -2.1141,  0.6914,  2.3447, -1.8453,\n",
      "         -2.0151,  0.4219,  3.2474,  3.6698, -1.1193, -4.0491,  0.1748,  3.5255,\n",
      "          0.3707,  3.4714, -1.0282, -1.7924,  2.9201, -4.2734,  2.0157,  1.8571,\n",
      "         -0.3963, -3.6360,  2.6375,  1.1975, -4.7075, -2.8375, -2.1080,  3.1287,\n",
      "         -0.0339,  3.0293, -4.4233,  2.7626, -4.7937, -3.2696, -0.0475,  2.6107,\n",
      "          4.6725, -0.7083, -4.6526,  1.8096,  3.1316, -1.0451, -2.6619,  3.8326,\n",
      "         -3.3931, -0.5586,  0.0324,  2.8568,  4.2394,  1.0065,  3.7550,  0.4254,\n",
      "         -0.6239,  0.4241, -0.7867,  2.2844,  3.6746,  1.5696,  3.9518,  1.1537]])), ('fc1.bias', tensor([-0.1879, -0.0292, -0.0620])), ('fc2.weight', tensor([[-3.2745,  0.8614,  2.4194],\n",
      "        [-3.2681,  0.8849,  2.5405]])), ('fc2.bias', tensor([ 0.9605, -0.9605]))])\n",
      "[[9570 1790]\n",
      " [2525 1175]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82     11360\n",
      "           1       0.40      0.32      0.35      3700\n",
      "\n",
      "    accuracy                           0.71     15060\n",
      "   macro avg       0.59      0.58      0.58     15060\n",
      "weighted avg       0.69      0.71      0.70     15060\n",
      "\n",
      "正解率 : 0.7134794156706508\n",
      "test loss : 0.5529831647872925\n",
      "step : 26000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8157, -1.7048,  2.4156, -3.2539, -3.0518,  4.0555,  2.3871,  2.1117,\n",
      "          3.4983, -3.9450, -2.0742, -2.5136,  4.4996, -1.6600,  0.9092, -0.3777,\n",
      "          3.7410, -2.9554, -3.3805,  0.2600, -1.4027, -3.3183,  4.9225, -4.7927,\n",
      "          2.6969, -1.8166,  0.2927,  2.6843,  1.9741, -4.4970, -3.7244,  2.6093,\n",
      "          2.9899, -1.7613, -2.9932,  0.4629, -4.3562,  1.0019, -1.7009, -2.5586,\n",
      "         -0.4153,  4.7767, -0.4863, -1.5742, -0.2708,  0.7109, -2.2626, -1.1158,\n",
      "         -2.3737, -1.2274,  3.9242,  3.5651, -1.4661,  3.9213, -3.0084, -4.8069,\n",
      "         -0.8038,  4.7500,  0.3280,  3.4525, -2.5038, -1.3533, -1.9099,  2.6349,\n",
      "          2.4590, -0.6424, -3.8302,  3.2174,  4.4070, -1.0304,  4.3914,  2.5343,\n",
      "          2.7899, -2.9276, -3.2847, -1.9185,  3.1526,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5367, -1.5560, -0.7465, -4.3141,  3.7218,  2.9148,  3.1240,  2.7050,\n",
      "         -4.0083, -1.2597,  2.8166,  2.6926, -3.4886,  4.6801,  0.5114,  2.2645,\n",
      "         -0.2522,  3.6574,  3.3888,  3.0506, -2.3886, -0.8781,  1.1706,  3.6791],\n",
      "        [ 4.1817,  3.9299, -0.6141,  3.9424,  0.9129,  2.4709,  0.7024, -2.8344,\n",
      "          3.1030,  0.4532, -3.0398,  4.2989,  2.5995,  1.0056,  3.1720,  3.8759,\n",
      "          0.2671, -2.3782, -2.9784, -3.3697,  2.8042, -3.5781, -4.4550,  4.4190,\n",
      "          1.1855, -4.4399, -4.7819, -2.5367, -1.4077,  3.5205,  1.3086,  4.6424,\n",
      "         -2.7812, -0.1447, -0.0284, -3.6826,  3.9927,  2.1570,  2.8307, -2.7856,\n",
      "         -3.6284, -0.4734, -3.4002, -4.5141, -0.4201, -4.0810,  4.5269, -2.6004,\n",
      "         -4.4675,  3.5088,  2.8321, -3.1850, -2.5801,  2.9495, -4.1194,  0.5683,\n",
      "          4.7505, -2.0765, -1.2345,  1.7095,  0.9894,  2.2643, -5.0343,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0612,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3001,  1.7042,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2080,  3.7505,  2.5495, -2.1631, -2.2137,  1.7909, -0.8856,\n",
      "          0.8303, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5731,  3.4011,  0.2047, -0.1507,  4.8395, -4.8962,  2.9688],\n",
      "        [-4.6117,  2.7508,  1.6588,  4.4940,  2.5740, -1.7546, -2.5816, -3.9517,\n",
      "          2.3449, -4.8166,  3.9345, -4.5353,  4.3886, -0.0896,  1.6509, -3.0687,\n",
      "          1.2835,  2.0353, -4.0782,  3.1331, -2.3522,  4.3825, -1.6092,  4.0213,\n",
      "         -4.3031, -1.7808,  4.2464,  3.2857,  1.0762, -0.4318, -2.7108,  2.9405,\n",
      "         -1.7973,  3.7359, -4.8275,  0.0476,  4.2571, -3.2177,  0.6644,  2.3376,\n",
      "          1.7645, -3.7328,  4.0033, -3.7339, -2.1142,  0.6922,  2.3448, -1.8459,\n",
      "         -2.0149,  0.4213,  3.2505,  3.6658, -1.1201, -4.0512,  0.1744,  3.5265,\n",
      "          0.3706,  3.4710, -1.0284, -1.7926,  2.9178, -4.2755,  2.0145,  1.8572,\n",
      "         -0.3964, -3.6360,  2.6374,  1.1974, -4.7076, -2.8376, -2.1080,  3.1286,\n",
      "         -0.0338,  3.0293, -4.4232,  2.7625, -4.7937, -3.2696, -0.0475,  2.6107,\n",
      "          4.6726, -0.7084, -4.6526,  1.8096,  3.1315, -1.0451, -2.6619,  3.8326,\n",
      "         -3.3935, -0.5586,  0.0324,  2.8568,  4.2394,  1.0065,  3.7551,  0.4253,\n",
      "         -0.6239,  0.4239, -0.7867,  2.2844,  3.6746,  1.5672,  3.9518,  1.1537]])), ('fc1.bias', tensor([-0.1890, -0.0308, -0.0653])), ('fc2.weight', tensor([[-3.2719,  0.8892,  2.4593],\n",
      "        [-3.2707,  0.8570,  2.5006]])), ('fc2.bias', tensor([ 0.9880, -0.9880]))])\n",
      "[[11360     0]\n",
      " [ 3700     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     11360\n",
      "           1       0.00      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.38      0.50      0.43     15060\n",
      "weighted avg       0.57      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.7543160690571049\n",
      "test loss : 0.58888179063797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 27000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8156, -1.7050,  2.4155, -3.2538, -3.0517,  4.0553,  2.3871,  2.1121,\n",
      "          3.4966, -3.9448, -2.0743, -2.5136,  4.4996, -1.6601,  0.9089, -0.3777,\n",
      "          3.7410, -2.9555, -3.3805,  0.2598, -1.4026, -3.3184,  4.9233, -4.7926,\n",
      "          2.6956, -1.8160,  0.2927,  2.6844,  1.9733, -4.4971, -3.7244,  2.6106,\n",
      "          2.9898, -1.7636, -2.9933,  0.4629, -4.3563,  1.0019, -1.7015, -2.5580,\n",
      "         -0.4155,  4.7763, -0.4868, -1.5747, -0.2708,  0.7115, -2.2625, -1.1159,\n",
      "         -2.3737, -1.2275,  3.9254,  3.5637, -1.4662,  3.9202, -3.0083, -4.8067,\n",
      "         -0.8039,  4.7500,  0.3277,  3.4525, -2.5047, -1.3538, -1.9107,  2.6349,\n",
      "          2.4590, -0.6424, -3.8303,  3.2174,  4.4069, -1.0304,  4.3913,  2.5343,\n",
      "          2.7899, -2.9276, -3.2847, -1.9185,  3.1526,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5367, -1.5560, -0.7465, -4.3142,  3.7218,  2.9148,  3.1240,  2.7050,\n",
      "         -4.0083, -1.2597,  2.8166,  2.6926, -3.4886,  4.6801,  0.5114,  2.2644,\n",
      "         -0.2522,  3.6574,  3.3888,  3.0506, -2.3885, -0.8792,  1.1705,  3.6791],\n",
      "        [ 4.1811,  3.9297, -0.6152,  3.9424,  0.9128,  2.4702,  0.7023, -2.8345,\n",
      "          3.1018,  0.4530, -3.0397,  4.2989,  2.5995,  1.0056,  3.1721,  3.8759,\n",
      "          0.2671, -2.3781, -2.9785, -3.3696,  2.8042, -3.5781, -4.4557,  4.4189,\n",
      "          1.1851, -4.4400, -4.7819, -2.5368, -1.4079,  3.5206,  1.3086,  4.6406,\n",
      "         -2.7812, -0.1447, -0.0283, -3.6826,  3.9926,  2.1570,  2.8304, -2.7859,\n",
      "         -3.6283, -0.4734, -3.4003, -4.5139, -0.4201, -4.0813,  4.5268, -2.6005,\n",
      "         -4.4676,  3.5086,  2.8306, -3.1849, -2.5802,  2.9496, -4.1193,  0.5681,\n",
      "          4.7505, -2.0765, -1.2345,  1.7095,  0.9879,  2.2642, -5.0357,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0612,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3001,  1.7041,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2079,  3.7505,  2.5495, -2.1631, -2.2137,  1.7909, -0.8856,\n",
      "          0.8303, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5731,  3.4011,  0.2047, -0.1507,  4.8381, -4.8962,  2.9688],\n",
      "        [-4.6109,  2.7504,  1.6593,  4.4946,  2.5744, -1.7549, -2.5814, -3.9511,\n",
      "          2.3392, -4.8150,  3.9342, -4.5350,  4.3886, -0.0901,  1.6502, -3.0687,\n",
      "          1.2834,  2.0349, -4.0785,  3.1326, -2.3523,  4.3821, -1.6067,  4.0219,\n",
      "         -4.3062, -1.7792,  4.2464,  3.2862,  1.0738, -0.4328, -2.7108,  2.9458,\n",
      "         -1.7975,  3.7288, -4.8275,  0.0474,  4.2558, -3.2177,  0.6628,  2.3402,\n",
      "          1.7636, -3.7340,  4.0012, -3.7351, -2.1142,  0.6944,  2.3451, -1.8457,\n",
      "         -2.0146,  0.4208,  3.2551,  3.6609, -1.1211, -4.0534,  0.1739,  3.5273,\n",
      "          0.3704,  3.4710, -1.0290, -1.7926,  2.9154, -4.2775,  2.0134,  1.8572,\n",
      "         -0.3964, -3.6360,  2.6373,  1.1976, -4.7076, -2.8376, -2.1081,  3.1286,\n",
      "         -0.0338,  3.0293, -4.4232,  2.7624, -4.7937, -3.2696, -0.0475,  2.6107,\n",
      "          4.6726, -0.7082, -4.6526,  1.8095,  3.1316, -1.0451, -2.6619,  3.8326,\n",
      "         -3.3940, -0.5586,  0.0324,  2.8568,  4.2394,  1.0066,  3.7551,  0.4251,\n",
      "         -0.6239,  0.4239, -0.7866,  2.2844,  3.6746,  1.5648,  3.9518,  1.1537]])), ('fc1.bias', tensor([-0.1902, -0.0324, -0.0684])), ('fc2.weight', tensor([[-3.3293,  0.8777,  2.4403],\n",
      "        [-3.2133,  0.8686,  2.5196]])), ('fc2.bias', tensor([ 1.0054, -1.0054]))])\n",
      "[[10743   617]\n",
      " [ 3081   619]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.85     11360\n",
      "           1       0.50      0.17      0.25      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.64      0.56      0.55     15060\n",
      "weighted avg       0.71      0.75      0.71     15060\n",
      "\n",
      "正解率 : 0.7544488711819389\n",
      "test loss : 0.525173544883728\n",
      "step : 28000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8150, -1.7051,  2.4156, -3.2536, -3.0514,  4.0552,  2.3874,  2.1121,\n",
      "          3.4951, -3.9446, -2.0747, -2.5135,  4.4995, -1.6602,  0.9085, -0.3778,\n",
      "          3.7410, -2.9555, -3.3805,  0.2597, -1.4026, -3.3184,  4.9245, -4.7926,\n",
      "          2.6942, -1.8156,  0.2927,  2.6848,  1.9722, -4.4970, -3.7244,  2.6116,\n",
      "          2.9899, -1.7660, -2.9932,  0.4629, -4.3563,  1.0019, -1.7023, -2.5572,\n",
      "         -0.4157,  4.7757, -0.4875, -1.5752, -0.2708,  0.7121, -2.2626, -1.1156,\n",
      "         -2.3734, -1.2278,  3.9264,  3.5627, -1.4662,  3.9189, -3.0083, -4.8066,\n",
      "         -0.8040,  4.7497,  0.3274,  3.4525, -2.5052, -1.3545, -1.9111,  2.6349,\n",
      "          2.4590, -0.6424, -3.8303,  3.2174,  4.4069, -1.0305,  4.3913,  2.5343,\n",
      "          2.7899, -2.9276, -3.2847, -1.9185,  3.1526,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5367, -1.5560, -0.7465, -4.3142,  3.7218,  2.9147,  3.1240,  2.7050,\n",
      "         -4.0083, -1.2597,  2.8165,  2.6926, -3.4887,  4.6801,  0.5114,  2.2644,\n",
      "         -0.2523,  3.6574,  3.3888,  3.0506, -2.3885, -0.8798,  1.1705,  3.6791],\n",
      "        [ 4.1803,  3.9295, -0.6166,  3.9423,  0.9127,  2.4695,  0.7020, -2.8344,\n",
      "          3.1010,  0.4527, -3.0400,  4.2988,  2.5995,  1.0056,  3.1722,  3.8759,\n",
      "          0.2671, -2.3781, -2.9785, -3.3696,  2.8041, -3.5781, -4.4565,  4.4188,\n",
      "          1.1847, -4.4402, -4.7819, -2.5369, -1.4080,  3.5206,  1.3086,  4.6389,\n",
      "         -2.7811, -0.1446, -0.0283, -3.6826,  3.9923,  2.1570,  2.8304, -2.7866,\n",
      "         -3.6284, -0.4734, -3.4003, -4.5139, -0.4201, -4.0817,  4.5268, -2.6006,\n",
      "         -4.4676,  3.5084,  2.8291, -3.1849, -2.5802,  2.9496, -4.1192,  0.5678,\n",
      "          4.7504, -2.0765, -1.2344,  1.7095,  0.9861,  2.2638, -5.0370,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0612,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3001,  1.7041,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2078,  3.7505,  2.5495, -2.1632, -2.2137,  1.7909, -0.8856,\n",
      "          0.8303, -0.8177,  1.1668, -0.4809,  0.1174,  4.7641,  1.4557,  3.9828,\n",
      "          2.2176,  0.5731,  3.4011,  0.2047, -0.1507,  4.8365, -4.8962,  2.9688],\n",
      "        [-4.6101,  2.7500,  1.6597,  4.4950,  2.5749, -1.7550, -2.5805, -3.9511,\n",
      "          2.3364, -4.8141,  3.9332, -4.5349,  4.3886, -0.0905,  1.6494, -3.0689,\n",
      "          1.2832,  2.0348, -4.0785,  3.1323, -2.3523,  4.3815, -1.6042,  4.0222,\n",
      "         -4.3083, -1.7784,  4.2464,  3.2868,  1.0721, -0.4328, -2.7106,  2.9479,\n",
      "         -1.7976,  3.7246, -4.8274,  0.0473,  4.2552, -3.2177,  0.6612,  2.3422,\n",
      "          1.7630, -3.7346,  3.9998, -3.7357, -2.1142,  0.6958,  2.3449, -1.8453,\n",
      "         -2.0143,  0.4203,  3.2567,  3.6590, -1.1214, -4.0551,  0.1735,  3.5279,\n",
      "          0.3703,  3.4706, -1.0294, -1.7926,  2.9142, -4.2785,  2.0123,  1.8572,\n",
      "         -0.3964, -3.6360,  2.6372,  1.1976, -4.7076, -2.8376, -2.1081,  3.1286,\n",
      "         -0.0339,  3.0293, -4.4233,  2.7624, -4.7937, -3.2696, -0.0475,  2.6107,\n",
      "          4.6726, -0.7082, -4.6526,  1.8095,  3.1316, -1.0452, -2.6620,  3.8326,\n",
      "         -3.3943, -0.5586,  0.0324,  2.8568,  4.2393,  1.0066,  3.7551,  0.4251,\n",
      "         -0.6239,  0.4239, -0.7866,  2.2844,  3.6746,  1.5638,  3.9517,  1.1536]])), ('fc1.bias', tensor([-0.1914, -0.0341, -0.0705])), ('fc2.weight', tensor([[-3.3074,  0.8929,  2.4582],\n",
      "        [-3.2351,  0.8534,  2.5017]])), ('fc2.bias', tensor([ 1.0195, -1.0195]))])\n",
      "[[11355     5]\n",
      " [ 3699     1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     11360\n",
      "           1       0.17      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.46      0.50      0.43     15060\n",
      "weighted avg       0.61      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.7540504648074369\n",
      "test loss : 0.5619603991508484\n",
      "step : 29000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8146, -1.7052,  2.4155, -3.2535, -3.0513,  4.0551,  2.3875,  2.1124,\n",
      "          3.4938, -3.9444, -2.0747, -2.5135,  4.4995, -1.6604,  0.9084, -0.3778,\n",
      "          3.7409, -2.9555, -3.3805,  0.2597, -1.4026, -3.3184,  4.9250, -4.7925,\n",
      "          2.6934, -1.8154,  0.2927,  2.6849,  1.9716, -4.4970, -3.7244,  2.6126,\n",
      "          2.9898, -1.7677, -2.9933,  0.4629, -4.3564,  1.0019, -1.7027, -2.5564,\n",
      "         -0.4158,  4.7751, -0.4879, -1.5755, -0.2708,  0.7127, -2.2625, -1.1154,\n",
      "         -2.3735, -1.2283,  3.9273,  3.5616, -1.4663,  3.9182, -3.0083, -4.8065,\n",
      "         -0.8040,  4.7497,  0.3274,  3.4524, -2.5058, -1.3549, -1.9116,  2.6349,\n",
      "          2.4590, -0.6423, -3.8303,  3.2174,  4.4069, -1.0305,  4.3913,  2.5342,\n",
      "          2.7899, -2.9276, -3.2847, -1.9185,  3.1526,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5367, -1.5560, -0.7465, -4.3142,  3.7218,  2.9147,  3.1240,  2.7050,\n",
      "         -4.0084, -1.2597,  2.8165,  2.6926, -3.4887,  4.6801,  0.5114,  2.2644,\n",
      "         -0.2523,  3.6574,  3.3888,  3.0506, -2.3885, -0.8803,  1.1705,  3.6791],\n",
      "        [ 4.1800,  3.9293, -0.6176,  3.9423,  0.9127,  2.4688,  0.7019, -2.8344,\n",
      "          3.0994,  0.4527, -3.0401,  4.2987,  2.5995,  1.0055,  3.1721,  3.8758,\n",
      "          0.2670, -2.3781, -2.9785, -3.3697,  2.8041, -3.5782, -4.4568,  4.4188,\n",
      "          1.1839, -4.4402, -4.7819, -2.5369, -1.4083,  3.5202,  1.3086,  4.6382,\n",
      "         -2.7811, -0.1455, -0.0283, -3.6827,  3.9918,  2.1570,  2.8302, -2.7867,\n",
      "         -3.6284, -0.4735, -3.4005, -4.5141, -0.4201, -4.0817,  4.5269, -2.6008,\n",
      "         -4.4676,  3.5081,  2.8284, -3.1855, -2.5803,  2.9492, -4.1193,  0.5678,\n",
      "          4.7503, -2.0765, -1.2345,  1.7094,  0.9845,  2.2629, -5.0381,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0613,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3001,  1.7041,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2078,  3.7505,  2.5495, -2.1631, -2.2137,  1.7910, -0.8856,\n",
      "          0.8303, -0.8177,  1.1668, -0.4809,  0.1174,  4.7640,  1.4557,  3.9828,\n",
      "          2.2176,  0.5731,  3.4011,  0.2047, -0.1507,  4.8347, -4.8962,  2.9688],\n",
      "        [-4.6087,  2.7498,  1.6605,  4.4955,  2.5754, -1.7550, -2.5802, -3.9498,\n",
      "          2.3320, -4.8136,  3.9330, -4.5342,  4.3886, -0.0910,  1.6488, -3.0690,\n",
      "          1.2830,  2.0347, -4.0786,  3.1319, -2.3517,  4.3812, -1.6024,  4.0225,\n",
      "         -4.3103, -1.7772,  4.2464,  3.2873,  1.0706, -0.4332, -2.7106,  2.9527,\n",
      "         -1.7976,  3.7184, -4.8276,  0.0474,  4.2542, -3.2177,  0.6600,  2.3446,\n",
      "          1.7625, -3.7355,  3.9986, -3.7366, -2.1143,  0.6973,  2.3453, -1.8444,\n",
      "         -2.0144,  0.4192,  3.2605,  3.6552, -1.1218, -4.0571,  0.1730,  3.5290,\n",
      "          0.3701,  3.4706, -1.0292, -1.7926,  2.9125, -4.2795,  2.0115,  1.8572,\n",
      "         -0.3964, -3.6359,  2.6372,  1.1975, -4.7076, -2.8375, -2.1081,  3.1286,\n",
      "         -0.0339,  3.0292, -4.4233,  2.7623, -4.7938, -3.2696, -0.0475,  2.6106,\n",
      "          4.6726, -0.7081, -4.6525,  1.8095,  3.1315, -1.0452, -2.6619,  3.8325,\n",
      "         -3.3945, -0.5586,  0.0324,  2.8568,  4.2395,  1.0065,  3.7551,  0.4251,\n",
      "         -0.6239,  0.4238, -0.7866,  2.2844,  3.6746,  1.5624,  3.9516,  1.1536]])), ('fc1.bias', tensor([-0.1922, -0.0360, -0.0722])), ('fc2.weight', tensor([[-3.3121,  0.8510,  2.4388],\n",
      "        [-3.2305,  0.8953,  2.5211]])), ('fc2.bias', tensor([ 1.0266, -1.0266]))])\n",
      "[[9735 1625]\n",
      " [2360 1340]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83     11360\n",
      "           1       0.45      0.36      0.40      3700\n",
      "\n",
      "    accuracy                           0.74     15060\n",
      "   macro avg       0.63      0.61      0.62     15060\n",
      "weighted avg       0.72      0.74      0.72     15060\n",
      "\n",
      "正解率 : 0.7353917662682603\n",
      "test loss : 0.5414638519287109\n",
      "step : 30000\n",
      "OrderedDict([('fc1.weight', tensor([[-4.8141, -1.7055,  2.4158, -3.2533, -3.0510,  4.0551,  2.3878,  2.1130,\n",
      "          3.4914, -3.9441, -2.0747, -2.5134,  4.4995, -1.6605,  0.9080, -0.3779,\n",
      "          3.7408, -2.9556, -3.3805,  0.2595, -1.4026, -3.3181,  4.9256, -4.7924,\n",
      "          2.6921, -1.8145,  0.2927,  2.6852,  1.9707, -4.4971, -3.7244,  2.6149,\n",
      "          2.9897, -1.7709, -2.9933,  0.4629, -4.3568,  1.0019, -1.7031, -2.5554,\n",
      "         -0.4163,  4.7742, -0.4885, -1.5759, -0.2709,  0.7137, -2.2623, -1.1155,\n",
      "         -2.3736, -1.2283,  3.9293,  3.5597, -1.4663,  3.9167, -3.0083, -4.8062,\n",
      "         -0.8041,  4.7495,  0.3272,  3.4525, -2.5066, -1.3559, -1.9117,  2.6349,\n",
      "          2.4590, -0.6424, -3.8303,  3.2174,  4.4069, -1.0304,  4.3912,  2.5343,\n",
      "          2.7899, -2.9276, -3.2847, -1.9185,  3.1526,  2.6810,  0.6493,  1.4863,\n",
      "         -2.5367, -1.5559, -0.7465, -4.3142,  3.7216,  2.9147,  3.1239,  2.7049,\n",
      "         -4.0085, -1.2597,  2.8165,  2.6926, -3.4887,  4.6801,  0.5114,  2.2644,\n",
      "         -0.2523,  3.6574,  3.3888,  3.0506, -2.3885, -0.8811,  1.1705,  3.6791],\n",
      "        [ 4.1794,  3.9291, -0.6187,  3.9423,  0.9126,  2.4680,  0.7019, -2.8345,\n",
      "          3.0982,  0.4525, -3.0400,  4.2987,  2.5995,  1.0055,  3.1721,  3.8758,\n",
      "          0.2670, -2.3781, -2.9785, -3.3697,  2.8040, -3.5783, -4.4572,  4.4187,\n",
      "          1.1832, -4.4403, -4.7819, -2.5368, -1.4086,  3.5202,  1.3086,  4.6364,\n",
      "         -2.7811, -0.1451, -0.0283, -3.6827,  3.9918,  2.1570,  2.8299, -2.7873,\n",
      "         -3.6284, -0.4736, -3.4004, -4.5141, -0.4201, -4.0820,  4.5268, -2.6011,\n",
      "         -4.4676,  3.5080,  2.8269, -3.1853, -2.5803,  2.9492, -4.1193,  0.5676,\n",
      "          4.7503, -2.0765, -1.2345,  1.7095,  0.9829,  2.2627, -5.0394,  1.8395,\n",
      "          3.3682, -4.9486,  0.1193, -2.0613,  4.4275, -1.8702,  2.6473, -4.5531,\n",
      "          4.3001,  1.7041,  2.0986, -4.8265, -1.8527,  1.3447, -0.2410,  2.9675,\n",
      "         -1.9162,  3.2078,  3.7505,  2.5495, -2.1631, -2.2137,  1.7910, -0.8856,\n",
      "          0.8303, -0.8177,  1.1668, -0.4809,  0.1175,  4.7640,  1.4557,  3.9828,\n",
      "          2.2176,  0.5732,  3.4011,  0.2047, -0.1507,  4.8331, -4.8962,  2.9688],\n",
      "        [-4.6079,  2.7493,  1.6606,  4.4959,  2.5761, -1.7552, -2.5796, -3.9483,\n",
      "          2.3264, -4.8123,  3.9328, -4.5343,  4.3885, -0.0915,  1.6482, -3.0693,\n",
      "          1.2828,  2.0345, -4.0788,  3.1316, -2.3517,  4.3813, -1.6021,  4.0227,\n",
      "         -4.3124, -1.7754,  4.2463,  3.2879,  1.0693, -0.4339, -2.7106,  2.9573,\n",
      "         -1.7978,  3.7119, -4.8275,  0.0476,  4.2524, -3.2178,  0.6591,  2.3464,\n",
      "          1.7616, -3.7363,  3.9976, -3.7373, -2.1143,  0.6994,  2.3457, -1.8447,\n",
      "         -2.0145,  0.4189,  3.2641,  3.6509, -1.1218, -4.0591,  0.1723,  3.5300,\n",
      "          0.3701,  3.4703, -1.0299, -1.7924,  2.9107, -4.2815,  2.0109,  1.8572,\n",
      "         -0.3964, -3.6360,  2.6371,  1.1976, -4.7076, -2.8374, -2.1082,  3.1286,\n",
      "         -0.0339,  3.0292, -4.4233,  2.7625, -4.7938, -3.2696, -0.0475,  2.6106,\n",
      "          4.6726, -0.7081, -4.6525,  1.8095,  3.1313, -1.0452, -2.6619,  3.8324,\n",
      "         -3.3948, -0.5586,  0.0324,  2.8568,  4.2394,  1.0065,  3.7550,  0.4251,\n",
      "         -0.6239,  0.4239, -0.7866,  2.2844,  3.6746,  1.5606,  3.9517,  1.1537]])), ('fc1.bias', tensor([-0.1933, -0.0375, -0.0748])), ('fc2.weight', tensor([[-3.2741,  0.8891,  2.4319],\n",
      "        [-3.2684,  0.8572,  2.5280]])), ('fc2.bias', tensor([ 1.0363, -1.0363]))])\n",
      "[[11319    41]\n",
      " [ 3687    13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     11360\n",
      "           1       0.24      0.00      0.01      3700\n",
      "\n",
      "    accuracy                           0.75     15060\n",
      "   macro avg       0.50      0.50      0.43     15060\n",
      "weighted avg       0.63      0.75      0.65     15060\n",
      "\n",
      "正解率 : 0.752456839309429\n",
      "test loss : 0.5394867062568665\n"
     ]
    }
   ],
   "source": [
    "sgd_model, loss_stack, test_loss_stack,accuracy_stack = hoge.learn(x=X_train, y=y_train, model=model,class_num=class_num,X_test=X_test,Y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10.0, 8.0))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.set_title(\"train data NLL Loss\")\n",
    "\n",
    "ax1.plot(loss_stack)\n",
    "ax1.set_xlabel(\"step\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkoAAAHwCAYAAABZmkAXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABDLElEQVR4nO3dd3xb5dn/8e8l2c4mocTMQAI0wENboJACHbRQymrp3u3Tp5sW2qf9dad9uiiztGWVFgqUFiirZUPCCiNkQpw9yN7b2d6Wpfv3xzmyZVuyZVvK8Tn6vF+vvGJZ0tGlY+noq+vc5z7mnBMAAAA6iwVdAAAAQH9FUAIAAMiBoAQAAJADQQkAACAHghIAAEAOBCUAAIAcCEoACsbMrjWzR/fD43zPzJyZndPh9wf7vz/Rv7zLzD6cYxnXm9kjeT7eSf5yh/W9egBhQlACIsQPEK8VaFmPmtnve3i3Bkm1eS5/jpld2vPKJP8x9km61swyt2O7/P/rMv7fl2MZXV2X7bZOeT43ANFBUAIiwsyGyPsgrzOzMjMb2MvlpO+bXtZAMyvP8+5JSalull9hZhUZyx9kZvEelpmSVCWpUdI30r90zrVk1JH+P6nsurou221Tjhl6gZJDUAKiY5Wkv0h6r6S9ksZLkpm938xmm9keM5tuZuPSdzCzz5nZCjPbZ2az/OtOkLRH0uck/cL/+d0dH8zMYmb2UzNbY2ZbzOw+SUMzri8zs+vMbIOZ7TWzl8zsWEnn+8t8l6Tb/FqP7OL2uThJ/0/SVWZW2btVVhhmNsLM7jCzTf66eMDMDvWvi5nZNWa21d8V+GS6XjM72sye9/82G83sJ0E+DwCdEZSA6DhM0qWSXnHODZF0uZkdLekJSVdJGinpOklP+B/sB0j6l6QfSjpQ0r3+7RZLGiTpfklXOucGSpqc5fG+KOmbki6QdJSkifKCS9qlks6V9A5Jo+V1kC6XNME5N1jSVEmXSBogaV0Xt8/JOTdX0gP+8wrS3fJC4lskHStpq6TH/d2CF8h7nu+S9zeqkfQt/37XStou6Qh5AfcyMztu/5YOoCsEJSAiOu4W8i9/XtLTzrlHnXMtzrnHJc2V9EF544l2S3qrpDc55252zl3gfF0t2/dlSb93zi13ziWcc/dJejLj+nskXeyc2+qc2yPpMUmjsi3b/13W2+fx1H8t6UIzOyuP2xac3zn6kKRvO+f2OOfqJf1UXmA6RdI2SeWSTpIUc8590Tl3pX/3LZIOl/RmSWucc0c755bv7+cAIDeCEhBtR0r6uL9rZ4+Z7ZF0jqSxzrmEvF1qb5I03cyeM7OP9WDZR8jrBGVamfFzQtKlZvaKmS2XdEs3y+vp7SVJfqj6saRbezCWqpCOkrTNObc3o6aEpDWSRjvn5kj6qKSPS1pqZvea2cn+TcdLekTSzZKWmNnvzGzQ/i0fQFcISkC0bZD0V+fciPQ/SZXOucvNrExSnXPuJ5KOk/QbSQ+Z2VF5Lnu9vK5JphMzfv6zvF1R/0/Se+SFma709PaZ7pe0Q9JlPbhPoayXdIi/K1OS5Ae2MZLW+cFnsXPuy/I6R7MlPWJmJukASXc5594n7zm/T9KP9nP9ALpAUAKipVnSwf6RaiPlBYhPm9l7/EHFp8jrarxL3m6htWZ2gbxdQ0MkxeUNkk4v6zAzO8A/oq6j+yT9xMxON7NyM/uSpIvUtl05VdI0SQvldZ++p/bbnPTyK/3Q1t3tM8UllaUv+LvuLpP0c/9XsYzbjTCzkf6/SjMb5YeauKSBGdeNNLNDzezwHI9nHW5baWZjJO2UNEFeR2u4mQ2WdI2k1ZLmSfqOpKlm9lZ/OUMy1vFLkv5gZgfJ+xsMzrgOQD9AUAKi5VV5cwNtlvR159xaSV+SdKO8OYYekPRL59x051yVvEHGN/jX3SrpG865Df6y/iPp/ZKWSTo9y2PdK29c0aOSNskb9/RHtR359n+S/ldStaTfy9vFdEDG/e+RFyKq5HWmurt9piGSRmT+wjm3xK85fX36/6f8ZVbLGzi9QdJH/Ou+mHFdtbwxQ/fkeLxYh9tul7d77RBJX5E35muJ/7sjJX3cOZeS1yl7Sl6Y2i7pYkn/7Ye7T8o7ynCFpEXyBtLfmOM5AwiAMS0IgFLh7+4aIG9OpOYs18clVTjnGvJc1iBJjX4gAhBBBCUAAIAc2PUGAACQA0EJAAAgB4ISAABADgQlAACAHMq6v0nPjRw50o0ZM6YYiwYAACio2bNn73DOZT25dlGC0pgxY1RVVVWMRQMAABSUmXU8HVMrdr0BAADkQFACAADIgaAEAACQA0EJAAAgB4ISAABADgQlAACAHAhKAAAAORCUAAAAciAoAQAA5EBQAgAAyIGgBAAAkANBCQAAIAeCEgAAQA4EJQAAgBwISgAAADkQlAAAAHIIZVBKJFNqTCSDLgMAAERcKIPS0ws266TLn9fG3fVBlwIAACIslEFpX0OLmltS2l7TFHQpAAAgwkIZlI4eOUSSlEq5gCsBAABRFsqgFI+ZJClJUAIAAEUUyqAUMz8oOYISAAAonlAGpbI4HSUAAFB8oQxKrR0lghIAACiiUAal9BilFLveAABAEYUzKLV2lAIuBAAARFo4g1LrUW8kJQAAUDwhD0oBFwIAACItpEHJ+5/pAQAAQDGFMiilj3pjZm4AAFBMoQxKZTGv7BaCEgAAKKJQBiU/J6mak+ICAIAiCmVQGjawXJLkREcJAAAUTyiD0vBB5RpcEdfO2uagSwEAABEWyqAkSRVlMTW3MD8AAAAontAGpfJ4TC1MOAkAAIoovEEpZkokGaMEAACKJ7RBqSweUwtTcwMAgCIKcVAyJZhHCQAAFFFog1JFPKYEg7kBAEARlQVdQG8t3VqjpVtrgi4DAABEWGg7SgAAAMWWV1Ayswoz70y0ZhY3s8HFLSt/zjFOCQAAFEe+HaWZkuaZWZWkWZJ+V7yS8vP19xwtSUoyoBsAABRJvmOUDpQ01jnXUsxieqJy2ABJUiLpVBYPuBgAABBJ3XaUzCwuqULS7WY2y8weNLPDil9a19KdJE5jAgAAiiWfXW9HSBoq6S+STpc0WdIdxSwqH4/M2ShJWrp1X8CVAACAqMonKG2QdLBzbrbzRk7fJukdfqeplZldYmZVZlZVXV1djFrb+fZ7j5UkjRhcUfTHAgAApanboOSHowEdfp2S5Drc7nbn3Djn3LjKysoClpjdgUO8gJTgNCYAAKBI8hmjdIykRWZ2uP+rr0qa5pwLNKGUx02S1ExQAgAARdLtUW/OudVm9jNJz5lZQtJaSZcWu7DuVMS9jMdgbgAAUCx5TQ/gnHtA0gNFrqVHKsoISgAAoLhCewqTcr+jxBglAABQLKENSnSUAABAsYU/KNFRAgAARRLeoOTvemuiowQAAIoktEFpQBljlAAAQHGFNiiV+R2lh2ZtCLgSAAAQVaENSnHzJpxcsHFvwJUAAICoCm1QOmCQNwXUqUeNCLYQAAAQWaENSuZ3lE4aNSLYQgAAQGSFNihJ0kFDKhjMDQAAiibUQak8HlNL0gVdBgAAiKhQB6WyuNFRAgAARRPqoFQRjymRoqMEAACKI9RBqSxuSjAzNwAAKJJQB6XyeIxdbwAAoGjKgi6gLxZv3qfFm/cFXQYAAIioUHeUAAAAiinUHaVzjq/UjtrmoMsAAAARFeqOUlk8phaOegMAAEUS7qAUM7UwmBsAABRJuINSPKYkHSUAAFAk4Q5KMVMiRUcJAAAUR6iD0uLNe7VhV0PQZQAAgIgKdVBavq026BIAAECEhToofeGMo4IuAQAARFiog9LwQeWqiIf6KQAAgH4s1CmjLGZqYTA3AAAoklAHpXjMlHJSiikCAABAEYQ6KJXFTJKUdAQlAABQeKEOSnXNSUli0kkAAFAUoQ5Kd01dI0l6Zdn2gCsBAABRFOqg9LMLT5AkDR1QHnAlAAAgikIdlN42argkyYldbwAAoPBCHZQGlHnl76xtDrgSAAAQRaEOShV+UGphMDcAACiCUAelIRVlkqS6ppaAKwEAAFEU6qBUFvfmUdpZ2xRwJQAAIIpCHZQG+x2lAwZx1BsAACi8UAel9GDuBn/iSQAAgEIKdVAqj3vl/+mF5QFXAgAAoijUQSnun+sNAACgGEIdlAAAAIqJoAQAAJADQQkAACCHyAQl55idGwAAFFZkglKS05gAAIACi0xQ4nxvAACg0EIflD5/+pGSpEQyFXAlAAAgakIflMYePEwSu94AAEDhhT4olfsnxk0kCUoAAKCwQh+UyvzTmLSk2PUGAAAKK/xByT+NSQsdJQAAUGChD0rp6ZNumMSJcQEAQGGFPij9c/paSdKjczYFWwgAAIic0Ael959wcNAlAACAiAp9UDqHoAQAAIok9EGpIh76pwAAAPqp0KeMMn8eJQAAgEILfVAqp6MEAACKJPQpo5yOEgAAKJLQByXHPJMAAKBIQh+UDhxSEXQJAAAgokIflIZUxIMuAQAARFTog1I8xhglAABQHKEPSmYEJQAAUByhD0oAAADFQlACAADIIRJB6fvnjpUkOeYKAAAABRSJoJQe0J1MEZQAAEDhRCookZMAAEAhRSIopQ98S7HrDQAAFFAkglLc0h0lghIAACicSASlmDFGCQAAFF6PgpKZHWtm+8zsjGIV1BsxxigBAIAiyDsomdkgSXdL2iapsWgV9UL6LCYpkhIAACigvIKSeecJuVXSPZI2SEoWs6ieSh/11kJQAgAABZRvR+lSSU7SHbnuY2aXmFmVmVVVV1cXqr68vLR0uyTpH9PW7NfHBQAA0dZtUDKz90r6sqTLXMbU19bhbLTOududc+Occ+MqKysLX2kXNu5ukCSt3Vm3Xx8XAABEWz4dpW9IGi3pDTNbK+lMSS9JurF4ZfVMSzIlSdpV1xxwJQAAIErKuruBc+5/Mi+b2WRJ33XOLSxaVT20dme9JGnm6l0BVwIAAKKkN/MoDfH/9RtfedeYoEsAAAAR1OOg5I9DmlmMYnrrgrccKkn60pmjA64EAABESSRm5j50+EBJ0qmjRwRbCAAAiJRIBKX04Xec6g0AABRSJIJS+mS4U1fsCLgSAAAQJZEISjWNLZKkR+duCrgSAAAQJZEISmMPGSpJ+sSpRwRcCQAAiJJIBKXyuPc0jhnZr2YtAAAAIReJoBTzz6bCOXEBAEAhRSQoef+nOOwNAAAUUCSCktFRAgAARRCJoCR5XSVHRwkAABRQhIKSsesNAAAUVMSCUtBVAACAKIlMUDJjMDcAACisyASlmJlStJQAAEABRSYoNSSSumPKmqDLAAAAERKZoAQAAFBoZUEXUCgjBpfrfcdVBl0GAACIkMh0lPbUJ/TEvM1BlwEAACIkMkEJAACg0AhKAAAAORCUAAAAciAoAQAA5BCZoPTxtx+hAwZG5iA+AADQD0QmKA0dUKZ9jS1BlwEAACIkMkFpZ11T0CUAAICIiUxQOrZyqGIWdBUAACBKIhOUzEycExcAABRSdIKS/79zpCUAAFAYkQlKMfOiUgttJQAAUCCRCUpOXkBaXV0XcCUAACAqIhOUTht9oCSppjERcCUAACAqIhOUhg8qlyRNX7Uz4EoAAEBURCYoHX/oMElSnDkCAABAgUQmKFXEvafSlEgGXAkAAIiKyAQlM9OAspiakqmgSwEAABERmaAkSRVlMTUlCEoAAKAwIhWUBpTF1UxHCQAAFEjEghIdJQAAUDiRC0p0lAAAQKFEKih5Y5Q46g0AABRGpIISHSUAAFBIkQpKHPUGAAAKKVJBiaPeAABAIUUqKFWUxdTUwhglAABQGJEKSgPKYmpuoaMEAAAKI1JByesoEZQAAEBhRCoo0VECAACFFKmgREcJAAAUUqSC0oCyOB0lAABQMJEKShz1BgAACilSQWlAWUyJpFMq5YIuBQAARECkglJFmfd0mHQSAAAUQqSC0oCyuCSprqkl4EoAAEAURCooNSa88UlrdtQFXAkAAIiCSAWlU44cIUmqa2ZANwAA6LtIBaURg8slSVv3NgRcCQAAiIJIBaVB5d4YpZhZwJUAAIAoiFRQGjqwTJKYnRsAABREpILSQL+jlB7UDQAA0BeRCkoD/HmU6CgBAIBCiFRQqojHZCY10VECAAAFEKmgZGYaUBajowQAAAoiUkFJ8sYpMUYJAAAUQuSCEh0lAABQKBEMSnSUAABAYUQuKA0sp6MEAAAKI3JBiY4SAAAolMgFJTpKAACgUCIXlOgoAQCAQolcUKKjBAAACiVyQYmOEgAAKJToBSU6SgAAoEDyCkpm9jUzm2tmi8xsppmdXOzCesvrKBGUAABA33UblMxshKTPSHq/c+6tkm6QdG2R6+o1b4wSu94AAEDflXV3A+fcHkkXSpKZmaTRktYUt6zeG1AWVxMdJQAAUADdBqU0M7tNXmDaLenDRauojwaUxdScTKmpJakBZfGgywEAACGW92Bu59y3nXNjJF0u6Wm/u9TKzC4xsyozq6quri5wmfkri3ll1TWx+w0AAPRNPmOUBprZYenLzrnHJR0pqTLzds65251z45xz4yorKxWUA4dUSJJakux+AwAAfZNPR+kCSZPN7CBJMrOzJCUk7SxmYb1VHvc6SomUC7gSAAAQdvmMUXpS0nGSpptZnaQGSR9xzvXLfVtlMS/70VECAAB9lc9Rb07SH/x//V6Z31FqoaMEAAD6KHIzc2/d2yhJWlNdF3AlAAAg7CIXlJ6Yt1mS9OCs9QFXAgAAwi5yQWlgufeUHHveAABAH0UuKP3gvOMkSZ86bVTAlQAAgLCLXFA6cLA3j1I8Zt3cEgAAoGuRC0oxf8Lw7TVNAVcCAADCLnJBaVuNd9TbLx9fpKaWfjnVEwAACInIBaWmRFs4Wrhxb4CVAACAsItcUDrzmINafx5UEQ+wEgAAEHaRC0qDK9omGx9YTlACAAC9F7mglHmwm2MyJQAA0AcRDEptSYnTvQEAgL6IXFDKyElK0VECAAB9EMGglNFRSgVYCAAACL3IBaVMdJQAAEBfRDIo/fHTJ0siKAEAgL6JZFA6aIh3vjcGcwMAgL6IZFBKD1OiowQAAPoikkEpPUUA8ygBAIC+iHRQSnLUGwAA6INoBiX/WbHrDQAA9EU0g5LfUSIoAQCAvoh0UCInAQCAvohoUPL+313fHGwhAAAg1CIZlNIq4pF+egAAoMgimSSGDiyTJLUw4yQAAOiDSAalMv+wtwTzAwAAgD6IZFAqj3uDlFqSdJQAAEDvRTIolfljk1pSdJQAAEDvRTIolfuHvSXoKAEAgD6IZFBq7SgxRgkAAPRBJINSRZn3tPY2tARcCQAACLNIBqWBflC6YdLygCsBAABhFsmgVMZEkwAAoAAimygqhw0IugQAABBykQ1K5xxfqUMPGBh0GQAAIMQiG5TisZiSjukBAABA70U4KElJzvUGAAD6ILJBqWrtbu2qayYsAQCAXotsUFq6tUaStLOuKeBKAABAWEU2KKXFzYIuAQAAhFRkg9IZR78p6BIAAEDIRTYoXXzy4ZLEkW8AAKDXIhuU0rvcUpwXFwAA9FJ0g5L/zOgoAQCA3opwUPKeWorpAQAAQC9FOCh5/zOPEgAA6K3IBqUNuxokSSu21wZcCQAACKvIBqVXlm2XJD23eGvAlQAAgLCKbFD64XnHS5IueMuhAVcCAADCKrJBafig8qBLAAAAIRfZoBSPefMoMZgbAAD0FkEJAAAgh+gHJSacBAAAvRT9oMQ5TAAAQC9FNiiV+UGpau3ugCsBAABhFdmgNLA8Lkm677X1AVcCAADCKrJBqXLYgKBLAAAAIRfZoAQAANBXBCUAAIAcCEoAAAA5EJQAAAByICgBAADkEOmgVBGP9NMDAABFFukk8alxozRyaEXQZQAAgJCKdFCKm3FSXAAA0GvRDkoxghIAAOi9SAelmJnISQAAoLciHZTiMdFRAgAAvRbpoBSLmZKOoAQAAHon0kEpbqYUHSUAANBL0Q5KdJQAAEAfRDooxczknOQISwAAoBfyCkpm9kEzm2NmC81stpm9u9iFFcLWvY2SxJFvAACgV8q6u4GZDZZ0h6T3OudWmdn5ku6RdGyxi+urh6o2SJL21DfroKEDAq4GAACETT4dpWGSvu+cW+Vf3iqppXglFc43zzpakjdWCQAAoKe67Sg557ZJeliSzOwkSY9K+nWR6yqIEYO987w1t6QCrgQAAIRR3oO5zeybkp6R9C3n3P1Zrr/EzKrMrKq6urqQNfZa5TBvd1tzkqAEAAB6Lt/B3N+R9ENJZzvnXsx2G+fc7c65cc65cZWVlYWssdcGlHlPj44SAADojXwGc1dKulLSac651cUvqXDK415QSiQ57A0AAPRcPh2l90mqkPRvf9fabDNbZGajilxbn7X48wI8MmdjwJUAAIAwyicoPSZpWHq3mqRxkt4uaVNRKyuAY0YOkSTd/mqoGmEAAKCfyOeot2SHy05SomgVFdBbDj9AUttYJQAAgJ6IdIIwM5lJpx51YNClAACAEIp0UJKkdx17ENMDAACAXol8UBpUHld9c7L7GwIAAHQQ/aBUUabGBEEJAAD0XOSD0uDyuOqbQ3FqOgAA0M9EPigNqmDXGwAA6J3IB6WB5XE1JRjMDQAAei7yQak8bkqkCEoAAKDnIh+U4jGTc1IqxfneAABAz0Q+KLWeGJeuEgAA6KHIB6WymEmSmlsISgAAoGciH5ReXVEtSbpt8qqAKwEAAGET+aC0ZU+jJOkvLxOUAABAz0Q+KKUcg7gBAEDvRD4oveXw4UGXAAAAQiryQemGz54iSTrlyBGB1gEAAMIn8kGposx7ivM27Am2EAAAEDqRD0oAAAC9VVJB6Yl5m4IuAQAAhEhJBKXRBw2WJN05ZU3AlQAAgDApiaCU9M/ztmF3fcCVAACAMCmJoLSrrlmSVNPYEnAlAAAgTEoiKB0wsFxSW2cJAAAgHyURlH7/qZMkSV8846iAKwEAAGFSEkHpvWNHSpIOGlIRcCUAACBMSiIomZnK46YEu94AAEAPlERQkqSyWEwtyVTQZQAAgBApnaAUNyWSdJQAAED+SiYo1TS26HFm5gYAAD1QMkFJkvbUJ4IuAQAAhEhJBSUAAICeKLmg1NSSDLoEAAAQEiUXlJidGwAA5KvkglJ1TVPQJQAAgJAomaAUj5kk6Z/T1wZbCAAACI2SCUpvO2K4JGnk0AEBVwIAAMKiZILSj88/XpJ0wKDygCsBAABhUTJB6fARAyVJu2qbA64EAACERckEpUMO8ILS1JXVAVcCAADComSC0qDyuCRp1trdAVcCAADComSCUsw/6g0AACBfJROUAAAAeqos6AL2p3NPOFjbahqDLgMAAIRESXWUks5p6ZaaoMsAAAAhUVJBaXd9Qi2c6w0AAOSppILS2cdVSpIampMBVwIAAMKgpILSQUMrJEm76pl0EgAAdK+kgtLNL66QJF32r9kBVwIAAMKgpILS9Z85RZI0f+PeYAsBAAChUFJB6fARg4IuAQAAhEhJBaVjK4dIksrjzNINAAC6V1JBycwLSIkkUwQAAIDuldTM3JJk5s3QDQAA0J2S6ihJknPSpDe2yzm6SgAAoGslF5TSdtcngi4BAAD0cyUblOgoAQCA7pRuUAq6AAAA0O+VbFBK0VECAADdKNmgFDfmUgIAAF0ruaD0kwuOlySlaCgBAIBulFxQGjG4XJL0jqsmBVwJAADo70ouKA0oiwddAgAACImSC0ojBpUHXQIAAAiJkgtKBw4hKAEAgPyUXFAaTkcJAADkqeSCEmOUAABAvkouKI06cFDrz5zGBAAAdKXkgpJlTDSZSBKUAABAbiUXlCTprLEjJUktqVTAlQAAgP6sJIPS+46rlCQlmZ4bAAB0oSSDUnr3Wwu73gAAQBfyCkpmVmZmMTOrKHZB+0PcH6b09iteCLYQAADQr+XbUfqcpNmSaopYy34Ti1n3NwIAACUvr6DknPuXc+7tkuqLXM9+8eIb24MuAQAAhEBPxygli1LFfnbqUQcGXQIAAAiBkhzMfezBQ4IuAQAAhEDBgpKZXWJmVWZWVV1dXajFFsWbDx7a+nOKKQIAAEAOBQtKzrnbnXPjnHPjKisrC7XYojj+kGGtP8/fuCe4QgAAQL+Wd1Ayb/KhSBwulnkaE/pJAAAgl550lAZJGlisQoISieQHAACKoizfGzrn6iVFbhQ0HSUAAJBLSR71lmnOut1BlwAAAPqpkg9KgyvybqoBAIASU7JB6eKTDpMk3TlldcCVAACA/qpkg1LlsAGSpIZEJCYbBwAARVCyQenkUSMkSVv2NgZbyH7gnNPJlz+v+19bH3QpAACESskGpeaWVNGW7ZzTa6t3yrn+cUxdMuW0tyGhXz6+MOhSkMPpV03SWde9FHQZAHrhG3fP0pjxE4IuA0VSskHp1NEj2l1eub1Gm/c05H3/NTvqNGd99iPmHpu7SZ+9faYem7upLyUWTP+Ia+jK9pombdiV/+sPQP8x6Y3tQZeAIirZQ74OGz6o9ednFm7RpffNkSQt/O35kqRhA8u7vP85f3xFkrT22g91um7dzvp2/wct1U86WwAAhE3JdpSGDGjLiL94rG2X1Nt++7ze9tvn+7Ts9BlS+suut35SBgD0yKY9DRozfoJmrt4ZdCkoYSUblDLtrk90+l0y5TRr7a4e7Y5LM//EKP0lnyzatFdS+3PcofQ8MW+TnpjXP3YHA/l4zQ9ID83aEHAlKGUEpRxumrRcn75ths7+wys9vm9bR6kwtTQmktpT39yr+76+Zpc+dduMwhSCUPv+g/P0/QfnBV0G0GP9pTuP/KVSTj/+z3zN37An6FL6jKCUw+LN+yRJzcmeHx3X177NQ7PWa1V1bevlj/91uk753Qu9Wta6nXU9uv3vnlqib9w9S5++bbo27OofY6wAlCaa4OG1o65JD8/eqK/fXRV0KX1GUMqhLwOgWztKvdz59rNHFupDN09pvfzGln29riVTPtucu6at0aQ3tmvW2t366ysrC/K4KIy99Qnd/OIKpVJ8u+6vGhNJ/adqAx2QAluzo2df+BC89FsgCmG3pIPSiMG5j2zL97NoxbYaPbNwS7vfpccC9WVb2ZhIaXdds3bUNvV+IWo/TopNd7j9+slFuv6F5Zq8vHq/PJ5zTmPGT9D1LyzfL48XpKaWpLbt6/vks394bpl+8vACvbyMw8ULYV9DiyRp/sa9AVeCnmoNSsGWURAlHZQm/+ScnNfl21E674ZXdel9c9SY5VQojYmU3nnNi3p5af4bzcxuwduveEHjrpyU932709MXbMdVkEimtGDjnkKVgx5a63+r7s3u4N5IP86tJdBZ/M59c3XG1S/2eTnba7wvNjWNLX1eVina2eGLYbGnNnHOaW7GfHiJZEqnXvGCnpq/uaiPWwrSe1ToKIXc8EG5O0o9fX8u3VrT2m5PvzA27anXlr2NuvypxXkvJ9nFA/e1nd/XTc7VE9/QR26Z1m78VFi8smy7mlrCfV6/9Lfqldv3z/pvSXqvmLJYcTcTVWt3tR6ZGZRJb2wL9PG7M2HBlnYhojGR1JjxE/SvmesCrKqwXl1erdOunNSjL5Z99eCsDfr4X6fr+cVbJUm765u1q665R9tsZNfWUQp/UirpoNSVzG8yizbt1faartvyH/vLNL3n9y9LkmJ+Ukp/wCSS+UeUZBf7/G6bvDrv5RRCx1w2Z533zWtryM6PN2f9bn3lH7N07TNLgy6lIPbX+JdX/V18ZfHibug+ddsMXfznqUV9jHz1dd0WoxOxs7ZJ37l/jr55T9ug2F113lGwt7zUdbfvv+98Tadf1fuutHNO17+wXCu31/R6GflKn+lgbo4zHhRD+ktH58mBw//hHrT0O4mOUoRlbi8v/vNUfeBPk7u9z6Y9DfrG3bO0t8Gbl6mts9TQ+s3vXzPX6fnFW7VtX6NeX7NLc9bv1pjxE/Tg694Ja7tqNT+zaEvO63Ip5Gt02z7vG+1PH17Qq/svy+i67U87a70PldXVdUqmnK555o2swfexuRu1r7HznFp91dyS0pjxE3TrK6t6fN/zb5isH/9nfrvf9XU+LOecapu63zWUnq2+LNa/t3R76xM6+fLnNWvtrj4va1X1/h00vK8xoTunrG73vli2tUYvLGnrcKW/aG3c3TanW/rW3f1ppq7c0bo7sDf2+AcQfP6O1zRjVf85f2WhpFdf64E3BRiAvGDjHo4YVtuXjv699cgPQSmHGR1mgt3njzmobWrp8k0w6Y3tuv+1zqHnl48vav3/kntn64yrX9Rn/jZDn/jrdEnS+Ee92cH/MW1tzmVnvuBWbq/Rzx5e0NqBqmlM6J4Za7vckPV0I9fxqL10ANzUi0k4X166XRfc+KoenbOpdVn5nph4X2NCS7f2/si/9Pixycur9fSCzfrb5NX6wUPz2o0rW7Rpr37w0Hz932OLWh+zUN+i06Hk98/2vKO1fFutHp69sd3vcm3EnXP6zn1zWjtBufzk4QV662+e67ZLmlYW79+biap1u7S3IdFtdyUfH7i++y9EvbVtX6PueLV9KPrlY4t05YQ3NHN1W8i74MZX23WPsv2902MZiz2JbHooQHVNkz5/x0wd/fOJSvRijNy0lTs0ZvyELo/gdVlaEJmbrMZEUg3Nhd193nH1tZbQh2V+5JZpOuu6l/uwhPyt31mvd1/7Ur+cSLbtqLfwR6X+vQXsZ+6cslqfunV6t2+CdADoyS63txx+gCTvqJmc/Bfcib9+Vh+4/lU9VLVBl903W5J0xdNL9OsnFmvayp2asWpnlx/KO2ub1JLHxi5zI1Xf3KKGLAPW87V8mxc60hvKky9/Xt/+1+y87nvSb5/XhTdOafe7hRv3dhlYm1qSevMvJuqxuRvb1Z2ecHHayp36r18/2/r7dAjc4X/7/vStM/SB61+V5M1ovWJbfqHptdU7tXVvY84PhAtueLXPnY9c+/ydkyYs3KL/uev1Lu+fDl6b9+QXlIJuKDnntLCLo57S87T0p15Htu8kl903R1dNfKNd1yodVvtrpyZbhzuzs5Wv5/wxQK+v2aUx4ydk3T4t8d8z1RkdsMzHP+u6l9u9ZwuprsnbRnQ8pD2Zcpq9ruv368bd2bdD2Q7wyfe++br22Te0aU9Dv55INp+xoc8t3qprnnljP1TTOyUflF7/xbl53/bKCW9o6dbuPzDTH8xz1+/Je9npCS67kp7htD7jW9Vzi70WffqN/t9/f02fv2Nmzt08dU0tOu3KSbri6SXdPl56EzVr7S5dNaHtRdzdF4TnF2/NuWsn874vdTFoc9GmvZq0ZJt217XNSJ45NurDt0ztMrBu39eklpTTDx6an/NDKP3rM66epG/d64W2ijLvLbEsIxh9/8F5Ou+GV9vdd29DQqde8YKqMkLP9x+cq8/ePlNnXvOiLrppiqas6NzZWbatpt26H//IAh398wk5n0c26eCyo7ZJ985YK0naXdes+T08IjGZcrrknip97C/Turxdepdrob2ybHtes/beM2OdPnzLVE1ZUS3nnG6atKL1CMD+Ktt7ZJ8fxues263bX/Xen60D5rN07ZxzSqacpq/aIUntdqGlX7sdx9k/NX+z3nHVpKxdH+dczzuzWd46LyzZ2qNF/Pg/89vC+V4vZGXbPqUHq2fWHstYkdV92IX4xpZ9Wb9YpbsdN724QrVNLW1HavlfRv7y8kp98tYZOb/cbN7T0Do2taMf/dvbZX7F00t0/C+f6XT943M36T2/f7n175uvWWt36f1/eqXX3TXnnP70/LKi7x5Mh9wdtd2fVeJb987W3/bzGNyeKPmgdPABA4u27J7OgZTvrqiOfvbwgpxjmzq2PdNjcO6esU53T1+ry+6brXFXTtLra3Z1mkfm4dkb5ZzTp2+bofv83YmSt5G+/dVVWb8prNxeq0vuna2fPdJ+HFO6ujumrMnZum9oTuqd17yoqSt26OI/T9U37qnSroxTt/zPXa/5j9/2XMeMn6BfP7Go07IyJ6jrbk6sbfuaWoNdx+5JxzFLN7+4Qg+8vl7zNuzRrrpm3fTiCklecHpiXvuBvF/6++tZn+v6jA3Ug7M2tOs+rK6u1ZjxE3TNM2/o5Mu7Pjnzd++fo189sVgrt9fo7Ve8oI/7u3GzuXNKto2Q0/NLtmmeH1ZueGF5QVr4W/Y25HVk5Ff+MUsf7SakSW1dyI27G7R1X6NumLRcX/vnrD7XmStAv7x0e48/vDovu/Pv0m/Fnz6yQFdPXKrddc1q8V+c8Sxtu39OX6tjfzFRT87rPEA8/X7P7C5+9Jap+t8H5qq6pkm1WaYneGTOJl144xS9tLTzEX655pDK9t7pSadc8rYj6S93989c3+l655xSKdd68MvRI4e0Xnei32k/tI/b6YtumtLpi9WGXfXtzlyQDrJS299qmf/FONcBLF2Ft/R8Z3+fukZN/rbdOde6nU8PXl+ex5fvTOMfWaDV1XVa2MsjRdfsqNOfX1qpS+7Nr6PfW5mvzWyvuTAp+aAkSd87d+x+eZzugtAl93Y/1ftjczd2+t1DVRv0zKL8vuXtyujQ/ObJxZq4cKt21DbpM3+bkXUemaYcNV89camO/+WzumqC1x35/O0z9ZeXV2pvg7f8TV2051dsa/sQTQ9il6QV22u0ZW9juxZs5qHCy/37dRyces+MzodIZ27Yutqr0bHztahDZ69jWLn+heX6+aML895VMvb/num0Qdvjn4Q52wzb6bDzt8mrW3cHdjRy6ABJbYPUn17Q/SD/Kyd0bmt3fAo3vbiiIC38d17zks7N4+CHjsaMn6Cb/eCZqS0UZOzWTmXvmOTrn9PW6OifT2zXsUz76j9n6Qt3vKaFG/fqxRzTBqzcXqMx4yfknDE6HYb3NSZ05dNLsn6p+Me0NWrxn8euuuZOE4k+Msd7r7+8rHNnMtsRRZmTMsayBK8l/mt7dYcB688s3KIzrn5Rl2bZFd7beYwemb1RR/98QqfnnW1p77hqko75xUS97ndtMocfpB/+kOFtQWlnbVNe3ZA3tuzrMvifdd3LrR15ydvWdT76zZO5ntftrNOY8RP0bJZtbnfj/u6atlbH/fKZdgHLzOSc0y0vrdD6HI+fKb3r9pHZnT8LeqKhue9zfTW1JPP6UvSbJxcrmXJ57Y7sjwhKkn7wgf0TlLobKPpKlg1iRz94aH63t8kl5aQP3dyzw7B/80TX84ncMWWNnl20VTNW79QfnlumT97qnYB33oY9mrZyh+qbW7RmR53+XdV29u+6jDdoehC75I3hkNrvhuz4AZ/K8WZ7edl2jRk/Qfe9tk4vL9uun2Z0tLra2KfnT0mrbWxp16HKvOsHb2obJ9X2QeVtQbsax5MZBjNlmzMrVziSpBMP875dHzbC+9BIP6+debS2s+nJruGu1De3aMz4CbrH3w3YF9lCb7opZ9a22znb3E5TVuxQMuW0dkdd1tA0a+0uTfBD5cN+CNmwuz5nwPrwLVNznqcqfVDCQ7M26LzrJ3eaByo9m/mNL6zQnVPX6OHZGzuNLYvFTIs2ea/1b95TpS93GFsW72L+qvRBHOt21uu6Z5fqhF+137XTMYQ75zImAGxfx6y1Xmcj25etbGsm8/134q+fzdrRvXLCEjnXeeLNbOs6266Z5paUlm+raXusjPuNu2pSXoOlL7ppSqfgvytLME679F+z9bnbZ0rqepqW9Ptm4sLOX1BOv6rty2a24QePz/VeN1v2tn2RTDmnb907W398frm+frfXKX1i3iZNW7lDG3blfn1uydIFbEwk9djcjV0f1OP/HyvAIOsP/3mqzv3T5Kwnbc/c7jonHfuLiTrhV/mNMVu5vbZfjdsjKMnbcJx85IiiP876/XzIaENzMuc34nw9lBFwclmyOXsL+It3vqYTf/2czvnjK+2+xX7p7691fpxZ6/MaJLqvMdE6nijTV//hbWD+77FFrT+ndRWUfvjv9sGzIZHM+mEttQ02ldR2GHG3FWf/AJK63hh3VNfU0vr4X7jDW3/pb5avrdnZ6fY/f3ShVlfXatnWmtYB/x3NyZiv5sqMcVOPzd2YtbMjeR90q6rbb8TSQe1vk1d3OlIwlXKtt21MJFt/zrURzAycG3bVa8z4Ca2dFZO1dhvSnZzNHY7A/Mo/XtfZf3xF/6lq+7btnNP0lTv06dtm6Dv3z9ET8za1fkg0t6TyPl1RTWNCNY3tp/6YsXqnVmyv1cV/nqq/TW4/7mbp1n1q9Dsq2Tqsr63uPO4lc9B6to5j+m+W+Zr+6yur1Jho32HrGMKda5sryOSF2/Ru5WSW7twn/jpNb/3Nc1lr+Mc07+jaTXsaVN/svV9SKdcuLObqRGcu7frnl+XswPzphWU6/4ZX9b0H5na6X/qprdlRp18+vrBH76NTr/BOLj5mfOdxgZnjTzsuMnN1/mP6WklSeR5Hg/7isYXtLmfuMk0v8/Knluh5fzqIFf68Tt9/cJ6+eOdrOuu6l3VXjiOhmxJJTVzYfttyxdNL9IOH5rc7avvOKat1/g1tX9Jb33vWfRd2zY46/fzR3Os43eWv7zBeanddsyZkBMlsDzNx4ZbW4JhWtXaXrnh6iT5w/WQ9NGuDdtQ2qS6PqUyKrSzoAvqLh7/9Tp159Yva2cU3jrAp1hEiHd3cw8OyO27U65tb9LNHFua4dXvPL9mW14D6TNdMLN5Ek5OXV2fd6OajJ4NTb+vwIfyXl9vW+fJtnVvfD7y+Xg/k6GSlZQa4O6euaf05W9dyzPgJWn7lRbr2maW6a9oavf2oEXrssndLatvNk3Ku9UhByTvlytl/fEWS9Jlxo/Tvqo360XnH6X/PHasHXs8ewM2kKSuqdeJhB7Q7RF6Sbp28qt2uroUb9+rDt7TvkE5Z4Y0tWrhprz7zjiN18Z+ntHZt0v5dtUEL/EBy6yurdP1nT8laS9rfp67R/7xztN72W2837NprP9TaHcocjH5NhwlNL7xxis4aO1KSF2YGlrf/YJ2xeqeOHjmk3XPq+Hw6+sRfp2v+b85vHQSey51T1mj8RSe0e6z0wRNm0om/fk6S9N1z3qy7M74YTF+1Q0eMGKQ5ftck2wdcbVOLZq3d3e753Dp5lf7w3DI9dtm79PajDmz94Ox4CqbM5d380spOu7rT0gN7a7r4kPzu/XO0ePM+fe4dR+mtRwzPebuOXaR0WOrKjtqmdl2SzNWQ/ps3tiS1O0snJdP9GWM7GxPJ1m65We6DYjp+2Zi1xgsPwwaU6dCMXZDpXfiZNaeHHNQ3tQWXjl359N9gdXWdjv75RD33/96r4w8dJsnrZA0fVK6zjz9YUts6/sLpR+lto3Kv48zaK4cO1KX3zW435UXmlDLXPbtUP73whNY9CB97+xGt133qthmtPy/evE/jH12oYyqH6KUfnd3tYxcTQclXHo9p9q/O0+x1u1p3H2H/OOm3XQ9aztSbyS77Mq1BLl/t42Di6at2tHaG8vHnDmG0y2kkimRHbZPumuYFqrnr92jO+t064dBheve1L0mStnQY8JoOSZL0b7/D86cXlmtgeTzniXa37WvSl/6efXqDjuOBsnXS0u6duU735nF6jxeXbu920PwVTy/Rjb08MfCCjA5Rxy8IUufnlCnXYN19DYluxw7dNnlVu6B0yT3ZdyHe8nL711XH12Suk/smU65dlyHdCevprP1dHfmaKd+9MI2JpMykzCZZx2DU1e63TF+447XWLm620wZNWLCldVduPrZnHD26ZW9jzm505pcNSXrWHx5Q09Simow6lnWYsuSy++ZoSEVckvSNe6o08XtndToqUurcbbzgxle1/MqL2k0zsPbaD3m39f/GmcupbWrR+657WZe895jW313x9BLd8oVTO9WezV9fWaWfXnhCt7eb6XfFOo6pCwJBqYPTRr8p6BJKTksPWudR0ZOQ1F90DGuf6OIou65cNbEw86Usz3Nuq46mrcwdsHLp2NnId/6brsac9VZvJjOsy9g10pO322+ezD5G8fN3zGx3Of1hfturq7vchd7bLy1dHeHlnLcLqbq2qd0Yob7K3NV+84srdPOLK3TRWw/t9fKeXdwWqr55T5UuPumwPtXX0etr2u/K/eDNU3Ta6ANbLzvnZGZZu5G/fHxh65eZzNumd9emj8pcsHGPPnKLd6RqZgf1mUVbs06Hkks+XfgV++mclvkgKGWRTtO765r1+2eX6vF5m3Rs5dBOcx29580jNXVl3w4jBsKiu115+1vmhn1/2ri7Xo9nOWS/v+k4o3vak0WcxXn+hj15zY1VCOntsZPT9x6cV5Tz7HWU79HF2VzdYQhAPker9tXsdW3jEB+atUEfOPGQrOdV7HgmikTSacbqHa3B1mRaXV3b6ctSpq/8o3dd9r31hf8yUWhWjJHl48aNc1VV3R/qXkpqm1q0u65Zow4cpJSTfvLwfC3fVqNFm/bpmMoh/aK9CABh87MLT+jV6YFKzdiDh+rT40Z1CmySN14qMwoc9abBOu6QYZrUx4OBCmXZlRdqQFm8qI9hZrOdc+OyXkdQCqf0323DLm8SvtOPbttlmEw5nXH1pKyH3Y49eKgevORMnZYxyPL1X5yrfY0trdMXvP+Eg/XWI4bnPPIpl8+MG6XBFWX6p39UCAAAfUVQQii1JFNqSTkNLO/84q1pTGjj7gadcOgwmZnmrt+tldtr9cDr61uPpjn/xEN03CHDOg0mTfv3t96pz/yt60H1Zx9f2W7uqaVXXJj3PB0AgHD4wQeO0/eLPN8hQQklJT0QMf2z5B1xNKgi7g2udd4g24MPGKCKeKz18HbnnB6ft0n/qdqo6ava9tnf+/XTddbYSq3dUaev/nOW1uyok5n05sqhOqZyiFZsr9VHTz5C/33mUUo56aoJS/T4vM364hlH6ayxlbr2mTe0NmPG3bKYdTmAvSIe0+iDBuuFH75PkvSvmev0y8c7T+rXU6MOHNTtXFUjh1bkdW4mANif0mOHi4WgBJQQ55waEkklWpwqymKKxdTatk6mnOqaW3TAwHLtrmvW+l31qhw2QHVNLRp7iDeXSmMiqYHlcW3a06DDhw+UmWnr3kaVx00H+adPeW7xVn37X7NbxzXc8T/jNGHBZm3Y3aDZ63brwrccqmcXb9Vnxx2piYu26NjKoTrvxEM0bGCZbpq0QjvrmvX9c8fq1NEH6q6pazqdvuOtRxzQOv/RQUMq2s1vdt6Jh+iFJds0+qDB+sB/HaJH5mzUnvqEvnjGUbrq42+T5J1YtSGRzDr1xCdPHaWn5m/WV98zRhe/7XDta0xo+KByHVM5pHV+oZNHDW93SpB8HD58oDZnHB7/32cepW+85xgdOnygLn9qcc65o4Du/Oi84/Tysu2tHflSRFACgBLU3JJSedzraDa1pBQzU3ncZGZKppxiJjUnUxpQFte+xoQGlcdlksr8WaGd8+YzSrm2TmVtU4t21DZpxbZaffBth3Y6ZUlDc1Kb9zZo2MAybdvbpAOHlGvUgYO1tz6hAeUx7alPtE6keGzlUO1tSGhgeUzDBpZnfQ6b9jRoYFlMBw0doJrGhL5xd5XOf8uh+sq7xmQ92W+mHbVNWrJ5n+Zt2KMj3zRI5/7XIXplmTfh6IptNTrvxENan2sq5bS9pklXTXyj3RFuXzpzdOucWdd84m36+aML9ZV3jdF/HTZMnz7tSCWd076GhA4YVK7yeEzJlNMvHl2oh6o26LpPndQ6N9v4i07Qra+s0o2fPUXnnHCw7p6+Vm8aUqEV22t119Q1mvOr83T1xDc09pCh+tgpR2jCwi1688FDdepRByqZcrr/tXVqTHinXtmyt1FfffcYrd9Vr8ufWtLuOb/nzSO1o7apdeLcr7/naJ185AjtbUhodXWt6puSeqhqQ9ZxORMWbNFvnlyk0QcN0erqWu2uT+gTpx6hR+ds0psPHqrt+xr1jjFv0kFDK1qPCj37+EqNOWhIu7GjPzzvuE5zmX3t3Udr1IGD9Lun29fb0a8vPlFjDxmqg4cN1OrqWl163xzd9LlT9NT8zZr0Rud5sb537tjW8a4Tv3eWPnjzlE63yeUD/3WI4jHp2+87Vm8/6sDu79AHBCUAAIAcugpKnOsNAAAgB4ISAABADgQlAACAHAhKAAAAORCUAAAAciAoAQAA5EBQAgAAyIGgBAAAkANBCQAAIAeCEgAAQA4EJQAAgBwISgAAADkQlAAAAHIgKAEAAORAUAIAAMiBoAQAAJADQQkAACAHghIAAEAO5pwr/ELNqiWtK/iC2xspaUeRH6PUsE4Li/VZWKzPwmJ9Fhbrs7D29/oc7ZyrzHZFUYLS/mBmVc65cUHXESWs08JifRYW67OwWJ+FxfosrP60Ptn1BgAAkANBCQAAIIcwB6Xbgy4gglinhcX6LCzWZ2GxPguL9VlY/WZ9hnaMEgAAQLGFuaOEbphZhZmZ/3PczAYHXVOYmFmZmcXMrCLoWqIg2/r0L5dnXB6YeRkImnkyX7MVZjYgyJqwf4UyKJnZaWb2ipnNNbMXzeyYoGvqp2ZKmmdmVZJmSfqdJJnZV8xsmpktMrO70gHKD1PXm9lMM1tiZj9ML8jMDjKzx8xslr/ezwvkGe1fn5M0W1JN+hf+RvNnZjbDX0d/MLOYf90gM7vbX3+LzOwLGfc72syeM7PZ/n1PzbjuIjN71cwW+Os46yGqEdBpfUp6q6QdZlblv05fk3SmxPrMh5l90MzmmNlCf1282/99Qd/jpbLNzbE+h0nal/EafV3Sx/zbsz67YGZf85/jIn8dnez/PlyvT+dcqP5JGiJpraQ3+5cvljQt6Lr64z9JaySVdfjdO+W90YdIMkl/lHSVf93PJP3V//1ASVMlnedf94ykz/g/j5G0SlJl0M9xP63H3Rk/f1bSk5LK5X3R+Lekb/rX3Srpp/7Pb5K0RNKJ/vpcKOld/nWnSVomqULSaEkrJI30r/uupPuCfs77cX2eJ+muHLdjfXa9HgdL2iTpWP/y+f77sqDv8VLZ5naxPsdKeinHfVifudfnCEnPSjrQv/xZf52E7vUZ+Mrsxcr/hKQHMi6bpO2ShgVdW3/6Jynuv+nvktdNelDSYZJulvStjNu9RVKV//MCScdnXPcd/0U80l+WZVz3H0kXB/0899O63JHx85OSLsi4/CFJD/uvw92SBmdc9wd5H9SnSprRYZmz5HVTfijpmozfD/Nfz1aM59If/nVYn1+W9JSkF/x18lN/XbI+u1+Ph0j6VMblk+QFxoK+x0tlm9vF+nyfpFclPS2pStLvJVWwPnu0bs1/b/81jK/PMO56O1rei1eS5Lw1M1feN020OULSUEl/kXS6pMmS7lCH9ef/PNrffTRK0uqM6+bIexGPlrTCX9cdrys1Hddfej28SdJe51x9lus63ifndc65GnkB4eCCV94/jZbXnfuEpHMkXSjpk2J9dss5t80597AkmdlJkh6VdLkK/x4viW1uF+tztLxt6dfkdUOOkPQ9/26sz26Y2W3y9m58XtLVCuHrM4xBqUlSY4ffJSQxuK69DZIOds7N9l84t0l6h6QWtV9/SXndJ5NU51+fll6vrPM2HddFej00S2rocNt81l+pr9srJX3YOVfjnKuVdIukC8T6zJuZfVPebolvOefuV+d10Nf3eEmt0yzr815JZzrntjvnEpKul/calVif3XLOfds5N0Ze6Hxa3ns7VK/PMAalRfL2GWc6Xt4+Svj8cNTxhZKSN7Yjc/0dLm/MSFLePt9RGdcdL++bwHJJY8y8I+g6XFdqOr7+jpe0xu9cODMb2PG6LPfJeZ2ZxSUdKWlL4Uvvl2LyxhZlXm5mfebHzL4jb3fj2c65F/1fd1w/fX2Pl8w2N8f6NLXflsbkfdhLrM+czDuC9bD0Zefc4/Lei9sUttdn0Psue7Gv8wB5bbax/uWLJE0Juq7+9k/SMZLWSzrcv/w1eWNp3invaLj0QLrfS7rCv83PJP1ZbQPpXpV0rn/dM5I+6f88St5Jj0cE/Tz3w3o0STszLn9W0uOSyuR9C3pA0tf9626V9CP/5+GSlko6Tt6GdYG8b6WSdIq8N35c3qDExfK6f5J0qaR7g37e+3F9/krSP/x1NEDSJPlj31if3a7LSnm7FY/p8PuCvsdLZZvbxfr8kqTn/ddnTNLdkr7L+ux2fX7Uf18e5F8+S9JWSe8O2+sz8JXZyz/Au+UN3pwlaYKkI4KuqT/+k7dPeKG8fbmPSjrE//0l8lL46/I+jAb4v6+QN6ZpobzDtL+Tsawj/HU9V9I0SWcF/fz20zocLKku47JJ+k3G+vudpJh/3XB5wWm+vyH4ZMb9TvTf9LMlvSzpxIzrPippnr+8hyQND/p578f1OVjSnf76nOtvKNMT4bI+u16Xn5K3q6LK/zfbX4+jCv0eL4Vtbhfrc7Ska+UF8LnyBheXsz67XZ8m6SfyQswcfx2c7l8XqtcnM3MDQAj5uxWdcy7lXzZ5nc4Wx4a9x1ifyIWgBAAAkEMYB3MDAADsFwQlAACAHAhKAAAAORCUAAAAciAoAeh3zOwQM/tu0HUAAEEJQL9iZhXyJpH7upmVm1lZ0DUBKF0EJQCB8sPQ42a21MyWyjvL+OPyTkNQJeldZnaYmT1lZvPNrMrM3uHf93Uz+6mZTTezBWZ2kz8fDgAUBEEJQNDOlRR3zp0gbzb5BkkfkrTEOXeyc+5VSTdJutk5d7K8U0rc7U8I2CBvVt6zJb1d3qzUn9//TwFAVBGUAARtvqQjzOw2SUMl3ZDlNudIusLMZso7N9wgSYdKcpJucM41O++kmvdKeu/+KRtAKWDfP4BAOee2mNlp8k7m+kVJV0j6SpabXuSc2y1545icc83+ycQzzyjOlz8ABcVGBUCgzOxL8k4uPEPSr+TtQkvI6xrJzGLyTnz7Rf/yWEmvZYxF+r6ZVfiDvr/s3xYACoKgBCBoEyS9TdJSSTMl/VjSZknrzGy+pPdL+p6kC8xsnqR7JF3m72qTvLOMvyJpnqRVkh7aj7UDiDhOigsgtMxssqTvOucWBl0LgGiiowQgzAZJGhh0EQCii44SAABADnSUAAAAciAoAQAA5EBQAgAAyIGgBAAAkANBCQAAIAeCEgAAQA7/H0jLWycR73DcAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10.0, 8.0))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_title(\"test data NLL Loss\")\n",
    "\n",
    "ax1.plot(test_loss_stack)\n",
    "ax1.set_xlabel(\"step\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x576 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAHwCAYAAACCIeo1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABk8UlEQVR4nO3deZwcRd0/8M93d/bI3tlkd5PsJrs5Njc5NyEX4UhIAgG5ISAociogIoeCoqKI4E8fFRVEvEXheVQUeORRFAHRcIb7hiDhhoQjByHnbv3+mJ7d2dk5+qjuru75vHnlxc5MT3dNdXf1t6uqq0QpBSIiIiJypyTsBBARERFFGYMpIiIiIg8YTBERERF5wGCKiIiIyAMGU0REREQeMJgiIiIi8oDBFBEFSkSuEJE/hp0OIiJdGEwRFRkROVtE7te0rj+KyDcdfm0bgA9srv9hEfmU85QREQUnEXYCiCg4IlKNZCCzVUQSABJKqe0u1pNAsvxIrasSQLdSapeNr3cD6Cmw/nLrz9T6BwHYqZTqdppWIiK/sWaKqLi8COAqAIsBbAJwIQCIyH4i8pCIbBSRe0SkK/UFEVklIi+IyGYRedD6bCKAjQBWAfiC9ffCzI2JSImIfE5EXhKRN0XktwBq0j5PiMj/E5FXRWSTiNwhImMBLLPWuQDANVZaR+ZZfgBJOt/a9mYReUBEZqd9fqiIPC4i74vIv0Rkatpni0TkfuuzNSKyt/X+NBFRIlKRtmxvTZ+IfEdEbhSR60XkLRH5jfX+XBFZbeXvayJyXtr3R4rIzSLyjog8JyJnWe+fISLrREQytvVozr1LROFQSvEf//FfkfwDIABOBHB72uvRALYAOBzJ2qZDAbwOoAFAHYDdAA4GUArgbAC3Wd8TAL8EcHFqXVm2dwKAFwCMB1AG4KMAtgP4pfX5pwE8BGCYtb1bAPwmtS4AdwE4Pm17WZfP8VsPBvAygHEAqpAMyv5tfdYF4D0AiwCUA/gUgHcA1AMYiWTw9hErzYcg2TQ5xvrXk/5bAZwE4A7r768BUFZelgKotv69Yi1XCmBfa5lx1utHAXwdQCWASQDesPKpFsBmAFPTtvV3AOeEfRzxH//xX/9/rJkiKiJKKZXl9bEA/qyU+qNSardS6iYAjwA4EMkg4n0AUwE0KqW+r5Rariz51m35OIBvKqWeV0rtUkr9FskAKOXXAA5SSr2llNoI4E8A2rKt23ov6/I5fu4dAPZSSq1VSn0I4H/Slj0FwE+UUv9WSu1EMtBajGRQ+VEAf1VK3WKl+WYAM5EMiHoA9GSkrwd9zZY9AO6x8rJbKbXVysP9AfzCeu9Oa11tAOYAaAbwFaXUdqXUM0jWxt2slNpi/d6TAEBEWpCs/fttjt9LRCFhMEVEIwEcZjVBbRSRjUjWnnSqZB+ohQAaAdwjIreJyKEO1t2KZO1QurVpf+8C8CkRuUtEngfwwwLrc7L8DgBHisjtIvI0gJvSPmtPT4cVqz2tlOrJ/Mz6/Fml1O4c25GM189kfLcHyfz7k9WU+iaSeZ5Kx0sqrS+YUmqdUirVQf/HAD5mNSseBeAvSqkNeX4zEYWAwRQRvQrgaqVUQ+ofgCal1FetjuZblVIXINlU9xUA/yMio2yu+xUAmX2aJqf9/QMAUwCcg2ST2/kF1udk+YuQbLL8AoAlSNbApbyKZDNbLxGZJCJlOT7rTHWCB1BqdeRP2T9fgkWkHcmm0d8gGRCNBfB2WjpGi0hp2vKtIjIEAJRSTyAZnB0G4DgAv8i3LSIKB4MpouKzE0CziFSKyFAA1wM4yup0XSIiMwA8KyILAMwAsE5EliPZf6gayX4+Km1dw0WkLiPASPktgAusDthlInICgAPQV/bMArAawBNI1mKdjf7lUmr9TVZgV2j5dLMAPGz9q0EyqEot+zMAp4rIXtZvXgHgHgCp/DjA6qBeKiJzANwLYAKANwG8BeATIlIhIqcAWJ623pIs6ZmBZB+sfwBYD+A8JPt8lQB4AMm+Wpda+2MYkjVox6V9/0cALgbQAeCvOX4rEYWIwRRR8bkbyY7NbwA4WSm1DsmO4t9DslP2DUh2Kr9HKbUGwGkAvmt99iMApyilXrXW9XsA+wF4DsDcLNu6Dsl+P39EslP7gQC+jb4n+r6IZKfyDQC+CeBGJDu9p/wawJkA1iBZo1No+XTfQPKpwHcB/ArJIKUOAJRS9yPZb+pq6/OvAjhAKfWmlR8HIRl8vYNk4HWiUupRq6/U6QA+g2St0t7WcqlAsgbAoIx0/BXAfUg2dz6KZIC4DkCd1XR4MJJ90l5DMqD7E5JPXKbcCKAFyY72uZoaiShEqSdmiIjIQJIcw+sNAAutDupEZBgO2klEZCgRaUWyye9pBlJE5mIwRURkIKs/27NIduJfFXJyiCgPNvMRERERecAO6EREREQeMJgiIiIi8iC0PlNDhw5VHR0dYW2eiIiIyLaHHnroHaVUU7bPQgumOjo6sGbNmrA2T0RERGSbiGROjdWLzXxEREREHjCYIiIiIvKAwRQRERGRBwymiIiIiDxgMEVERETkAYMpIiIiIg8YTBERERF5wGCKiIiIyAMGU0REREQeMJgiIiIi8oDBFBEREZEHDKaIiIiIPGAwRUREROQBgykiIiIiDxhMEREREXnAYIqIiIjIAwZTRERERB4wmCIiIjJAT4/CN//6LN7YuE37utdv2Y616z8ouNwjr7yPZ97crH37mR56+X08+upG/GfDwDT9+t51+PE/Xxzw/srv/wsdF96Knbt7fE+fUwymiCLm7c3bsatbT2Hy6nsf4n8fe0PLuvx2z4vvYNO2Xdj44c5+F5snXttk6+Lzwttb8O4HOwa8/8gr7+Ptzdt7X/9y9Ut49b0PXaVx7fotWLPuPQDAM29u7t1P3T0KSilX60zZ3d2DjR/uxNYduwfs/7c2bcedz63Heb97DEddcw86LrwVb27ahsv/8gze3LQND657D+u3bMeGLf1//382fID9vn0XXnpnK97fuhPPvbUFALB5+y6c//vH8MGO3f2Wv/7+VzDvG//o/Y0A8OambRj7hf8bsO5cdnX34PTr1mDqV27D5u27Ci6/adsuHPeT+/DmJucBxpubtuGiPz7eL7+UUrjqzrXY+OFOx+vz27f/9hx+dNeL+Oz/PKp93XMv+weWfuefOPSq1ei48Nacyx129T044Mp/5T1eOy68FQdc+S9P6TniR/fg0KtWY7//+ieee2sLfnPfy+i48FZs39WNL9/8FC7/y7MD0vDUG8kg7xYDy6xE2AkgyrR+83bc/OgbOGWv0RARz+tbvfYdzG4fjMqy0n7v79zdg909Pagq738avLlpGz5/4xP44XEzUVdZlnWdO3f34KAf/As/+VgX2odUe05jLj09Csu+dzfWrv8A665Yie27urHnN/6BI2e34dtHTXe93ve37sRjr23Eib94EACwu6cHh81s05VsAMn9eMez69HZUoNjfnwf7v7cvlhwxR29n6+cNhzfOGwP1FUmsu7nrTt24/HXNuHFDR/grU3b8cM71/b7fN0VK7Hxw504+If/BgD88YwFOPzqe3D9qXuiujyBQ65ajetP3RM1FQl85Zan8MgrG3u/l+6wq+/p/fuMfcbi6rtexDX//A/u+8IS27/1zufW4xNWXgLA/ztiGj534+MAgF+cOAef+OWDOGTGCFy5aqbtdWYa98W/9P6974Qm/OITc3H38xswd3Qj5l3+jwHLz788mdc//ud/Bnz2lYMn46v/+3Tf+r59V+/fd1+wL3635lX84aHXUD+oDBcsn4A7n12P/Se34At/egIAcOQ19wIAnr10Re925lx2+4C8zeb83z+G2556GwAw7ZK/ARi4T9JdefsLuOfFdzH/8jtQV5nA45csL7iN7h6FXd09OPJH9+L1jdswrrkWJy7owBm/fah329+67bm821VKYcfuHvQoharyBB5+5X3UVZZhXHNNwe3b0d2jUFrSd9y/uOEDXH1Xsjbmidc3adlGNo++utHWcmfd8AiuOm7WgHSmApxn3tyMnbt7UJ5I1sns2N2NV9/bZit/Nm3rH0Qv/97dvX+n39isefl9zOloBIB+we+3bnsWR87WW155JV7vltzq6upSa9asCWXbutz9/Abc+dx6fHTPdtzwwCuYPrIB697Ziu/8/XkMqS5HeaIE+0xoxg0PvAIA+OFxM3HHs+vx6CsbsXLacJy3bAKefH0Tvv+PF3DFEdOw/3f+icHV5aguL8UFyydiXHMN/vDQq/jhnWvx6f06sWNXN15Y/wHGt9TiDw+9hj1HN+LuFzYAEBw3dyS+f8daDKkux7tbd2LppBbUVSbw0rtbUVtZhruf3zAg/VNb69BUU4G3Nu/AM29uxqJxQ/Hvte8AAMpLS7Az7W7u/GXj8frG7ZjTMRjn/u4xzO1oxANpd6fplkxsxoPr3sPm7f3vaie01OKqj87CuOYa3Pzo6/jxP/+DRKng2be29Fbb1lYmsCXte+ftPx7/9ffn+61n0vA6vLjhg97vTBlRh8bqcvzrhWTaKxIlqBtUhutOnoudu3vwkR+uBgDMG9OI+/6TTPP0tno89trAAqumItHvbjyVJ0Oqy3H63mOwq1vhW7c9l/V3ZypPlGDn7h5csHwCFnc2YcKwWvz58Tfwk3+9hMXjh6K7WyFRWoJr0qqzz1naiavuXIujukbi+vtf6be+q46bhTOvfzi57tISPHvpCvz2gVewY1c3nn5jM/74yOuoH1SGaW31+NcL72CfCU0YVleJ3z/0Grp7kuf54bNaMb2tAV+55akB6e1qH4yDpg3HJdZFduW04bj18TcBALUVCWzZsbs3Pw6b2Yo/PfI6zl7SiWWTW3DQD/6NEgF6FPDTj3XhzufW47cZ6bebX3677ZzF2L6rG9NHNgBAzrv0o2a3YfXad3DMnFEYNWQQ/u+Jt/Dj42fjhJ/fj9Vr38VXPzIlaz7acdyeo7D27Q9w9JyR+MEdL+Dld/tqwi5eOQlfv/UZV+sN25Gz2/Dyu1vx4Lr3+71/8qLReObNzbjnxXezfu8TCzvwlYOnAADOvP5hvLj+A5wwvx1f/NOTWZefMqKut5Zi0vA6/M/p83pvfK69+0V84/+e9fQ7cpUP6V78xoF4/u0tuPnRN7Cruwc/+/dLOHFBB355z7oBy84fMwTzxw5BiQBlpSW4/C/J9LU2DMLrNmpVl05qwe3PvI26ygQGV5fj5Xc/hAjw9FdXoLKsBFfduRYzRg7G8IZKHPeT+/D25v61hHaOqcqyEmzf1f/8yyznF4wdknMfFtLVPhhDasp7g9lcVs0Zif9+8NWC61s+paXfun510lzsPb7JVdrsEpGHlFJdWT9jMOXOzt09GH/xXwovmMejX94fM772d00pioYVU4bhrP3G4aAf/DuQ7e3VObQ3yCLK1Nlcgxds9CNJufaE2Tjtuod8TFHxWnfFSmzYsgNzLrvd8XePnzcKXz90D2zf1Y2JX/qrD6kzU1NtBa7+6CwcZdUUFjs7NaNe5Aum2GfKpYdfeb/wQgGsI2p29/QMqOL1k85AataoBm3rIjM4CaQAYHdP383nwnFDdCen6P35cXd9YX5z3yt49NWNeOCl7LXlcbVhyw7c8qh5/YeKEftMubQlownLjZN+Gd2aObduf2Y9bn9mfdjJcKU2R/8pMs8Pjp2JT9/wiPb1plfk11bweNBlSHU5APTrx+XUoVet1pWcSLnuvpfDTgKBNVOuPfRy8dUqFbsS733hKSCjh/rzUIBCXzRVWsoDwqu5Vufid7fuxBYbT/YRmYrBlEvXZBkDg+Jt2ZRhWDqpJexkRM6qOSPDToI2PeldTMPpbhor1RV9T9i+t9W8oQqI7GIwFUM1FWy91W3M0GqsmjMSn9x7TM5lprfVB5ii6LjssD3CToI2/R7YYcWUZyVpQ2IIM5QijMFUDGUOtBeEA/cYFvg2g1RdkRwLKV9lROZ4VZQUp0skYym90ocXyzXUCpEdtZXhlr8MpkiLcc21YSfBV6lCP99IIt8+2v0gmnGmYdxVY/SENJRMfPUdHOf//rEQ00FRVz8o3AdCGEwROZDvYtraMCjAlESHjlHsnW/Tn/Wm95kK43fFDbOQ4oLBFGkR9zIx9fumsV9UUWPNlF4TWuJdo03BCfvUZDBF5AD7RRU59pnS6pylnWEngUgLBlOkBavrk06Y1x52EshH6eNM8Zj3LlHKSxDFA49k0uIvT7wVdhL8ZfPKuWJqvJ9qjJKVewzXvs6eiLbyjWqsCjsJZEP7EO6nqGIwRVo8v35L2Enwld1KiLDb7anPiIZK7euM6tAIZRytPRJYsx1dDKaIbGCTTrT4NQDkjQ+/1rcNHhREZGEwRVrwskImUVC+1BJyTk4iyobBFJENtpv5OGGbEQT5R6vXsw0ivVjbGV0Mphy67r6X0fnF/ws7GURUAPuvUdQwlHJPhXzCc9Ach75005NhJ8FIvG4l8QJeRHjlI81YMRVdrJkiLeIeRNitfo95NkRK3JpcLzpgYthJ0Gp8S03YSTBCetGSXsoMq9P/NCr5h8EUkQ28YYwevwN8v54YzKWqvNT1d03si9NYXR52EoxQkrZv0vdTdYX7/U3BYzBFZEMY16Kz9h0X/EbJNgPjE4qghkFlvX+X8JiKLAZTRIY6f/mEsJNAeQR93YtXo2XwNXum2qtzaN+LtAg9bvvbb2HnF4MpIhvsFvxhP1FCRN4EPVp8SY4qToaazoRd9DKYirmvfmRK2EkIRFf74LCTACD8uyPqk+sipQub+eLpjvP2CW3b6c18LEucCft8ZDAVc5VlxbGLR/o9kauLE/WQGSP0p4NsO27PkWEngfII++KXS3NdRbAbNDQfooY1U0RxknZC79XZFF46ipyCQkXC36eh2OfHG1ODKWNEsGrqyNltoW077KFQGEzFXNjRely4Kfd5rQiPQCJ37J++9xjf1q3jWFwxZZiGtZgvzCC5JOId0IfXF+/YWAymKBaCLP5+fMJsW8vxzjtcqTvVIREZzyjB5+KLUmvDoN6/o34EDK4K71wL++aJwRSRQ8vz3KGHXdVMA1VX+DNrVonm0tPPi0GYF7lCPr/CrJHdg74JOntJZ7Ab9NHH5reHtu2wS14GUzEX9gFWzMK+UypmIkHkf3TqEa766KywkzBAqjkt6KEITFNWmv0yHMVhVhI5fksxKN5fTvEScnmcuptNL//YzBeu1K6Iyn7w89LZVBvwE2o2hLVfjp07KpwNk6/Cjj0ZTDlw+9Nvh50Ex8I+wIpF6rrA/DZDrslj/dqGDoWOnbCPLQXVr39PVBXqmhaR2JsG4NN8kXHKr9eEnQQylF8Tyc4Y2eDLeovBqMYqHDaz1cgmrmyi0N9u9YX7YeG4IVrXGUSQ2Fxbgc/EqG8SDRT2zQaDKR9MHFYb6vaH1pjb2TRqTlk0GoD9WoiWOr2PBo9pqta6vmJSWiL47jEzMGVEvS/rH1qjuemswMXAlObKEfV6a6eCCCL71VQWqpkyJKPDig2c/Pzzl433LyEOhX0rwmAqhirL+gYrjMLdrg5+jQ3TMdReMJPa+h5tfRduLWVycew+7fweK+j8ZeOxcKzmGhqta/PP2OaasJMQO0d3DRzsMqyallmj7E/NddZ+5tT2HTazNdTtM5gi0sCQm1kKyN7jm7Wv0/Snt3QHqKkaoCB+dlRGq08vR4p5AEw3vnjgpFC3z2AqhtILJ8PLZ+PZDZKiUlj7bemklrCTEFlR6IAOAJ1WzdSlh04NMzmOpNfQFzpXwzyT0/dxolRw3J7BP3loelCfS0nIg94ymPKBKW3u5J3tIIm7HAAwZURd2EkIhB+neFTG6FkyqQV/+cxeOGKWnmYVPy/dn1jYAQAYM5RNk+SvaJy95AhjOX1S17dcA+vlM1xzR12Kt7P2G+f4O+UBBmDpFRaThtdpq431syJkjNXnMX20+sId0PVs282+6T+kh7kF+dcOmYK2weGXb4PK/J3M3AkGUz4Iu5o0orW0RprT0YjTF4/Bt4+a7vi7U1v9eYrMZKYcekHcUOj+rTVupr0x93pbUO/YbD4eNWEej099bbnj7/TrogEVyu61k2cfm9+Bf39+P9/TEiUMpojyKBHBRQdOKjjkQYSvaXoVSSQfzHQ1A7dpEq/pCfr3BL29RImgutycmhO7ch3Xk4cXRxO+WwymfGDS9cSgpPjKbkF55OyBjyDrWG+25Qy79gXC7fGW6tsSFQIJfNgRk8oVnfz8XW7WrbPPq9N1hREwn7rXaFvLmRbMA8DhVr+96W3htwIwmKJYCPs896t/Q9Sun4fMGBF2EgD4fzyIIHo7xyMTL6Z2pZ+fQf4Mr9sKIs8zh/mI0mE9d3QjAGDUkPAHN2YwFXcB3c6Ob4nG0zJOn541uROoicY1uxv9PxHyY83ZnLnv2LyfG3HR0ZyIuE4CHMbgxSKCtsYq998PqOyZkDFjR5VBnbqjhMGUTU46lRfLqOPpojKHXEkEqt2L0aeXdOKEee2RGagwjD5TQVg2Jfc4Ybp/b9/k4MFmZJBD18ztsD+aeDZBBFRNtf2nRbpy1Qycs3TgyOYml4UmJI3BlE1xLDhJH78KGhMKCS/sDjpYV1mGSw+d2m8qJC907I98FzI7faYmscNuXkGMgJ4K1MKqYY7aZeO8/cejua4SnzZomhg7TMhnz8GUiJSISKWkhfsiUioisaordLKzTAq8DEqKEaIW9HD/RZeTY+L2c/f2LR1OOEmzyTUVKVE5f0y5Znx6Se4gil0e8rMVTInIbBG5S0QeEZF/iMiYtI9HAFgDYI2IrBGRNQA2AzjGh/SGxlkzX/EpdKKVlZpyIpqSjuJwTNfIkLbsfT/nq3my08yXLdjI1Q9rnNvJgzUfzmHM3uDnJoP4NROHuesnWIhINAJWSioYTIlINYAbAZyilJoJ4LsArkt9rpR6TSk1VSk1WynVBeAEAI8D+INPaQ5FVAMkU+547NzVnLigw/36PQxhoHN5Xd+Ni0Ljc2W66ICJPqVELzsP82Xb/xcs1/v7dB9iQfZfSqW9vqo8sG2aKuyy4s+fXoS/nrNXuInwIOyBsgF7NVPLAdyrlFprvb4VQKeIDAjHraa+KwGco5TaqS+Z4XOyr8LesWFsX0dhcPreYwov5BHjG//84NiZntex94QmDSnRo9ANQKHzzM9mkTlWx+YwSxpdv6+u0sXI7w75WvuVZ+V2i+KwY4GprfWYOKyvj1+2XxR2wGc6O8HUaADPpV6oZAnyCIDJWZY9DMBWpdT9epJnhp4ehV3dPWEnI1KcVn1/9xjn07W44bxmKvsXMt/2q3kk7MDciYOnDxxjKspPtubbpSLuaqZ0+Nj8dpyyl3XjEWD26t5UkBfn9NNI93b9/BkmxS8mpSVTGM3TmewEUzsAbM94bxeAiizLng/g6lwrEpHTUv2qNmzYYD+VIfvcjY9jylduCzsZrgR1Mc48llNPcR1qcxDHOR2NKA3ghHA6NEIue483pwYlTqLTybVwNNVcq3eYh6znciz6TPm3zSBKPwOu40XPhJtOO8HUkwAyu/hPALAu/Q0RmQBgHIA7cq1IKXWtUqpLKdXV1BSdi9EfHnot7CQ40tniT4dIvw2udt93wu5FWFe5t2jcUE1rijc7ZZyXqSCuPWG26+96kayZ6v/jlkzsG0n6Y/PbcdGBAfT/CvEa4jWIqAhwcEh/m/k0riujhDKhxsVkJuWPnWDqYQCLRKQTAETkAABvKaVeyVhuXwAPKKW6NacxcsLewVeumtH7d1hlras5sfQnY+A2nA7a6VM6bG/foMLCL2Oa3I+ev2zKsKzvh5Ft6ds8dGYrKhJ6h/FLPxbCuBHXnaWpGxI/d1UQ+WRApUgwiqAs8qJgzz+l1GYROQnA9dbJvB7AKhE5DcAIpdQl1qLzADzkV0KjJOwqx5oK/zt02hXXYCBzF/s2zlTES2o7qY/iEVIozUoFdOx73ET7kCq8/O6HtpbN3Jdef52BMwi54tvYdTEtO/1gQilp66qrlFoNYE7G29dmLHOipjRFngk71ouKRAl27Hba4T5HR23vyQmVp6ERIv/rvQsrGPQ750Ukb42EH9dBP/KyvLR/7VmwkwCHc37o3m6+9dl9AGPTtl1Z39ddu+kFS7P8zNlTpJ3b+cNSM3FHyZ8ff8PWcroucgPWw5Km6OQNpuDfISEA9p3YhMNntuKSg6d4WpeuBzK88DMJ6bsoFfSY+ITp355+GwDw9Jube98TAMfMCWfQWwMOC0dMSC6DqSLXUFU24L3vHD1jwOSXhYR98m3daa+rnl8XDxNOZgqOnUE7/VSRKMV3jpmB4Q3hTQytqxkqbjW45YkS3HvRfq6+m9kiUFZq/iV69YX9f+vNZy4MKSXhMn9PRVCUioaz9+vEmouX9nuvqbYCn95vXEgp8pfTfZOroA+q9cq8e2hnhlQ7C8p10XGhz7eGZK1vgUE7gygINB8ggd4URamgdKAiUYLh9YNcfXfg+HX2v/v4JctcbdOr1ob+v3V4fTABfmPa098mlJPm9FSOkbB3rJMLSYn40y4fVKHcWF2O97baH2zfr+lknF68EyWC3T1hHyn+WnfFSnsLRvCiKpC853lUxk4Ks0Y5temwa7W9GhAApf3t5abLab4M8nmoiXzpufaE2b0BZFCl2pyOwUYVHQymYsykA80v9YPKHAZTmpomPK7GboFTDPsw9LuPXArs5MJ9puK997z+urg8rabzV5icI/nSlj5EScQfQHaNzXwxlN78YOvR9CyFWuYJccOp8zymKr/MqmK7nD7hNLt9sKPlcxUgxVpg+C0q19dkOsNp5utX85EjDZlP6ekQl2Pe5CA3Ksd/Pvk6+Kc/3OS0LM5m5qgGAMCRs9s8r8srBlMxkW3MFi93fplBio4DP5+g7lLnjR7iy3qzJV/HT4rJ9SuWBgYXfTu8qjy40b2zGddsbyDUzPMujEDD30E7B55BJj7Nl4uTctGUOCxf0P270+f3/v3xBR2et9U2uArrrliJfSc0F17YZwymYqK2su+pvPRj2e3YNCW6RtQz5Qw3DLMljvrOtc6W2mBG9Pe4FSff9tI5Ot+2AxnbNMD5ZPqNVO90VWl7hGVEtDCYijEvJ6PuSVojiyVaJPk/aCdrDe3I13w/1OHwK8Ug6Ga+9KnH+qdjYELsBqR2z4uoz+6QicGUDwodcqcvHqN9m+kVSamxlJZPzT5vmR1xaLvXweT+FbERwSwuNAJ6ciG928y2ObdNVhOsydAPmj683/up8762cuCzSU5/TnlpCW4+K/eYQ3uPT012H8EDII2fqfdz3dPb6nHIjFbtaYlbkGQXg6kQTG2t177O9LuG0hLBA19Ygu8ePcPR99I5PR8yl0+9dhKMhPl0j0nzGaYbObgq7CREko5DqdAqotT3JtOYpmoAQHtjddbPs3VgH9jMlz+HZo5qwNCa7LVP6X3K4nbj1jbY+cM0qcCy0wpyAefloSlPRxZpLMVgyg8mHEvNdZUoN2BeJ7/Pb8d5rWmcqYnDa/sv5zQdNn1maadPayYvBPk7oCdf6T0qnKytYKVZjpWFcSH0twO6jyvPIZHWTGB3+yOs5tC4TP5cjMK/2saRCdGUxc7JrOP8NeSmKDB7dTZhxsiG3td+3RVGYTqJYmRKn6lc57cfTS1RbvL2tSkuY+VxGVQ13YUHTDQmLSmmHY8sqYucaSdIWNxcfEY2um+CM+FCHGc6Ctp854ZAshwz/V+HeW7ZPZyj3FRpqvTd/tE9R9n8lvf94PRwc7LF/Se32F62bfAg7eM+VWcZasS0axeDqZgw7Ljq5TZdk4bXaU2HW/nSn34xNTX/o4CPg9vj5OLnNUjya9y03nX1W2+we133gKaZqU//PVNb6+1PqwSzzwW7NygigvOWjde23StXzcD/fWYvbevzC4OpmMjZB6LQKM05Pwn3jrVt8CCcqGFQN7tyFeh2C3rHc/45WzzWTK0dyTtdTNYdmNlnyh92jkm70z6a1lSiW7ZjqzxRgsNn2n+KzSk3sWGxdtq245AZrWgfMvBBCdPyjMFUCEyrngyEIb/Zv7w35AcSAE1P8+VZR4nhJ3GPzStNrkA229dTTwDqUFoSbA2MSP/9Oaxe3zh6A0eRd+6/H3wVAPCfDR9krMvJ09DOtmlaMBJ1DKYK+O39L4edBE+COmEKbsdhOvwqYJ3mRykfr3HF7xnsC9E2gn+u9dtYvV/NV7b69xVYJNdFOluSU2NOHTB1+MAPXfr9Jxfk3aZXAzqFBxg4eNnU6xu39f7tV7x+85m5x/7KJVEi2HNMcl69CS21BZa2p9A+md0+GNefumfOz027nzFzcB2DfPFPTzr/Uig7WfdG9azPywFv56LhdyFZP6is8ELUzz8v2Kff9EZBu/TQqa4nzk6Xr1bAzqCdus/ITdt2AQBeee/D3vdyPs1XYF26mlbP3X889pvYjIN+8G9H35swTM8F2YnU8AMjGgbh1bQ89Ernfja1tqhEBM11ydq8ro7BgWzzwD2GY8HYoYFsSwfWTPnB5V1hKESMi/CjaeBOL9Z8bR9Sjcbq8pyft9T1H8gx1/ng5iGE2ooETpjXXnC5BWP1T3i9as5I7etMd9dzGwAAd1r/D0xqAN4su+nsJZ2eByH244ZlYKdw4IhZrfjlJ+Zg1ZyRqMkywruJnJQhfvXvzGRovBc6BlMRNKwuiHnznD3mXfAE1TRYptvlCi3vpnzJyCEXa/Cfk07809r0j8yfzVc/MrXgMqUlgr+4eILHbkF/6MxW7Dm60fH6c7npzIVYmvH4uO5geuG4ZABoZzqqQn2mcjbzWf/vN1l6ge941dWhbz/kIyLYZ0IzRCT0ZuhcTL4BMy1ppuUVg6kIGlo78K7ftANrAI/T05jO1PxPOOg7dMtZi3xMSR8deXXjp+bjj2csKLxgLgpYMqk57yKF0pneVBZIJ2prK3amPvLj/DH1GM8mVUsTRDmidciIfuvyN8OdNvWm0qYrT019itetaNR1UkFu+9v6XT763aQZZtAVoWtL7Mxu91abobsgz7Y23ce+kzTbfZovrrLVsEVB/2PGn9S7OS5F0r8XTK4WSuXweu/9InVizVRMGNUPK42Xi1aQBWFzXfYJWSla7J4FyRHM8y+Td5ypAp/7yU5NiNe0pT/84XZqGp3Zk68Pnh2+Tiejce39y0tzSvX0/lj2pijzP+V2+kYGicEUaaHjwtJ/VOT+n6XPg+eH354yz9f1UzBsH4bBtMsBACo0Tzhua2QEjZFeb58pU67sLkSthioITg8R0/a/aWO9MZgKQZDHgNtCRFdZrOsOZcXUYVrWk4vXQfyc/sqgjgFeRNzTtY/83Ae51m13BPRc53m2mghd5/IvPzFHy3ryCfM6a6dPWy7m1EX15zZVmU/upotbSzSDKR/4fYxkOwi9FB5+nsDaLkgGnniFHkXOl68m/p6gGHG5sNVUYV+2Ze0e+9Md1rraWa/OcZxaByf7plSW6blc7DMhf8d/P/h6zKWt/PMrJuI7R8/QtGLla8KdDbuQ1g/N1pixxVfAsQN6TBhxgdLITp8Wt6a31eOx1zb5s3LyJKgiuCzh/YzRdXx+aeWkgssc3dVme323nr0Ir7+/Df98vvB4VDnn9Ez7cd87ZgbWvbs16/xoeded5T23D8o4bbZM3sio3IOa+nSgfWqfsd5WEGSrhctmPieBUr+JmzX/NtMCNgZTIYhb4EPm9SeIOr+zs6aiDOuxw/X3B0xXkm0Z12vv74XLDkCpCL79t+cGfJYtyJgyoh6jh1Zj3phG3Pef9/Kue8DXsyS6flAZDpo2wkmSs7rssKmY63JMKbMum/35WK/vz1q9DtrpYGfkGz4kbrXzDKZiruCUF5rOVydj8qS7/dzF2LBlp+vtmnJ34rSptJiDL1Om6PF65Og68gqtp6y0f/OanZGuq8oT+O/T5qPjwluzLxDC8ffRPYN7+sqUciEuxPrPyfJ+M61/GYMpH5i1i93JLIryBWV7deaeP6lQuT+uuRbjgu9CoUUU9rOJd397juk/lUsYgaWdZqMhNd6Gy5C+dpECafG0GXcKpSmYVNjmuEnKaubrfZ1xkI1oCGIWCa+UrwGDkzwVAdoak33n3PbHy9wHph1jXrEDug8KHSQm1UroOFmntdX7ckGwc3fpJv1+1Cg4vRMO6gLKO3Rnfnf6/N6/qyu8TTli98jUOYxBPucs7Sy4jN4xk8y1fMowXHfyXCzLmALIDZPKcyD/ze01x89ytU4BsGDsUNxy1kKctHC063XEGYMpg3gZSylX1X+hi6nfBYHf1wkGC/mZVhVeSKl1QH52//GhbH+ug/n60oMgL7kc1BF8ztK0PM2R4HLNY2Lp4n7g0OzfExHs1dmkZawineeY3TXlCphWX7gffvKxLm3pyTStrQElbp8i0My0sp/NfAYJp7kj+3adPRauP+H9py+IJhPuWE0rcAopKRGsu2Kl79ux0+8o7/dRuMnC7iZMaoodM9TZE3tBsZtFLXUVeHvzjmCfivPxHHN6mLY2FJpiRVBXmeyzOL6lxkFCnKUjFZR3DKlO7g8XTCg/nTDzNiT2sh8lETt2bDHthNA5DYiXn2ZavhQbOzUdXgMu3bKlWMehPDpLAGVSgOdERaJ/02wQD+DozCu7x5yXY3PUkCrccOo8XH74NNfrKKSxuhw/P7ELPz5hdu97A56AjepBlgODKYOEcWjlHGcm2GQUdNzcUVgyMaI91bPYo7U+7CQYY9WckaFs1++y3G7Nati1h22DzZowNivHHdApn/ljh2BQuf0+gW5aCfab2IKGqr45FXW3NJjWcsFgKkLc3Ixoq4UJ+LjN3F59VRl+dqL/01AEZUyTgyr2GDt8Viu6XI49FDZtIVDIdy7ZajkMq5QzWqeT5rIcUs2rU0bU2Vqeuyf8m5BMDKYi5MEvLsWzl64IOxlZ5a7CFeu1s3Xk6svllQIvFKSfl+lk7NJZk1ZhjV1Vakhn4kK8/vRcv1JHnp64IPl0W7bmUrtSw4Wkz+un/J1NxhEdx3JDVf/x5cwKhbxjMBUh5YkSVJZ5e1w7k66T1bTm73wdMaNaW+eG099aVhrsjwqzqr6m0uPzN5qOozBOnS8dNBmnLR6DZZNbsu4B085nv/vXTGtz3+yeKgei0IfS7XZ0JE/Hk5MmYzBFntk5R5yeR16ehKouL8Xt5+6dfb3OklF04l7gpTt2zkh85eDJ7r5sYzoZu+zGCTp3zeDqcnzhwElIlJb0S7vObVx6yFRX38uWBqf52zteqs3M/eTeHufU8yg9mQdP9z51Ty4mnN2/OHEOrlw1I+xkaMdgygeFTuAoXK9MuzN1QkSMyON8SYhy/rrxpYNcBi0+SpSW4BMLRyPhsqlLV58Nu+uJ2jHjeqTsLO/Z/e2ZeVnoqTcTyol0IsBHrGBKJHf6TUu3E/tObMYhM1oxva3B0ffGNvVvRmUHdMqpMqG3Cc8kbqaDcHuqFPqeaR0Xi8HJi7KPmmzCRcGENDiR2bcQAKZ7GPA3mzAfW9cxJEXUAs9sTPoNfgwTMmFYLV647IDc28x43T6kfzBlWjnOQTuzOOSq1Xjs1Y1YOsn7VANOnLZ4DOaMbsTVd67F7h5nB4qpFwRT00XFbeAj2wPPN2cD17qn46LZUuttHsEU0+72U+xeOE1Nf2F6RtP3i19pypzEO92UjOFjTMyXdKyZyuKxVzcCAG5/5m1f1p/roKhIlODc/cfnnNIh9b2sI5aHeKTlu2sx6e7KJEHtr0iMIRSC9Gljwr7Dtbt1v9Jp2kUqW3rm2Bw+I5VHXs+vyrISLetxytRgMOh8OHFBx4B9bvqlhMGUQUwatNOJ0xePybLe/itOuHhKzLQRqKPmguUTMKy+MuxkGM/OBSxz6g2/Ds2u9sEFl+mfXn2lxtJJ5g6Ku2LqMEfLp/Io1Vzpdn+FcTPY74GAHMtEsWR0sg+a6/TUtAaJwVRMhHlHU12RwEkLO7J+VlYqOGdpJ/50xkLH63Xbb6NQAFEstWUViRJj73SrrdGX3c5Ar1WOLHrqjc29f2erLU4/jrzNzdf37VP2GnhjMmD5bE2SGnbzR+e1e1+JBl5+S+a5bbvjeozLhOPnjfK8jnzNcX7Itj/MLMn6MJgKgR81LtoHCHR4x9vZUov/Omp61s/OWToek4bbG9lXh1NtXJB0MP3kNlndoOQAfvUZA/mZ5Kk3NvX+PUjz+G7pdFzH4xQMBHkDkHM6LZX/cz/p3uTH53f0rdvFD7rxUwtQXeG+e/XRXW0AgBkOHpLQMTxG0Io+mHry9U04+pp7sX1XNwA9T7F4XUPQBaOuAkNrwZPnseB02fLKlFGdw2imnBvRqVlMlH5s/eDYWQM/L/D9VFAwoqFAU6uLJ12DEFp/u2wXUpdjcRU6BQtOhGxvs57lSoeOIiR9HW5WN9tG03M+s0Ylv19Xaf/GydQa9XyKPpj6yi1P4YF17+GJ15N3od0On6LTqVDtjZuLc8Exr3IctJnvx+XON8gAJzPvhwfQf+n85RNsLzuuOfz5AU0oMlNBw5yO3BeNQk3Hqd+xdFIzrjouGXiVJ0pw1XGz8N+nzc/7XR0dy+PevdB2J/2MGiW/B0S9+Uzn3RfspiNf0t2WY1Euxk0/xIs+mHro5fcBALu6e7Dpw13QEUsV2um5Pg/jCZKwn2TyKlewaOLFpV+3YZ+y3UnXhpvOXIh7L9rPn4RESIc1fs3pi/uPgp3v3BBk34c//fgcrJw2vPf1ymnD9fXh8/tULdAHLChZK5azZNLnV0zMuY7UKrwOOFAoH3SN75X+80ye0zEoJpbfhRR9MJVy+q8fwvSv/Q09Go48PoXmvbnUbg463YrOwQid7OfTFo/Br0+eq23bueT6edlqXWoqEhhe77wpZ3BVGV66/EDH3zOdGadt4ePT13QakQf2TB+Zez69VC6mRmE/KC3Azbp8RrZfvHISgOA7XucK0rMtV6zOWdqJg6YNR9vgqrCT0g+DKcuWHbsBhNvMl+Lmep/r5HIbOwyclsFGGrKNf+Vgm+6aMR1/pdeicUPdf9mhLxw4CeOa3U2voUOTpkEdU+J0w/CVgydjycRmLMw4HkpL7BePTg7DCS39jwMvx7DWWoeMXXrs3ORTYA0GPyRQyKjGKvznGwfi0JmtWT/PdRifML8D665YiVIHx7nuK0euLU9oqcV5y+w350dRvlyfOqIePzxuljF9Y1M4AnqGde9u9bwOz7UyZh0jtunuNOh6hnObnU6rK8KbvieofRz1Zlw7/v7ZxehRwPLv3e3q3GsfUo2fnThnwPtHzW7D3c9vwPwxQzyn8fvHzsSYodVZP8u4bSm4ruyPjWt/nBdn7DMWn9x7rBEXLccTHaf9XRJQ+nVvJddvvu2zix2tJ6rXk6gp+mCqtET61UatXf+B53V6vXwVOvazFqZFesbkChZydqxPy6coPjHihJNjYq9O+7V0ph1rnS21WL9lu/b1psaWyvVYuHLQIyc1eS1g9sWt35NfInAx1q73NGTk5uThdaGNFxXGTY/Jx4cXcb+xK+pgald3D9oGD8LL737Y+54Jd2G5+JWyKAcV2QPL4NORTdhBh1LK1r594ItLHD22bLKg8lzndvo/5Rl8nymTL3F/OmMBpoyox/X3vxzK9qM6TE26sDugu/lNppThThRtn6k3N21D5xf/0i+QAvwdnC8l2Kf1oklEbAUCbn5f6jtRPGH90FxbicoAjvt0QRfwoxrdd1b18zj5y2f2wtSMCV2DdvfzGwAAL7y9JdR0ZFNdkcg5V2mceD0fJg4Lrz8mJRVtzVSu5rwaDyO9etU7n1RoKejjqhO8Txed1JM12XjpP6IzvUZMi5LBS+3J3NGNeOCl9zSmJjv9j4HrO3sKrUrHppzMDOB3ufDieu/9RXUI8iZnXFNyrDXdD2i45aaV4MEvLs3b/zOKN41RbC0p2mBqx66erO8fc+19AadEj+gdev7KVYBU+HSXe/reYwsvFDAvLdZBDDAK6KuhimLh61a/8cpCS0UwBo4XZfN7NiOIs5d0Yv7YoZg7OtyZA7zsx0KBYNjNfMUi/vWnOezszh5MBcGkOwVTTzSB3Xyy/wPWXbESZaUl2movvOxGP/K9tjLRLzeWTmrRvxEAp+xlXi1cis6+TAWfCtW2Je90TztiiopEssbFr3IqUVqC+WO9P62pTY59UD8oHn0a7TLxWCykaIOpXSEGU25F8QDTIb0gPXf/8Th3//FZP3PK79oMnU1Odvz504t6/+5qH4yRHvoJ5bPn6OTF55rjZ3teV5Sb+YJ2+KzkWEnLpgwLOSXBGTUkeQxn2xXjWwr3E/K6Dw+enn+wTx3bsOuGU+fhb2nDIkSlL1lLXbKWu31I9qFBsskXPBp2WvaKxt7wwY7dIdZMxbRJIognqc5e0omzl3T2vs52YtlNht+P6iYCHj3ZSWGlw4qp7i/quvNe96HX2tA3Mny2VQuAsU3B5vfEYXVYd8VKjE4br0rnhdzuvHB+s7srh9ZUYOKw2qzjgOk6HL5x2B746zl7aVpbbtn2Y+aNwfyxQ/oFkHedvw9+/8n88z4C4d+E7zOhGb85eU980kZXiNQNWlcEJ2wv3j5TIQZTUWBS9J+vMHBTE5EK+obWhNfp1O8CLjNXnGZTvuSVhTH4UIDu/8ISVJWXYvXad/Mut2DsUNRUJPCBNXuCXX7cdOhaZdT27F/PSdbUdFx4qy/rT5SWoLGqPO8yOnenk1WNaBiEEQ2Fp4NKP/eDri1PWWRzHLsVU4dh3RUr8y5j6jFaNDVTGz/ciW/d9ix2W817uwwOplwdLB6OsLDvXArJd/67GhrBWuHRXSPdJShFY77dpHn2+UxO93G2C/4XDpyILx80GXtoeJTfr9rZXIGKk5qwlrpK1Nocd2uM5top19M/ablGmlsQOA4Cghx+RkPeZzs+RcT1uofW5A8Ao8ykG/10RRNMXfrnZ3DVnS/iuJ/eDwDY3WNuMOXmYHE7N1+ui6wJxaqdNHzjsD3Q2jAItZXOK1lLDIoidT9l6Mcva6gqx0mLRmupWYnLaMifWz4RQ2vKMa65JuykaBVWDQYQ/mC3A6QlJ++Tc1oeAuhbiZd9EPbYZcWoaIKp1HQTQYydU1CuAKbAyWh6X6u5ae3c00Y2AAAWuJxM2G55euAew7H6wv2QCGPk+njEA1nl6iekfzt61urP3i+8gxd1DsWai/fPOeWMaRqrCzVZmVnGOI4rfDo3540Zgie/ulz/itPS239KH3erWxHjhxTMPEKLqM/Uhi07wk5C7KXPLj9r1GA8ccky280l+dipxYhxXKOFjooGUy+06YJKoV9Z4dfk3im3nbMYr2/cpnXbQWqurcB6G2X5UV0j8fPVL/kyXlrOgZ19KITcnrdBTe4cBlPL+qIJpqrK+48Qa3otjy6FApFcJ2vm22UunkzzGkg5Kdwzf4edr3q+eBh8CO2yJu92+xuzPiXpPjmhc3e++9Svy5e12tNUWxH4aN9//+xivPr+h4UX1OgTCztw8cpJWoKK9GNHx747edFo/OzfLzlLg9MNmxpxeGB6sF80zXzdaQfX6xu3+dpnw2stgNt+TlHxqX2cjRZu2ng/Ovj1mx5/bRMA4LFXN2pft8m7wUmt2XUnz7W5ZO5f7Nf+c7peneVYokRQbt00HTqzVdt6O1tqsd9EbwPIpn5nwYFUVd9yftTO5N2+zc0dMast7yoarKcH04c60XW8mXwOF2L6daBoaqa60zqcf7hjN/wcs9NrAedulu3oRFifXzERP7rrxYLLOflN/fsZRCcvdHvnAz3N2XHOwb06mxwtr31gUb2rA6Cnpr1EBOWJEjx+yTJUl5t1aUhdSOPaopB+TMwaNRi/OHEOFowbgg93dIeWJnKmeGqm0oKnkhJBj8FhbtDFRTyLp9xM2PVRjPcikeRIJNJsdZVlKA2xz022LadO2YIP6YRyYukrUFLJ33dic+9UOunv21+RtiQZw/Qys2iCqZ6evgO+VMTXR38L3T3581RUdiYEDm44ncxVMv62U6iafnKaRmd+RfW4TDHl2Il6PjoVRrb3q/X2aRuFrke6htky5LB1xfRj3ay6XB+ljytVWiK+NvN5LWg7hlbjqTc260mMS2GOM5OSLxvvOG9vPP1muHlkYpODn7vNjwCiWEfu1qVH2etLFHWl1g8sNB+d3+VW9ps0fZmvaz/mfOLQYGfvNy7sJHhSPDVTGeN4+NnM53XVdS6egotbYdp/8LqBn49pqsFB00b0LdPvu/nXnZrbrKrMnALHuP3nU3rGDO0/Yrju01Bnsv0qInSmMVWOhdksF4Tj57Xj4/PbccNp82wt71dzn461uusT62z5yrJkE+Hi8U2R6XR+7rIJeT83rozMYM7VxGcvvbO13+sw+0wVcwdpR7xMkZPns28fPR3HvDSyd0b6TBNaavHc21vcbzwGUo/PT2ur731C0KsXLjvA9xqkYju3UhXupRp+t8lZN6i8FF89ZCq22pwHMdiade/b8iu1mbs0KoFVNgY0luRVNDVT6ZQKN5gqxM3TgLmanMz9lTZ4SHy+x6JrKhLYd2Kz+5X7wO/D0Xmfi2T+TRlRpy0NZaUlSGSMVxbUBdzVOWVAcHH63mPyft7d28yndzwl6iM5X/ixLf3t3tyrwSjKYAoAtu0Mb26+tsGFZ/rOxo/CPdLBVhqDY+NAZR4jjh8CyvMFnRdb3bvLl3MjTyK95EW+35752ajG7LWnKakHa1yMqRtJdvezf818/vSZ8rP8ikvRaMLNTT5F08yXTing56udjUDraP0FDt9RjVW4+cyFOOSq1QPSFYZsBY+bwkh7+t1OreGxcDP9pPVT73g+0v91+nthOmTGCAypHjiCt68d70O8ty+07e4i6TNVLEw4x1JuOHUe6gd5nw5MF9NvmIszmDIgVg96SgenVkwZhuPnjcJv7ntF2zrLSgW7uv3P+2H1ZudtNiYVogCweu07AIA/Pvy6L+t3+3OvXDUz/3pzrNhNQJQKUAo9QeaU1g7oVs1UScz7TJnNvz5Tqf3a4DCoSWg4duePHeL6u8WoSCqH+/M7wo1D34PyRAm+fugeWtd570VLcNf5+9hatv84U8522Oz2RkfLe7V0krepMpw6aNpw37fxvNUBf6dPY4iEfztT2JJJLThjn7H46kemBLbNgR2G8+dU6ljff3Kwx2Ac/ezjXTh50egB76fX0udvBrcnfR1fP3Rq3mXrq8rw9UOn4ren2nuKMWXh2KE4a99xuPzwPWJwNYqGoqyZMpXdO0OdwaDOE61Q+ofWVGBojf1aI9OD0tTvXTYl2AvZ1w+dij8//mbWz7weG6nfZHreZ/IjOCstEXxuxUQf1qzP5BF1eOnyAzV1QDefn8flkkktWFLgxijf1t0cg8fPawcATG+rx/8+9gZGZukjl1rGiZISwfnLk0MNvLd1Z18ao3AXU4Cpx2lx1kz5vP66Qe5i1Dgc6H5gvgQns8+UX3SvvneCW83r9YOTDuh2xG04CD8mKNZlcHW5q+89+uX90dqQ+8GjkxeNxt8+uxizRg12mzQKWXEGUz5fnTubawsuE8Xy749nLMClBaqltZFo5lGc6bxoMz62J8gOwKacb15iKX8mke5z7v7jbS2XqaGqHFXlpTk/FxGMbyl83SBzFWcwFXYCfJCzINQYOM4aNRgnuKhyjj0NWTy83t1wGZlyHQd2+53p6BPiRKF1Xn74Hlhi2JhgQVg6qRnfOXo6Vu7hf/+4KAkz4KupSPSOLE7hMfX6XZzBVNre6Gov7mpVBTObRj6599iwk1CQrnw7d//xjmognPQb0To5sb5VYXpbAwCgIpH/4nTs3FH42YlzbK83Ck1edmrGy0pLcPistkB/T5jN6ecvG4/h9ZWe12P+3ie3LjtsD6yaMxJ7j28KOylZFWUwtWnbrt6///CpBdrX7/aETtUefH7FRHTkmOqkWIxvqWXBGILUBVXHo/b5fP/YGbjpzIWorzJnHJtiF2YcetZ+nbj17L08ryeMeLChKtmParHNi3zUHu4wxbD6SlxxxDTtQ5XoYitVIjJbRO4SkUdE5B8iMibj8zIRuVJEHhKRp0XkeyJi5i8GsG1nd9hJyGvmqMG464J9tawrvXAZFOMq6mDn4grf1R+dhX+ct3eg2xzpcuT+bKrKE5gxskHb+opr7/sjCrV6dgX9lPLqC/fDFw+cpHGr/ig0oj65VzDgEZFqADcCOEUpNRPAdwFcl7HYlwC8CKALwDQATwEwtv3M1Hn5Ct2xeC3r/B6s1K9sLbZAyY4D9xiOsU01jr83tyP/GFx9I5/35flgq/YoCgVxzq6Dmo/9GMUdveL0k4IuMVobBg2YdzJTWMfMCOspwrOXdGKyxrk2qT87tUfLAdyrlFprvb4VQKeIpD96cAKAnQDuAfBPAO8rpd7VmlKNMoOplrrgR8xmVW9hTgqfON1V++W+i5bgVyfNtbVs/4EKzc/bKMXbUUorRV9NRQLrrliZ90lE8s7OgEijATyXeqGUUiLyCIDJAO63gqrhAPYAsBeAJgB3iciTSqlnfUizZ5llmSmFW6G7Z88DMkYsgBts9UUwaX4oPwR1/A2z0cE33zhThpwmeemcTsYv+c7zMMsik/bvLWctRHeP+xSZs7cHMmE6M9LPTjC1A0Dm1WwXgFR1ToX172Kl1G4Ab4rIDQD2B9AvmBKR0wCcBgCjRo3ykGxvMpuN4nxop//UqJ3EJy7oQHVFAkd3jQw7KZFhyo0B5WYnsItAZaCvpllPe5rApECczGUnmHoSyWa8dBMArLP+fhfARgC70z4vAzBgUi+l1LUArgWArq6u0Ir9noyURe0C5LagrR9Uhu27dmhbn98SpSU4dm54QbddmUHq3z+7GE+/uVnb+m8+cyF29ygc8aN7km/4uL96j4Us54ShhwmAaN0o2ElrGGWSyfs3xdSyishOn6mHASwSkU4AEJEDALyllHoFSDb7AfgdgPMkaQiAQwHc7k+SvcvsM9WdGV15VeCE92XwwwKlTGN1Ob579IwB70ctkMwljE7qubK8s6UWh8xo1bad6SMbMDvHeGhTbHYodZw9vGj5Jt++CDVY0LhtL5NxezmTL7Dmo2t0Oe2Ln1jDFW8Fa6aUUptF5CQA11sX7PUAVllNdiOUUpcAuAjATwE8hmSA9nWl1HM5Vhm6zKb4Hbs1B1M+yVfQFpqC4RMLOlzNK3X64jF46Z2tjr9HwbjhtHmYdsnf8izhrgD3e5ypYpZ3br6Y3NyUFXiyLZvUDZGXY+/wWW04fFab6+8TuWVrRl6l1GoAmcMQX5v2+XsADteYLl9l1mJs32XGuFOFRoN2w2vzx0URGDsFiHa/Ny/7qK4yuM75Rudxb+LiEQQWYyybusk17qdrTpBSwNcPnYo1697Tu2IKlbEDa/ops2bq2hO6tA4gaOeqk62wLM2oXprgYOLLQoVvMRbOQYlLbUIc8Dh3T2cz1CEzRjj+Tuqp3VRTXTZRbipLPzaPn9eO762aGV5iSDtbNVNxk9lnaunkFizqHIqJX/prSCnKTnen2mwXfV583DOxYM/cn3WVyVPczrAIQP6hEcz7tX3qrAvx6YvHFFgyfCbnoy77THA+OXV5ogTrrljpQ2rMwJuueCvKYCrbMc2gwrswn6jSO31EfA6G+WOH4MpVM7B8yjBH34taDlSWlUbmQsxrKlH8FGcwleUWIQodbr3WhOQc0DACv92Lu87fB9t36+8XF4XH8UXE0ZOFMT8UjJd6avO4ue0hp8S9kY365nA0ga5zgudWvBVlMJVtbr70YErEY5WsppPGSRrsBFp+VzM7CfZ+/8n5vXO++a1jaHUg23Fr3pghjpbPVyj7sY9rKxN4b+vOSAfdV66agcOuvifsZBQ0rL4ytBo2Hbv395+cj9E+nm8RPgQp5oqyA3q2C0563+/zIjiHkUm1JJVlhQ+rOR2NGNdsv4O9iXT0mbrssKmOgyk/9fWZ6vttvzl5T3zpoMlGjt1j18xRxs67HitzOhoxtCb4uU6jhH2n4qlIa6YGvpd+8ags0z9EwYDt+b4Fe3hiD+TnAKB7tNajIa1Gzs14PPloa5JI+3tkYxVOXjRaz4ojrLYygS3bdxdeMKJMKZNMw3whO4qyZipbM5+JdKQyynPzxdH/fnoRrjt5z7CTkRObUXJrG1zV+zfziYjSFWUwVajmIYp9Qwo1OUXxN0WFSSEq97J/mLfhC2MfmHR+k7mKMpjK1syXztRC02s8FJEKOVd0/jS7gWec49M4/za34p4nueZ/JKLCijSYinFUkcHvX5ooNCkgZXXyotEYXFWGfV0MbpiPvv3N/ZqpfUhV4YUiqLUhOZTBeAczLhQT3WcCu1vEEzug+8DEkbEpHN86chrGNNUMeH/S8Do88uVlrtbJo8u9VODghq5H/v18wCHuotxdIcppp8KKMpgq3GfK3+3bPalypdPUsrhY77jy7Y+jukYGlxDK676LlqC6Qs+TumUlRVmpn9Oai5eiNKbBQnGWauRUUQZTPX5XTdlho9zJTGVUiqpiqZmL6bUjtuzOT1jIefuPR4mH5m1Tayi8JItjS1GxK8rbq0Kx1PSRDZ7W71cNTSLLmES1Fcl4OFdBWKgWy2taDQhLQ2NiDaGuy7Sh1/tQxfUmYcKwZF+pioT/4+tFUTz3OulWlDVTha6Bs2I4WrJfF0f2/9Cft0d3tWHP0e5GRdeVlnLNg4nGga6bJNPOme8fOxOPv7YRTbXm1y4xsCFTFWUwtXb9lrCToJ3bQiaud9teOM0R3dfG85dNQHOdniYptz6xsANfv/UZLBxnzlQ35I+aigQWjB0adjKMle30Xj6lBUNcNm0aFkuTJkUZTN3wwKsFlyktEXRr6ltVkSjBjt09zr/o00k3ZUQdprXV28qHqFgwdghue+ptLJvc0vveb07eE0++scm3bZrYFKaroB5UnmzyGRTA1EpRwRsPSvnxCV2Ov8OjJ96KMpiyY3h9JV57f5ur74ZS6Oa4sqc3TcT5jig11cecjsbe9xZ1DsWizuK649a1i1PHcJyPGae0NfNpWQsFhUEQ2cGOETmkAqnj9hyFiw6Y6Oi7dgpdWwGXxrM4fXsm1qiQfUE8DcZjJDevecOsdY/HJZmKwVSG8kQyS1JTKxw+szW8xOSIyTitzEBhlrFRG1/rxAUdOHFBR95lUsMITG2tDyBF0RLH84eIvGEzX5p/f35fVJUns2S31V+qlNOlFJ1Jw+vw9JubbSxp3rFhJ0WXfGRKwWWmjKjDrWcvwsRhdd4TRUQUc6yZStM2uAqN1eUA+gb2jEowlSuVSyYmO2SnP5WVXrOlc5ypikQpqspL8ZWDJ3taZ9guO2xq2ElwTVcziEAwZUR9ZI7/IEWpqamzuQb7TdQ7/yMRDcSaqRxST/KVaCg53a5CR2vC3NGNWHfFSgDAE6+lP9mm54qQ3uRRWiJ4+msrtKw3TJUhP8HmZXRtNkH5z2seB7mL/n7u3gFuzX+mjh5vR4STTjawZiqHHhWxmilb09PwSqtTalxL3U9vcmoOIvPoGmyVNzzxVBQ1U3998i3H30n1mUpoCKbcXmz9GimZ4+Xocf6yCVAKOHxWiA8pADhz37G45bE3Qk1DMeHTfMUlVQp7rRVjzVS8FUXN1COvvu/4OxevnITh9ZUY2Vjly0lgryaJTNZQVY7LDtsj8GbBzEPnguUT8a/P7ad3Gyz4c4pSMx95l9rfXk8J1kjFW1EEU276Pe0zoRn3XrQk9P4zdtn5hXE+mcusIS2i0iwbFz/9mPORoIkipbdqKtRUkOGKopnPtOurH8lxUgUdx1qHs/Ydh54ehY/OGxV2UkIV9L5dmjZ9T7HwmsdDqsvxnw1b9SSGfFdRlrxRO2JWm6f1xLHcpT6smfKDynwZ4yohQ1RXJHDRgZNQkYhGTSIVry8flBzna/TQ6pBTQnZUlpXiya8ux5cPivaQL+SvoqiZCvtx2jg3r0Xd9afuiZqKojgNHOFNtH+qKpIBP/PYncNntXquJXJKZxnBm+t4KoqaqSALrds1juviZxC2xBrIb8bIBv82EgELxg7FtLaGsJNBRDZ95+gZWDguehOY8ynqeCuKW/IgK6bGNdfYit50J8nOMArpSyyd3IK1lx2ARGlRxNNkEwv8aBtizeBA5mGNVLwVRTBF/aUulwykKBML/Nwaq5ODqdZXmRmwPP215cH3DyUiAAym/MHrEblw5aoZvRNt5+Pn9bJ3TB1elAf4+Px21FYkcMTsYPvr2GXn2KHwsNY33ori7Lv6rhc9fT8uJ4FfI6qTHofMCHck9XTxOOL1SpSW4Og5I8NOBhEZqCjaeXbu7gk7Ca741uTCWgciolDwnjaeiiKYiiqedBQWxttEeqXOKRbr8cRgKgCmXJhaGwYBAA7aY3jIKSG/xKVJmogoShhM2bB4fJP2dXrp4Ou2xqq5rhLPfG0FTtlrtOttk9m8Ng33TUPGoIyIyK6i6IDu1YRhtVh3xUp0XHhr2EnxbFA5p1shGxhLEWmVOqX4IFB/v//kfFTGYBowBlNEEeNrrRHLeSJ/mNLfwzBzOhrDToIWRdHMd9yeo0LdvtsbEd7AUFhMK/dPWcSmaYoHFuvxVBTBVNAKnSxeL1SmXeiI/HbxQZOx7oqVYSeDyLW+Zr5Qk0E+KYpgqrs7efQeNjOcQREZ/FBUpDqw85ClqEk9rUwUhqLoM7W7R6G1YRCO6mrDnx553fft2bkQ8WJFJuN0MhQlt52zGM21FWEng4pYUQRT3T09SJQKhtVVhrJ9P6t1WWNM6TikARWjCcNqw05CQbw/ibfYN/Nt39WND3Z0o7REMKapJuzkOOLkEVrWJBCgbwoiHk1EfuEtcBzFvmZq2iV/w87uHoxvCS6QCuNU4cWPdGDnWP9VWWO9jWmqDjklFCR2QI+32AdTO7uTkxyXloRXCef23GFtE2WT77DQ1czHQ88/w+sH4VcnzcWsUQ1hJ4UCxPI83mIdTN2U1tk8URK9A7m2Mta7J6cjZrWFnQR895jp6BhSvDUH7Hvlr719mKKKiMIT66v1LY+90ft3aYjBlNstzxjZgGff2qI1LaZ77usrUBZiLWLKYTPDD+jC4KYWddnkllDPL6IoYStfPMU6mNqyfVfv34++ujGw7WZeVrLV7rLGN7uKGMzRFAdOjs9rP9blX0KIYoJFfryFXwXgo0RINRyZdx7bd/W4Ww9vYYiIYoXlejzFOpgyoLUoMDw/SQfOaE/kD7ZGxFusm/mi3ok2NWbQCfPaMT7HoHR9j9vyIkj6CmwW/ET+YFkdT/EOpmJyQZjaWodj5owKOxlUBFjME/kj6jf3lF8RNYQRkV0s+ImI7GMw5YNOG6Ot27lYdbU3AgDGNZs/7xQRERXG2t94inUw1T6kKpTtfnLxWPzhk/Nzfm53JNyjutqw+sL9MLt9sK6kUcx57Y6R+n5cmsiJjGGdU+wyFU+xDqZaGwYGU6l5sfxUUiLo6mj0vB4RQWvDIA0pInKGsRSRXjyn4i3WwdTu7oHjO1WWcVBIiq/muoqwk0BEeSg29MVSrJ/m290z8KCN290BT0t9bjpzIZprox2MzBqVbBKe0OKtnx0nZSXSqzyRrLvgwx3xFOtgqjtbMBXT45gXP+9mjGwIOwmepQ6DEs6VR2SUbx81HT/790vYc7T3LiBknlgHU9lqptKNqK8MKCVE+gQRNzMUI9Krpa4SXzhwUtjJIJ8UXZ+p9MvETWctDC4xuZPhWFV5rGNg8kDXk0Ks6CQisi/WwdSal98f8F76RaK5Npo1Uz84dmbYSSDDMRYiIgpOrIOpR1/dOOC9uRqGLAhbS100g0CKDvbBIyKyL9bBVDb/dfT0sJNAZKyffbwLe49vCjsZRESRUnSdbyrLSjGnYzAeXDewCZCo2C2Z1IIlk1rCTgYRUaTENphSGT1xL17Z9xTFdSfviW07u4NOElFgOP4YEVFwYhtMpY8xdcSsNnxi4eje15VlpZ5GQi8RoMCoCwWxSwq5lW/QPx5XRETBi28wlVYzxX5SVCw4iSoRUfBi2wF987bdYSchUKyQoHQ8HoiIghPbYKq6ghMaExERkf9iG0xxlHAiIiIKQmyDKSIiIqIgMJgKCfu0EBERxQODqZjgQ1wEAOOaa9AxpAoXH8TZ6YmIgsKORUQRk28sqcqyUtx1wb7BJYaIiFgzRUREROQFgykXhMNMExERkSXWzXxPfXV52EmIpZqKBD7YUVyDohIREeUS62CquiLWP4+KFOtFiYjMwma+kES5qVBxAjgiIqJeWoIpESkTkRLrbxGRGh3rNRWDCSIiIkqxFUyJyGwRuUtEHhGRf4jImIxFvglgrYisAbAGwK26E2qC/3fkNCyb3BJ2MoiIiMggBYMpEakGcCOAU5RSMwF8F8B1GYu1ADhRKdWllJqtlNpbf1LDd3TXSFz7sa6wk0FFLspNxEREcWSnZmo5gHuVUmut17cC6BSR2rRlRgA4RkTuFZE7RGSu7oSSOXgxJyIi6mMnmBoN4LnUC5XsMPQIgMlpy7QDeBjAAgDnA/idVaNFREREFGt2xg7YAaAs471dACrSXk9USu20/n5YRB4HMAPA6vQvichpAE4DgFGjRrlJb2ywboeIiCge7NRMPQmgM+O9CQDWpb2uzLLenRnvQSl1rdWvqqupqclJOomIiIiMZCeYehjAIhHpBAAROQDAW0qpV6zXCQAPisi+1uspSAZbT/qTZKLixlpNIiKzFGzmU0ptFpGTAFxvdTxeD2CV1WQ3Qil1iYisAnCViAwCsBXAcUqpbX4mnMLDizkREVEfW/OtKKVWA5iT8fa1aZ8/gmTncyIiIqKiwulkIo6jsRMREYWLwVRMBNn0xvAtXBzmi4jILAymQqL7gsgLLBERUTgYTBERERF5wGDKhWKfTqW4fz0REVF/DKaIIqbYg3kiItMwmIoJPtRHREQUDgZTLnA4AiIiIkphMBUS0dzziOEdERFROBhMRRz7zxAREYWLwVTMXLB8gv8bYfxGRETUi8FUzEweURd2EoiIiIoKgymNfnf6/LCTEAx20CIiIurFYEqjuaMbw04CERERBYzBFBEREZEHDKZCEumH8KKcdiIiIs0YTGlyzfGzQ9kuBxAlIiIKF4MpTVZMHRbq9llZREREFA4GU0REREQeMJgiIiIi8oDBFBEREZEHDKbIMfbPCkdVeWnYSSAioiwSYScgikQE4FN0FLA/f3oR7n/pvbCTQUREGRhMEUXEmKYajGmqCTsZRESUgc18LhT72E7F/euJiIj6YzAVN4x0iIiIAsVgKiaCnJ6GHdCJiIj6MJgiIiIi8oDBVEhMm+i4xLD0EBERRQWDqZjw2if+P5ev1JMQIiKiIsOhEeImwBqmT+0zFvtPbglug0RERAZiMEWunb54DBqqysNOBhERUajYzEeOiWkdvoiIiELEYCriLjpwEgCgsozzthEREYWBwVRIRFPnpuPntWPdFStRysfxiIiIQsFgioiIiMgDBlNEREREHjCYIiIiIvKAwRQRERGRBwymiIiIiDxgMOWCl3GWfvbxLo0pISIiorAxmHJBuZwIr0SAJZOS069w3EsiIqJ4YDBFrnmdXJmIiCgOGEyRY6xVIyIi6sNgioiIiMgDBlMBytdxfUxTdYApISIiIl0SYSegmFSXZ5+M+NlLV3BuPSIioohizVQARjYOAgBceMCk3vfSQ6fKslKUlUZnVywaNxQAUFEWnTQTERH5hTVTASixmveqK7LXTEXNfx09Hecvm4Cqch4+RERErFqImwCGK6hIlKJjKPt4ERERAQymAhHEeEwcroCIiCgcDKYC5GUamkI4gCYREVE4GEzFDWuoiIiIAsVgioiIiMgDBlMh8bPJj4iIiILDYIqIiIjIAwZTAWJdFBERUfwwmAoQH7gjIiKKHwZTRERERB4wmCIiIiLygMFUAFSWBj72nyIiIooHBlMBYgBFREQUPwymiIiIiDxgMEVERETkAYOpAAgb+IiIiGKLwRQRERGRBwymApDtaT4iIiKKBwZTAVBWLJU+tzHnOSYiIooHBlNEREREHjCYIiIiIvKAwRQRERGRBwymiIiIiDxgMBWgbONNtTYMCiElREREpEsi7AQUKxHBNcfPwvSRDXpXzFEYiIiIAsWaKRf2HD1Ey3pWTB2O4fWsmSIiIooyBlMu/PTjXWEnITeOX0VERBQoBlMuVFc4ax2tsZYvTzC7iYiI4oZ9pgLwpYMm47HXNmLJxOawk0JERESaMZgKQE1FAmfsMy7sZBAREZEPGEwFwI95+K5cNQM7d/foXzERERE5wmAqog6Z0Rp2EoiIiAjsgE5ERETkCYMpIiIiIg8YTBERERF5wGCKiIiIyAMGU0REREQe2AqmRGS2iNwlIo+IyD9EZEyO5SpE5GER+bzeZBIRERGZqeDQCCJSDeBGAEuVUmtF5CAA1wFYmGXx71jr3K41lURERESGslMztRzAvUqptdbrWwF0ikht+kIiciKAwQD+AKBbZyKJiIiITGUnmBoN4LnUC6WUAvAIgMmp90RkNoAzAZyab50icpqIrBGRNRs2bHCdaCIiIiJT2AmmdmBgs90uABUAICItAH4J4Hil1NbUAiIDJ1FRSl2rlOpSSnU1NTW5TjQRERGRKexMJ/MkgBMy3psAYJ3190cAtAK4zYqfGgAoAB8HMEdHIomIiIhMZadm6mEAi0SkEwBE5AAAbymlXgEApdRPlFKNSqkOpVQHgCsBfFkpxUCKiIiIYq9gzZRSarOInATgeqvmaT2AVSJyGoARSqlLMr5SDWCb7oQSERERmchOMx+UUqsxsMnu2hzLnu81UURERERRwRHQiYiIiDxgMEVERETkAYOpmBjVWAUAqB9UFnJKiIiIioutPlNkvi+unITF45swa9TgsJNCRERUVBhM+WiP1no88fqmQLZVWVaK/Se3eFrHbecsxsChVomIiCgfBlPUa8Kw2sILERERUT/sM0VERETkAYMpHymosJNAREREPmMwFQABOyIRERHFFYOpALCGioiIKL4YTPmINVJERETxx2CKiIiIyAMGU0REREQeMJgiIiIi8oDBlI/Y8ZyIiCj+GEwFgB3RiYiI4ovBFBEREZEHDKaIiIiIPGAwRUREROQBg6kAsCM6ERFRfDGY8hE7nhMREcUfgykiIiIiDxhM+YjNe0RERPHHYCoAbO4jIiKKLwZTRERERB4wmCIiIiLygMEUERERkQcMpoiIiIg8YDAVAD7VR0REFF8MpnzEp/iIiIjij8GUj1gjRUREFH8MpgLAGioiIqL4YjBFRERE5AGDKSIiIiIPGEwRERERecBgioiIiMgDBlNEREREHjCYIiIiIvKAwZSPjpo9EgAwoqEy5JQQERGRXxJhJyDOPja/HR+b3w4RjjNFREQUVwymfMQgioiIKP7YzEdERETkAWumPPrcign4z4atYSeDiIiIQsJgyqMz9hkXdhKIiIgoRGzmIyIiIvKAwRQRERGRBwymiIiIiDxgMEVERETkAYMpIiIiIg8YTBERERF5wGCKiIiIyAOOM+XSGfuMxYyRDWEng4iIiELGYMqlz62YGHYSiIiIyABs5iMiIiLygMEUERERkQcMpoiIiIg8YDBFRERE5AGDKSIiIiIPGEwRERERecBgioiIiMgDBlNEREREHjCYIiIiIvKAwRQRERGRBwymiIiIiDxgMEVERETkAYMpIiIiIg8YTBERERF5wGCKiIiIyAMGU0REREQeMJgiIiIi8oDBFBEREZEHopQKZ8MiGwC8HMCmhgJ4J4DtFAvmp17MT72Yn3oxP/VifuoVdH62K6Wasn0QWjAVFBFZo5TqCjsdccH81Iv5qRfzUy/mp17MT71Myk828xERERF5wGCKiIiIyINiCKauDTsBMcP81Iv5qRfzUy/mp17MT72Myc/Y95kiIiIi8lMx1ExRHiJSLiJi/V0qIlVhpylqRCQhIiUiUh52WuIgW35ar8vSXlemvyYKkySlH6/lIlIRZpooWLENpkRktojcJSKPiMg/RGRM2Gky1H0AHhWRNQAeBPA1ABCRE0VktYg8KSI/TwVZVsD1HRG5T0SeFpFzUysSkSEi8icRedDK9/1D+UXBWwXgIQBbUm9YhevnReReK5++JSIl1meDRORXVh4+KSLHpX1vtIjcJiIPWd+dlfbZASJyt4g8buVz1kd0Y2BAfgKYCuAdEVljHav3A5gHMD8LEZEDReRhEXnCyoeF1vtaz/FiKXNz5GctgM1px+cDAA61lmd+5iEiJ1m/8Ukrj6Zb70fr+FRKxe4fgGoA6wCMs14fBGB12Oky8R+AlwAkMt6bj2RhUA1AAHwbwGXWZ58HcLX1fiWAfwPY3/rsLwCOtv7uAPAigKawf2OAefl+2t/HALgFQBmSNy2/A3Cq9dmPAHzO+rsRwNMAJlt5+gSABdZnswE8B6AcQDuAFwAMtT47C8Bvw/7NAebn/gB+nmM55mfuPKwC8DqAsdbrZdZ5qfUcL5YyN09+dgK4I8d3mJ+587MBwF8BDLZeH2PlSeSOz9Az06cddDiAG9JeC4D1AGrDTptJ/wCUWgXDz5GslfpvAMMBfB/A6WnLTQGwxvr7cQAT0j470zrQh1rrkrTPfg/goLB/Z4D5+U7a37cAWJ72eiWAP1jH4vsAqtI++xaSF/NZAO7NWOeDSNbKnAvg8rT3a61jWvz4LSb8y8jPjwP4XwB/t/Lkc1ZeMj/z52ELgCPTXk9DMqDUeo4XS5mbJz/3BnA3gD8DWAPgmwDKmZ+O8las8/rqKB6fcW3mG43kAQ4AUMncewTJu1Xq0wqgBsBVAOYC+CeAnyAj/6y/261mqjYA/0n77GEkD/R2AC9YeZ35WTHKzMNUXjQC2KSU+jDLZ5nfyfmZUmoLkkFEs/aUm6kdyVq+wwHsC2AFgCPA/MxLKfW2UuoPACAi0wD8EcBXof8cL4oyN09+tiNZlp6EZK1KK4Czra8xPwsQkWuQbCU5FsA3EMHjM67B1A4A2zPe2wWAHQL7exVAs1LqIevgugbAHAC70T//upGsxRIAW63PU1L5yjzvLzM/UnmxE8C2jGXt5GGx5+/XARyslNqilPoAwA8BLAfz0xYRORXJJpDTlVLXY+Dv93qOF3t+XgdgnlJqvVJqF4DvIHl8AszPgpRSn1RKdSAZmP4ZyfM6UsdnXIOpJ5Fsw043Ack2U7JYAVTmwdSDZD+T9PwbgWT/lW4k26Db0j6bgOQdxfMAOkSSTwZmfFaMMo/BCQBesmpAlIhUZn6W5Ts5PxORUgAjAbypP+lGKkGyr1P6653Mz8JE5EwkmzX3UUr9w3o7M2+8nuNFU+bmyE9B/7K0BMmAAGB+5iTJp3KHp14rpW5C8jx8G1E7PsNuJ/XjH4A6JKv0Oq3XBwD4V9jpMu0fgDEAXgEwwnp9EpL9euYj+ZRfqvPfNwFcai3zeQA/QF/nv7sBLLE++wuAI6y/25CcyLoh7N8ZUF4KgHfTXh8D4CYACSTvqG4AcLL12Y8AnGf9XQ/gWQDjkSyAH0fyDhcAZiBZQJQi2ZnyKSRrEgHgUwCuC/t3B5ifXwLwCyuPKgDcDqs/HvMzbz42Idl8OSbjfa3neLGUuXny8wQAf7OOzRIAvwJwFvOzYH4eYp2TQ6zXewF4C8DCqB2foWemjztpIZKdTR8EcCuA1rDTZOI/JNuon0CybfmPAFqs909DMpp/AMmLVYX1fjmSfayeQPLx9DPT1tVq5fUjAFYD2Cvs3xdgPlYB2Jr2WgB8JS0PvwagxPqsHsng6jGrwDgi7XuTrcLhIQB3Apic9tkhAB611vc/AOrD/t0B5mcVgJ9a+fmIVaCmBh1mfubOxyORbBZZY/17yMrDNt3neDGUuXnysx3AFUgG6I8g2SG6jPlZMD8FwAVIBjoPW3kw1/osUscnR0AnIoopq/lSKaV6rNeCZG3pbsXC3zHmJ+XCYIqIiIjIg7h2QCciIiIKBIMpIiIiIg8YTBERERF5wGCKiIiIyAMGU0QUWSLSIiJnhZ0OIipuDKaIKJJEpBzJwfhOFpEyEUmEnSYiKk4MpogoEqyA6SYReVZEnkVyhvmbkJwWYg2ABSIyXET+V0QeE5E1IjLH+u4DIvI5EblHRB4XkSutMYOIiDxjMEVEUbEEQKlSaiKSI/dvA7ASwNNKqelKqbsBXAng+0qp6UhO8fEra2DFbUiOgLwPgJlIjgB+bPA/gYjiiMEUEUXFYwBaReQaADUAvptlmX0BXCoi9yE5l98gAMMAKADfVUrtVMnJUq8DsDiYZBNR3LGPARFFglLqTRGZjeQkvR8FcCmAE7MseoBS6n0g2a9KKbXTmkg+fTZ53kgSkTYsUIgoEkTkBCQnjL4XwJeQbK7bhWTtE0SkBMnJjD9qve4EcH9a36jPiEi51VH949ayRESeMZgioqi4FcAeAJ4FcB+A8wG8AeBlEXkMwH4AzgawXEQeBfBrAGdYzXpAcob5uwA8CuBFAP8TYNqJKMY40TERxZ6I/BPAWUqpJ8JOCxHFD2umiKgYDAJQGXYiiCieWDNFRERE5AFrpoiIiIg8YDBFRERE5AGDKSIiIiIPGEwRERERecBgioiIiMgDBlNEREREHvx/FhH1OP+xr5AAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10.0, 8.0))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_title(\"test data accuracy\")\n",
    "\n",
    "ax1.plot(accuracy_stack)\n",
    "ax1.set_xlabel(\"step\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.5167330677290837,\n 0.5167330677290837,\n 0.5186586985391767,\n 0.5219787516600266,\n 0.5228419654714476,\n 0.5228419654714476,\n 0.5237051792828685,\n 0.5215803452855245,\n 0.5199867197875166,\n 0.5169986719787517,\n 0.5166666666666667,\n 0.5166666666666667,\n 0.5195883134130146,\n 0.5195883134130146,\n 0.5197875166002656,\n 0.5197875166002656,\n 0.5197875166002656,\n 0.5197875166002656,\n 0.5192563081009296,\n 0.5087649402390438,\n 0.5162018592297477,\n 0.5168658698539177,\n 0.5168658698539177,\n 0.5186586985391767,\n 0.5186586985391767,\n 0.5201859229747676,\n 0.5201859229747676,\n 0.5250332005312085,\n 0.5250332005312085,\n 0.5274900398406375,\n 0.5274900398406375,\n 0.5274900398406375,\n 0.5307436918990703,\n 0.5307436918990703,\n 0.5307436918990703,\n 0.5307436918990703,\n 0.5307436918990703,\n 0.5307436918990703,\n 0.5307436918990703,\n 0.5353253652058433,\n 0.5395750332005312,\n 0.5410358565737052,\n 0.5410358565737052,\n 0.5410358565737052,\n 0.5410358565737052,\n 0.5410358565737052,\n 0.5410358565737052,\n 0.5414342629482072,\n 0.5389774236387782,\n 0.5373837981407702,\n 0.5374501992031873,\n 0.5320717131474103,\n 0.5320717131474103,\n 0.5320717131474103,\n 0.5320717131474103,\n 0.5320717131474103,\n 0.5367197875166002,\n 0.5405710491367862,\n 0.5347941567065073,\n 0.5347941567065073,\n 0.5376494023904382,\n 0.5376494023904382,\n 0.5277556440903054,\n 0.5241699867197875,\n 0.5242363877822045,\n 0.5266268260292165,\n 0.5236387782204516,\n 0.5236387782204516,\n 0.5236387782204516,\n 0.5245683930942895,\n 0.5245683930942895,\n 0.5303452855245684,\n 0.5303452855245684,\n 0.5303452855245684,\n 0.5337981407702523,\n 0.5381142098273572,\n 0.5428286852589641,\n 0.5382470119521913,\n 0.5435590969455512,\n 0.5412350597609562,\n 0.5412350597609562,\n 0.5412350597609562,\n 0.5384462151394422,\n 0.5384462151394422,\n 0.5384462151394422,\n 0.5384462151394422,\n 0.5377822045152723,\n 0.5398406374501992,\n 0.5345949535192563,\n 0.5271580345285525,\n 0.5272244355909694,\n 0.5283532536520584,\n 0.5223771580345286,\n 0.5201859229747676,\n 0.5201859229747676,\n 0.5221115537848605,\n 0.5221115537848605,\n 0.5197875166002656,\n 0.5211155378486055,\n 0.5211155378486055,\n 0.5287516600265604,\n 0.5287516600265604,\n 0.5228419654714476,\n 0.5209827357237716,\n 0.5209827357237716,\n 0.5250996015936255,\n 0.5320053120849934,\n 0.5320053120849934,\n 0.5278884462151394,\n 0.5278220451527225,\n 0.5278220451527225,\n 0.5324701195219124,\n 0.5328021248339974,\n 0.5347277556440903,\n 0.5348605577689243,\n 0.5369853917662682,\n 0.5297476759628154,\n 0.5297476759628154,\n 0.5210491367861886,\n 0.5210491367861886,\n 0.5207171314741036,\n 0.5231075697211155,\n 0.5231075697211155,\n 0.5292828685258965,\n 0.5322709163346614,\n 0.5322709163346614,\n 0.5322709163346614,\n 0.5322709163346614,\n 0.5322709163346614,\n 0.5320053120849934,\n 0.5333997343957503,\n 0.5389774236387782,\n 0.5391102257636122,\n 0.5352589641434263,\n 0.5352589641434263,\n 0.5388446215139442,\n 0.5388446215139442,\n 0.5388446215139442,\n 0.5388446215139442,\n 0.5406374501992032,\n 0.5406374501992032,\n 0.5405046480743692,\n 0.5448871181938911,\n 0.5464143426294821,\n 0.549402390438247,\n 0.549468791500664,\n 0.549468791500664,\n 0.549800796812749,\n 0.550996015936255,\n 0.550996015936255,\n 0.552324037184595,\n 0.551660026560425,\n 0.5519256308100929,\n 0.5519256308100929,\n 0.55199203187251,\n 0.5573041168658699,\n 0.5573041168658699,\n 0.5573041168658699,\n 0.5573041168658699,\n 0.55132802124834,\n 0.55132802124834,\n 0.550929614873838,\n 0.5530544488711819,\n 0.5577689243027888,\n 0.5612217795484727,\n 0.5627490039840638,\n 0.5679282868525897,\n 0.5669322709163347,\n 0.5669322709163347,\n 0.5669322709163347,\n 0.5625498007968127,\n 0.5570385126162019,\n 0.5575697211155378,\n 0.5575697211155378,\n 0.5575697211155378,\n 0.5507968127490039,\n 0.550996015936255,\n 0.550996015936255,\n 0.5541832669322709,\n 0.5541832669322709,\n 0.5569057104913678,\n 0.5569057104913678,\n 0.5569057104913678,\n 0.5557104913678619,\n 0.5527888446215139,\n 0.5527888446215139,\n 0.5527888446215139,\n 0.548273572377158,\n 0.548273572377158,\n 0.5537184594953519,\n 0.5616865869853918,\n 0.5616865869853918,\n 0.5616865869853918,\n 0.5583665338645418,\n 0.5658698539176626,\n 0.6144090305444887,\n 0.5598273572377158,\n 0.5642098273572377,\n 0.6164010624169987,\n 0.6142098273572377,\n 0.6124833997343957,\n 0.6134794156706508,\n 0.6169322709163346,\n 0.6201195219123506,\n 0.6201195219123506,\n 0.6221779548472776,\n 0.6223771580345285,\n 0.6223771580345285,\n 0.6223771580345285,\n 0.6246347941567065,\n 0.6246347941567065,\n 0.6246347941567065,\n 0.6246347941567065,\n 0.6246347941567065,\n 0.6250332005312085,\n 0.6250332005312085,\n 0.6274236387782205,\n 0.6266268260292165,\n 0.6268260292164675,\n 0.6268260292164675,\n 0.6270252324037184,\n 0.6269588313413015,\n 0.6276228419654715,\n 0.6267596281540505,\n 0.6267596281540505,\n 0.6267596281540505,\n 0.6267596281540505,\n 0.6231739707835325,\n 0.6238379814077025,\n 0.6210491367861886,\n 0.6162682602921646,\n 0.6162682602921646,\n 0.6162682602921646,\n 0.6162682602921646,\n 0.6162682602921646,\n 0.6160026560424967,\n 0.6203851261620186,\n 0.6219787516600266,\n 0.6219787516600266,\n 0.6219787516600266,\n 0.6248339973439575,\n 0.6264276228419655,\n 0.6264276228419655,\n 0.6264276228419655,\n 0.6264276228419655,\n 0.6268260292164675,\n 0.6247011952191235,\n 0.6250332005312085,\n 0.6205843293492695,\n 0.6157370517928287,\n 0.6157370517928287,\n 0.6157370517928287,\n 0.6160026560424967,\n 0.6211155378486056,\n 0.6243691899070385,\n 0.6202523240371846,\n 0.6202523240371846,\n 0.6226427622841966,\n 0.6173306772908367,\n 0.6174634794156707,\n 0.6138778220451527,\n 0.6152058432934927,\n 0.6179282868525896,\n 0.6217795484727756,\n 0.6189243027888446,\n 0.6134130146082337,\n 0.6134130146082337,\n 0.6134794156706508,\n 0.6134794156706508,\n 0.6179282868525896,\n 0.6213811420982736,\n 0.6213811420982736,\n 0.6213811420982736,\n 0.6217795484727756,\n 0.6218459495351926,\n 0.6223107569721116,\n 0.6231075697211156,\n 0.6231739707835325,\n 0.6177954847277557,\n 0.6191235059760957,\n 0.6120849933598937,\n 0.6106905710491368,\n 0.6106905710491368,\n 0.6106905710491368,\n 0.6106905710491368,\n 0.6106905710491368,\n 0.551195219123506,\n 0.545816733067729,\n 0.5458831341301461,\n 0.545816733067729,\n 0.545816733067729,\n 0.5457503320053121,\n 0.5457503320053121,\n 0.5457503320053121,\n 0.545816733067729,\n 0.545816733067729,\n 0.548871181938911,\n 0.548871181938911,\n 0.548871181938911,\n 0.548871181938911,\n 0.548871181938911,\n 0.548871181938911,\n 0.548871181938911,\n 0.5388446215139442,\n 0.5466799468791501,\n 0.5466799468791501,\n 0.5466799468791501,\n 0.5466799468791501,\n 0.5466799468791501,\n 0.5466799468791501,\n 0.552988047808765,\n 0.552988047808765,\n 0.552988047808765,\n 0.552988047808765,\n 0.5538512616201859,\n 0.5658698539176626,\n 0.5658698539176626,\n 0.549468791500664,\n 0.5370517928286852,\n 0.5370517928286852,\n 0.545484727755644,\n 0.545484727755644,\n 0.5460823373173971,\n 0.548804780876494,\n 0.5413014608233732,\n 0.549269588313413,\n 0.5405046480743692,\n 0.5405046480743692,\n 0.5320053120849934,\n 0.5321381142098274,\n 0.5282868525896415,\n 0.5282868525896415,\n 0.5282868525896415,\n 0.5284860557768924,\n 0.5234395750332005,\n 0.5315405046480743,\n 0.5296148738379814,\n 0.5314077025232403,\n 0.5383798140770253,\n 0.5383798140770253,\n 0.5383798140770253,\n 0.5339973439575033,\n 0.5368525896414342,\n 0.5368525896414342,\n 0.5368525896414342,\n 0.5326029216467464,\n 0.5384462151394422,\n 0.5413678618857902,\n 0.5417662682602922,\n 0.5418326693227091,\n 0.5418326693227091,\n 0.5418326693227091,\n 0.5541832669322709,\n 0.5541832669322709,\n 0.5541832669322709,\n 0.5541832669322709,\n 0.5542496679946879,\n 0.5545816733067729,\n 0.5762948207171315,\n 0.5764940239043824,\n 0.5413678618857902,\n 0.5413678618857902,\n 0.5441567065073041,\n 0.5391766268260292,\n 0.5391766268260292,\n 0.5391766268260292,\n 0.5446215139442231,\n 0.5446215139442231,\n 0.549269588313413,\n 0.5411686586985391,\n 0.5376494023904382,\n 0.5430942895086321,\n 0.5437583001328021,\n 0.5342629482071714,\n 0.5342629482071714,\n 0.5413014608233732,\n 0.5341965471447543,\n 0.5341965471447543,\n 0.5341965471447543,\n 0.5341965471447543,\n 0.5345285524568393,\n 0.5378486055776892,\n 0.5378486055776892,\n 0.5289508632138115,\n 0.5289508632138115,\n 0.5214475431606905,\n 0.5214475431606905,\n 0.5282204515272244,\n 0.5288844621513944,\n 0.5351261620185923,\n 0.5355245683930943,\n 0.5426294820717131,\n 0.5357901726427623,\n 0.5357901726427623,\n 0.5358565737051793,\n 0.552324037184595,\n 0.552324037184595,\n 0.5613545816733068,\n 0.5476759628154051,\n 0.548472775564409,\n 0.550398406374502,\n 0.5391766268260292,\n 0.5391766268260292,\n 0.5332005312084993,\n 0.5341965471447543,\n 0.5342629482071714,\n 0.5342629482071714,\n 0.5342629482071714,\n 0.5343293492695883,\n 0.5345285524568393,\n 0.5399734395750332,\n 0.5333333333333333,\n 0.5333333333333333,\n 0.5333333333333333,\n 0.5339973439575033,\n 0.549867197875166,\n 0.5527888446215139,\n 0.6051128818061089,\n 0.549601593625498,\n 0.5372509960159363,\n 0.5319389110225764,\n 0.5264940239043825,\n 0.5264940239043825,\n 0.5354581673306773,\n 0.549800796812749,\n 0.549800796812749,\n 0.603585657370518,\n 0.6119521912350597,\n 0.6119521912350597,\n 0.6132138114209827,\n 0.6132138114209827,\n 0.6133466135458168,\n 0.6132802124833997,\n 0.5967463479415671,\n 0.553519256308101,\n 0.549468791500664,\n 0.549468791500664,\n 0.549667994687915,\n 0.549867197875166,\n 0.5567065073041169,\n 0.5567065073041169,\n 0.6055776892430279,\n 0.6055776892430279,\n 0.6072377158034529,\n 0.6072377158034529,\n 0.6072377158034529,\n 0.6072377158034529,\n 0.6127490039840637,\n 0.6197211155378486,\n 0.6245683930942895,\n 0.6245683930942895,\n 0.6245019920318725,\n 0.6265604249667994,\n 0.6265604249667994,\n 0.6265604249667994,\n 0.6274900398406374,\n 0.6280212483399734,\n 0.6281540504648074,\n 0.6281540504648074,\n 0.6280212483399734,\n 0.6280212483399734,\n 0.6296812749003984,\n 0.6333997343957504,\n 0.6333997343957504,\n 0.6337981407702523,\n 0.6347277556440903,\n 0.6346613545816733,\n 0.6346613545816733,\n 0.6346613545816733,\n 0.6348605577689242,\n 0.6355245683930942,\n 0.6355245683930942,\n 0.6355245683930942,\n 0.6324037184594954,\n 0.6324037184594954,\n 0.6324037184594954,\n 0.6322045152722443,\n 0.6302124833997343,\n 0.6241035856573706,\n 0.6255644090305444,\n 0.6231739707835325,\n 0.6218459495351926,\n 0.6218459495351926,\n 0.6160690571049137,\n 0.6160690571049137,\n 0.6160690571049137,\n 0.6160690571049137,\n 0.6207171314741036,\n 0.6207171314741036,\n 0.6239043824701195,\n 0.6167994687915007,\n 0.6062416998671979,\n 0.6090969455511288,\n 0.6140106241699868,\n 0.6140106241699868,\n 0.6141434262948208,\n 0.6142098273572377,\n 0.6142098273572377,\n 0.6160690571049137,\n 0.6160690571049137,\n 0.6168658698539177,\n 0.6236387782204516,\n 0.6236387782204516,\n 0.6236387782204516,\n 0.6265604249667994,\n 0.6265604249667994,\n 0.6265604249667994,\n 0.6265604249667994,\n 0.6265604249667994,\n 0.6280876494023905,\n 0.6264940239043825,\n 0.6264940239043825,\n 0.6266932270916334,\n 0.6266932270916334,\n 0.6266932270916334,\n 0.6266268260292165,\n 0.6263612217795484,\n 0.6211819389110226,\n 0.6245683930942895,\n 0.6206507304116866,\n 0.6272244355909694,\n 0.6272244355909694,\n 0.6272244355909694,\n 0.6272244355909694,\n 0.6272244355909694,\n 0.6282204515272244,\n 0.6310756972111554,\n 0.6310756972111554,\n 0.6264276228419655,\n 0.6264276228419655,\n 0.6219787516600266,\n 0.6231739707835325,\n 0.6250996015936255,\n 0.6250996015936255,\n 0.6228419654714475,\n 0.6247011952191235,\n 0.6260292164674635,\n 0.6260292164674635,\n 0.6282868525896415,\n 0.6282868525896415,\n 0.6282868525896415,\n 0.6201195219123506,\n 0.6201195219123506,\n 0.6162682602921646,\n 0.6162682602921646,\n 0.6221115537848606,\n 0.6264276228419655,\n 0.6215803452855245,\n 0.6215803452855245,\n 0.6247011952191235,\n 0.6247675962815405,\n 0.6247675962815405,\n 0.6260292164674635,\n 0.6261620185922975,\n 0.6261620185922975,\n 0.6266268260292165,\n 0.6172642762284196,\n 0.6175298804780877,\n 0.6187250996015936,\n 0.6203851261620186,\n 0.6206507304116866,\n 0.6206507304116866,\n 0.6276892430278884,\n 0.6286852589641434,\n 0.6304116865869854,\n 0.6341301460823373,\n 0.6406374501992032,\n 0.6406374501992032,\n 0.6415670650730412,\n 0.6355245683930942,\n 0.6384462151394422,\n 0.6403054448871182,\n 0.6406374501992032,\n 0.6406374501992032,\n 0.6428950863213811,\n 0.6436918990703852,\n 0.6429614873837981,\n 0.6429614873837981,\n 0.6365205843293492,\n 0.6357901726427623,\n 0.6357237715803453,\n 0.6357237715803453,\n 0.6304116865869854,\n 0.6240371845949535,\n 0.6240371845949535,\n 0.6292164674634794,\n 0.6311420982735724,\n 0.6288844621513944,\n 0.6288844621513944,\n 0.6183930942895086,\n 0.6184594953519257,\n 0.6207835325365206,\n 0.6282204515272244,\n 0.6183266932270917,\n 0.6187915006640107,\n 0.6164010624169987,\n 0.6176626826029217,\n 0.6182602921646746,\n 0.6150730411686587,\n 0.6173306772908367,\n 0.6172642762284196,\n 0.6172642762284196,\n 0.6183266932270917,\n 0.6270916334661355,\n 0.6270916334661355,\n 0.6299468791500664,\n 0.6299468791500664,\n 0.6226427622841966,\n 0.6227755644090306,\n 0.6227755644090306,\n 0.6227091633466135,\n 0.6226427622841966,\n 0.6233731739707835,\n 0.6150730411686587,\n 0.6150730411686587,\n 0.6150066401062417,\n 0.6150066401062417,\n 0.6150066401062417,\n 0.6150066401062417,\n 0.6102257636122178,\n 0.6033200531208499,\n 0.6154714475431607,\n 0.6158698539176627,\n 0.6158698539176627,\n 0.6159362549800796,\n 0.6159362549800796,\n 0.6213811420982736,\n 0.602921646746348,\n 0.5948207171314741,\n 0.5949535192563081,\n 0.595219123505976,\n 0.595883134130146,\n 0.5977423638778221,\n 0.5974103585657371,\n 0.597875166002656,\n 0.601261620185923,\n 0.6113545816733068,\n 0.6207835325365206,\n 0.6226427622841966,\n 0.6229083665338645,\n 0.6143426294820717,\n 0.6057104913678619,\n 0.6146082337317397,\n 0.6237051792828685,\n 0.6286188579017264,\n 0.6299468791500664,\n 0.6340637450199204,\n 0.6340637450199204,\n 0.6283532536520584,\n 0.6257636122177955,\n 0.6304116865869854,\n 0.6316733067729083,\n 0.6322045152722443,\n 0.6322045152722443,\n 0.6355245683930942,\n 0.6355245683930942,\n 0.6355245683930942,\n 0.6354581673306773,\n 0.6359893758300132,\n 0.6370517928286853,\n 0.6373837981407703,\n 0.6389110225763612,\n 0.6357237715803453,\n 0.6355909694555113,\n 0.6358565737051792,\n 0.6371181938911022,\n 0.6353917662682603,\n 0.6327357237715804,\n 0.6328685258964143,\n 0.6330677290836654,\n 0.6344621513944223,\n 0.6344621513944223,\n 0.6344621513944223,\n 0.6344621513944223,\n 0.6345949535192563,\n 0.6345949535192563,\n 0.6367861885790173,\n 0.6395750332005312,\n 0.6395750332005312,\n 0.6391766268260293,\n 0.6391102257636122,\n 0.6391102257636122,\n 0.6365205843293492,\n 0.6365205843293492,\n 0.6409030544488712,\n 0.6404382470119522,\n 0.6335989375830013,\n 0.6347277556440903,\n 0.6365869853917663,\n 0.6390438247011953,\n 0.6353917662682603,\n 0.6353917662682603,\n 0.6353917662682603,\n 0.6353917662682603,\n 0.6386454183266932,\n 0.6386454183266932,\n 0.6329349269588314,\n 0.6341965471447543,\n 0.6250996015936255,\n 0.6296812749003984,\n 0.6312084993359893,\n 0.6209827357237716,\n 0.6214475431606906,\n 0.6021912350597609,\n 0.598140770252324,\n 0.599468791500664,\n 0.599468791500664,\n 0.599535192563081,\n 0.599800796812749,\n 0.599800796812749,\n 0.600730411686587,\n 0.60066401062417,\n 0.601062416998672,\n 0.5905046480743692,\n 0.5911022576361222,\n 0.5911022576361222,\n 0.5912350597609561,\n 0.5911022576361222,\n 0.5911022576361222,\n 0.5911022576361222,\n 0.5822709163346613,\n 0.5822709163346613,\n 0.5822709163346613,\n 0.5831341301460823,\n 0.5832669322709163,\n 0.5837981407702523,\n 0.5731739707835325,\n 0.5751660026560425,\n 0.5818725099601594,\n 0.5808764940239044,\n 0.5810092961487384,\n 0.5883798140770252,\n 0.5922974767596282,\n 0.5887782204515273,\n 0.5880478087649402,\n 0.5879814077025233,\n 0.5909030544488711,\n 0.5909030544488711,\n 0.5918990703851261,\n 0.597675962815405,\n 0.5928950863213811,\n 0.5929614873837982,\n 0.5927622841965472,\n 0.5990703851261621,\n 0.6065073041168658,\n 0.6065073041168658,\n 0.6064409030544489,\n 0.6065073041168658,\n 0.6073705179282869,\n 0.6073705179282869,\n 0.5918990703851261,\n 0.6019920318725099,\n 0.598472775564409,\n 0.598472775564409,\n 0.5987383798140771,\n 0.598804780876494,\n 0.601128818061089,\n 0.6054448871181939,\n 0.6019920318725099,\n 0.6065073041168658,\n 0.6084329349269588,\n 0.6084329349269588,\n 0.6083665338645419,\n 0.5897742363877823,\n 0.5987383798140771,\n 0.598804780876494,\n 0.6057104913678619,\n 0.6057104913678619,\n 0.6053784860557769,\n 0.6063081009296148,\n 0.6079017264276229,\n 0.6088313413014608,\n 0.6124169986719787,\n 0.601062416998672,\n 0.603253652058433,\n 0.5915670650730411,\n 0.5916334661354582,\n 0.5928950863213811,\n 0.5911686586985392,\n 0.6053784860557769,\n 0.6082337317397079,\n 0.6073705179282869,\n 0.6074369189907038,\n 0.6078353253652058,\n 0.6188579017264276,\n 0.6048472775564409,\n 0.6154050464807437,\n 0.6183930942895086,\n 0.6164010624169987,\n 0.6261620185922975,\n 0.6224435590969456,\n 0.6225099601593626,\n 0.6275564409030544,\n 0.6276892430278884,\n 0.6278220451527224,\n 0.6327357237715804,\n 0.6328021248339973,\n 0.6332005312084993,\n 0.6333997343957504,\n 0.6233731739707835,\n 0.6237715803452856,\n 0.6151394422310758,\n 0.6171978751660027,\n 0.6072377158034529,\n 0.6071049136786189,\n 0.6074369189907038,\n 0.6041832669322709,\n 0.6110889774236388,\n 0.6110889774236388,\n 0.602456839309429,\n 0.602456839309429,\n 0.6025232403718459,\n 0.595551128818061,\n 0.6144090305444887,\n 0.6139442231075697,\n 0.6140770252324037,\n 0.6185922974767596,\n 0.6245683930942895,\n 0.6247011952191235,\n 0.6247675962815405,\n 0.6248339973439575,\n 0.6245683930942895,\n 0.6078353253652058,\n 0.6130810092961487,\n 0.6141434262948208,\n 0.6246347941567065,\n 0.6208499335989376,\n 0.6314077025232404,\n 0.6317397078353254,\n 0.6317397078353254,\n 0.6397078353253652,\n 0.6404382470119522,\n 0.6405046480743692,\n 0.6403718459495352,\n 0.6434926958831342,\n 0.6441567065073042,\n 0.6444223107569721,\n 0.6442895086321381,\n 0.6442895086321381,\n 0.6442895086321381,\n 0.6442895086321381,\n 0.648738379814077,\n 0.6423638778220452,\n 0.646746347941567,\n 0.6441567065073042,\n 0.6441567065073042,\n 0.6446879150066401,\n 0.6446215139442231,\n 0.6446215139442231,\n 0.6445551128818061,\n 0.6445551128818061,\n 0.6474767596281541,\n 0.648937583001328,\n 0.6422974767596281,\n 0.6430278884462152,\n 0.6446879150066401,\n 0.6450863213811421,\n 0.6453519256308101,\n 0.6454183266932271,\n 0.6356573705179283,\n 0.6304116865869854,\n 0.6304116865869854,\n 0.6139442231075697,\n 0.6237051792828685,\n 0.6205843293492695,\n 0.6214475431606906,\n 0.6361885790172642,\n 0.6286188579017264,\n 0.6336653386454183,\n 0.6389774236387782,\n 0.6395750332005312,\n 0.6397078353253652,\n 0.6366533864541832,\n 0.6367861885790173,\n 0.6365869853917663,\n 0.6278884462151394,\n 0.6116201859229747,\n 0.6116865869853918,\n 0.6220451527224435,\n 0.6228419654714475,\n 0.6112217795484728,\n 0.6118193891102257,\n 0.5994023904382471,\n 0.5796812749003984,\n 0.597675962815405,\n 0.600398406374502,\n 0.6177290836653386,\n 0.6183930942895086,\n 0.6329349269588314,\n 0.6379814077025232,\n 0.6302788844621514,\n 0.6302124833997343,\n 0.6302124833997343,\n 0.6138778220451527,\n 0.6208499335989376,\n 0.6112217795484728,\n 0.6231075697211156,\n 0.6241035856573706,\n 0.6276892430278884,\n 0.6281540504648074,\n 0.6197211155378486,\n 0.6248339973439575,\n 0.6349933598937583,\n 0.6350597609561753,\n 0.6352589641434263,\n 0.6356573705179283,\n 0.6342629482071713,\n 0.6347941567065073,\n 0.6441567065073042,\n 0.6442231075697211,\n 0.6445551128818061,\n 0.6474767596281541,\n 0.648937583001328,\n 0.649070385126162,\n 0.649070385126162,\n 0.6312084993359893,\n 0.6316069057104914,\n 0.6169322709163346,\n 0.6177290836653386,\n 0.6162018592297477,\n 0.6229083665338645,\n 0.6121513944223107,\n 0.6181938911022576,\n 0.5893758300132802,\n 0.5768924302788845,\n 0.5806772908366534,\n 0.5855245683930943,\n 0.5929614873837982,\n 0.5954847277556441,\n 0.5849933598937583,\n 0.5672642762284197,\n 0.5762948207171315,\n 0.5802788844621514,\n 0.5810756972111554,\n 0.5730411686586986,\n 0.5705843293492696,\n 0.5749667994687915,\n 0.5903718459495352,\n 0.5744355909694555,\n 0.5754316069057105,\n 0.5766932270916335,\n 0.5873173970783533,\n 0.5856573705179283,\n 0.5900398406374502,\n 0.6048472775564409,\n 0.6079681274900398,\n 0.6255644090305444,\n 0.6073705179282869,\n 0.6081009296148738,\n 0.6089641434262948,\n 0.6090305444887119,\n 0.6120849933598937,\n 0.6141434262948208,\n 0.6217795484727756,\n 0.6258300132802125,\n 0.6287516600265605,\n 0.6313413014608233,\n 0.6405046480743692,\n 0.6407038512616202,\n 0.6340637450199204,\n 0.6363213811420982,\n 0.6365205843293492,\n 0.6418990703851262,\n 0.6450199203187251,\n 0.6424966799468792,\n 0.6461487383798141,\n 0.6448871181938911,\n 0.6239043824701195,\n 0.6055112881806108,\n 0.6075033200531208,\n 0.6300796812749004,\n 0.6304116865869854,\n 0.6309428950863214,\n 0.6252324037184595,\n 0.6039840637450199,\n 0.6043160690571049,\n 0.6206507304116866,\n 0.6262284196547144,\n 0.6276892430278884,\n 0.6167330677290837,\n 0.6212483399734395,\n 0.6102257636122178,\n 0.6155378486055777,\n 0.6354581673306773,\n 0.6380478087649403,\n 0.6404382470119522,\n 0.6159362549800796,\n 0.599269588313413,\n 0.5752988047808765,\n 0.5755644090305445,\n 0.5760292164674635,\n 0.5848605577689243,\n 0.5971447543160691,\n 0.6166666666666667,\n 0.5982735723771581,\n 0.599136786188579,\n 0.601128818061089,\n 0.6046480743691899,\n 0.5885790172642762,\n 0.5918326693227092,\n ...]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy_stack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}