{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "m = nn.Linear(20,30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "input = torch.ones(128, 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "output = m(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-1.6946, -0.0449, -0.4358,  ...,  0.3827,  0.9301, -0.0555],\n        [-1.6946, -0.0449, -0.4358,  ...,  0.3827,  0.9301, -0.0555],\n        [-1.6946, -0.0449, -0.4358,  ...,  0.3827,  0.9301, -0.0555],\n        ...,\n        [-1.6946, -0.0449, -0.4358,  ...,  0.3827,  0.9301, -0.0555],\n        [-1.6946, -0.0449, -0.4358,  ...,  0.3827,  0.9301, -0.0555],\n        [-1.6946, -0.0449, -0.4358,  ...,  0.3827,  0.9301, -0.0555]],\n       grad_fn=<AddmmBackward>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-bc57ef3bb176>:3: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  m = F.log_softmax(a_tensor)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([-9.4586, -8.4586, -7.4586, -6.4586, -5.4586, -4.4586, -3.4586, -2.4586,\n        -1.4586, -0.4586])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(10).astype(np.float32)\n",
    "a_tensor = torch.from_numpy(a).clone()\n",
    "m = F.log_softmax(a_tensor)\n",
    "m\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "class Net(nn.Module):\n",
    "    ## 個々で\n",
    "    def __init__(self):\n",
    "        ## nn.Moduleを継承するよってことで。\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 3)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        ## 最後にlog softmax(ココは普通にF.softmax()に変えても処理は回ります。)で出力\n",
    "        return F.log_softmax(x, dim = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model = Net()\n",
    "train_X = torch.Tensor(iris.data)       ## torch.Tensor型: Pytorch版のnumpy形式\n",
    "train_y = torch.LongTensor(iris.target)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 0\tLoss: 2.297\tAccuracy: 0.327\n",
      "Train Step: 100\tLoss: 0.559\tAccuracy: 0.893\n",
      "Train Step: 200\tLoss: 0.457\tAccuracy: 0.920\n",
      "Train Step: 300\tLoss: 0.406\tAccuracy: 0.953\n",
      "Train Step: 400\tLoss: 0.372\tAccuracy: 0.967\n",
      "Train Step: 500\tLoss: 0.346\tAccuracy: 0.967\n",
      "Train Step: 600\tLoss: 0.324\tAccuracy: 0.967\n",
      "Train Step: 700\tLoss: 0.306\tAccuracy: 0.973\n",
      "Train Step: 800\tLoss: 0.290\tAccuracy: 0.973\n",
      "Train Step: 900\tLoss: 0.276\tAccuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.02)\n",
    "## エポック数(何回学習させるか)\n",
    "epochs = 1000\n",
    "## 後の可視化用に取っておく\n",
    "loss_log, accuracy_log = [], []\n",
    "w = []\n",
    "\n",
    "data, target = Variable(train_X), Variable(train_y)\n",
    "for epoch in range(epochs):\n",
    "    ## pytorchでは勾配を蓄積する仕組みなので更新前に初期化しておきます\n",
    "    optimizer.zero_grad()\n",
    "    ## feed forward(つまり予測させます)\n",
    "    output = model(data)\n",
    "    ## 予実差からの誤差を決めます。nll_lossは、Negative Log Likelihood(負の対数尤度)ですね。\n",
    "    loss = F.nll_loss(output, target)\n",
    "\n",
    "    ## Back Propagation\n",
    "    loss.backward()\n",
    "    w.append(list(model.parameters())[0])\n",
    "    # print(list(model.parameters())[0].grad)\n",
    "    ## 各層内のパラメータの更新\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    ## 正解率の計算\n",
    "    prediction = output.data.max(1)[1]\n",
    "    accuracy = prediction.eq(target.data).sum().numpy() / len(iris.data)\n",
    "\n",
    "    ## 記録を取っておきます\n",
    "    loss_log.append(loss.item())\n",
    "    accuracy_log.append(accuracy)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('Train Step: {}\\tLoss: {:.3f}\\tAccuracy: {:.3f}'.format(epoch, loss.data.item(), accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "a = list(model.parameters())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[Parameter containing:\n tensor([[ 0.3532,  0.7583, -1.3931, -0.6541],\n         [ 0.1787, -0.6736,  0.2229, -0.0440],\n         [-0.9763, -0.9781,  1.7044,  1.2810]], requires_grad=True),\n Parameter containing:\n tensor([ 0.2214,  0.5510, -0.7020], requires_grad=True)]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}