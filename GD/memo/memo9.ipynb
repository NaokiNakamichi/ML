{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from ML2_lib import RV_SGDAve\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import model_selection\n",
    "from ML2_lib import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "hoge = RV_SGDAve.RVSGDByTorch(lr=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "real_data = load_iris()\n",
    "x = real_data.data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "x = scaler.transform(x)\n",
    "# x = x.T\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "y = real_data.target\n",
    "y = y.T\n",
    "\n",
    "data_train, data_test, label_train, label_test = model_selection.train_test_split(x, y)\n",
    "\n",
    "model = models.LinearClassification(4,3)\n",
    "lppl = hoge.learn(k=5,x=data_train,y=label_train,model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "model = models.LinearClassification(4,3)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "swa_model = AveragedModel(model)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=150)\n",
    "swa_start = 5\n",
    "\n",
    "train_X = torch.Tensor(real_data.data).float()## torch.Tensor型: Pytorch版のnumpy形式\n",
    "train_y = torch.LongTensor(real_data.target)\n",
    "\n",
    "for epoch in range(150):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      output = model(train_X)\n",
    "      loss = F.nll_loss(output, train_y)\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "      prediction = output.data.max(1)[1]\n",
    "      if epoch > swa_start:\n",
    "          swa_model.update_parameters(model)\n",
    "# # Use swa_model to make predictions on test data\n",
    "preds = swa_model(train_X)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('n_averaged', tensor(144)),\n             ('module.fc1.weight',\n              tensor([[-0.0030,  0.8189, -1.0889, -0.8011],\n                      [ 0.0216, -0.4333,  0.0091, -0.2323],\n                      [-0.5705, -0.2816,  0.6418,  0.7262]])),\n             ('module.fc1.bias', tensor([ 0.5911,  0.4911, -0.6677]))])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swa_model.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(LinearClassification(\n   (fc1): Linear(in_features=4, out_features=3, bias=True)\n ),\n [tensor([[[-0.3174,  0.3169, -0.4591, -0.4188],\n           [-0.0530, -0.2691,  0.1196,  0.0599],\n           [ 0.3704, -0.0478,  0.3396,  0.3589]],\n  \n          [[-0.3541,  0.4381, -0.5719, -0.5165],\n           [-0.1182, -0.4139,  0.1658,  0.0610],\n           [ 0.4723, -0.0242,  0.4061,  0.4555]],\n  \n          [[-0.3822,  0.5176, -0.6539, -0.5874],\n           [-0.1606, -0.5007,  0.2022,  0.0583],\n           [ 0.5427, -0.0169,  0.4517,  0.5291]],\n  \n          [[-0.4061,  0.5765, -0.7199, -0.6444],\n           [-0.1903, -0.5576,  0.2329,  0.0532],\n           [ 0.5963, -0.0188,  0.4870,  0.5913]],\n  \n          [[-0.4271,  0.6233, -0.7757, -0.6926],\n           [-0.2121, -0.5970,  0.2596,  0.0463],\n           [ 0.6392, -0.0263,  0.5161,  0.6463]],\n  \n          [[-0.4460,  0.6624, -0.8244, -0.7346],\n           [-0.2287, -0.6250,  0.2835,  0.0382],\n           [ 0.6747, -0.0374,  0.5409,  0.6963]],\n  \n          [[-0.4632,  0.6961, -0.8677, -0.7719],\n           [-0.2414, -0.6452,  0.3052,  0.0292],\n           [ 0.7047, -0.0509,  0.5625,  0.7427]],\n  \n          [[-0.4791,  0.7258, -0.9069, -0.8056],\n           [-0.2513, -0.6597,  0.3253,  0.0195],\n           [ 0.7304, -0.0662,  0.5817,  0.7862]],\n  \n          [[-0.4938,  0.7525, -0.9428, -0.8365],\n           [-0.2590, -0.6698,  0.3439,  0.0091],\n           [ 0.7528, -0.0827,  0.5990,  0.8274]],\n  \n          [[-0.5075,  0.7767, -0.9760, -0.8649],\n           [-0.2649, -0.6766,  0.3614, -0.0017],\n           [ 0.7724, -0.1001,  0.6147,  0.8667]],\n  \n          [[-0.5204,  0.7990, -1.0069, -0.8914],\n           [-0.2694, -0.6808,  0.3778, -0.0130],\n           [ 0.7898, -0.1182,  0.6291,  0.9044]]], grad_fn=<StackBackward>),\n  tensor([[[-0.3258,  0.2770, -0.4863, -0.4466],\n           [ 0.0535, -0.2970,  0.2143,  0.1396],\n           [ 0.2723,  0.0200,  0.2720,  0.3070]],\n  \n          [[-0.3547,  0.4055, -0.6010, -0.5448],\n           [ 0.0046, -0.4579,  0.2603,  0.1298],\n           [ 0.3501,  0.0524,  0.3408,  0.4150]],\n  \n          [[-0.3789,  0.4874, -0.6847, -0.6163],\n           [-0.0226, -0.5554,  0.2958,  0.1169],\n           [ 0.4015,  0.0680,  0.3890,  0.4994]],\n  \n          [[-0.4001,  0.5467, -0.7519, -0.6736],\n           [-0.0389, -0.6204,  0.3254,  0.1029],\n           [ 0.4389,  0.0737,  0.4264,  0.5707]],\n  \n          [[-0.4188,  0.5934, -0.8084, -0.7218],\n           [-0.0490, -0.6666,  0.3513,  0.0883],\n           [ 0.4679,  0.0732,  0.4570,  0.6334]],\n  \n          [[-0.4357,  0.6319, -0.8575, -0.7635],\n           [-0.0554, -0.7006,  0.3746,  0.0735],\n           [ 0.4911,  0.0687,  0.4829,  0.6900]],\n  \n          [[-0.4510,  0.6649, -0.9010, -0.8005],\n           [-0.0592, -0.7261,  0.3958,  0.0586],\n           [ 0.5103,  0.0612,  0.5052,  0.7420]],\n  \n          [[-0.4651,  0.6938, -0.9403, -0.8338],\n           [-0.0613, -0.7454,  0.4155,  0.0436],\n           [ 0.5264,  0.0516,  0.5248,  0.7902]],\n  \n          [[-0.4781,  0.7196, -0.9761, -0.8642],\n           [-0.0621, -0.7600,  0.4338,  0.0286],\n           [ 0.5402,  0.0403,  0.5423,  0.8356]],\n  \n          [[-0.4902,  0.7430, -1.0092, -0.8921],\n           [-0.0620, -0.7708,  0.4510,  0.0136],\n           [ 0.5523,  0.0278,  0.5582,  0.8785]],\n  \n          [[-0.5016,  0.7644, -1.0399, -0.9181],\n           [-0.0612, -0.7786,  0.4673, -0.0013],\n           [ 0.5628,  0.0142,  0.5726,  0.9193]]], grad_fn=<StackBackward>),\n  tensor([[[-0.3930,  0.2929, -0.5461, -0.5024],\n           [ 0.0840, -0.3199,  0.2173,  0.1316],\n           [ 0.3090,  0.0270,  0.3288,  0.3708]],\n  \n          [[-0.4007,  0.4332, -0.6349, -0.5719],\n           [ 0.0237, -0.5072,  0.2316,  0.0812],\n           [ 0.3770,  0.0740,  0.4033,  0.4907]],\n  \n          [[-0.4167,  0.5227, -0.7061, -0.6285],\n           [-0.0044, -0.6290,  0.2485,  0.0420],\n           [ 0.4211,  0.1063,  0.4576,  0.5865]],\n  \n          [[-0.4339,  0.5881, -0.7657, -0.6759],\n           [-0.0182, -0.7185,  0.2652,  0.0078],\n           [ 0.4521,  0.1304,  0.5005,  0.6681]],\n  \n          [[-0.4504,  0.6398, -0.8169, -0.7166],\n           [-0.0248, -0.7897,  0.2809, -0.0237],\n           [ 0.4752,  0.1499,  0.5359,  0.7403]],\n  \n          [[-0.4659,  0.6828, -0.8619, -0.7523],\n           [-0.0274, -0.8494,  0.2957, -0.0533],\n           [ 0.4932,  0.1666,  0.5662,  0.8056]],\n  \n          [[-0.4802,  0.7197, -0.9021, -0.7840],\n           [-0.0275, -0.9010,  0.3096, -0.0815],\n           [ 0.5077,  0.1813,  0.5925,  0.8655]],\n  \n          [[-0.4935,  0.7520, -0.9386, -0.8127],\n           [-0.0261, -0.9467,  0.3227, -0.1086],\n           [ 0.5196,  0.1947,  0.6159,  0.9213]],\n  \n          [[-0.5060,  0.7807, -0.9720, -0.8388],\n           [-0.0236, -0.9879,  0.3352, -0.1347],\n           [ 0.5296,  0.2071,  0.6368,  0.9735]],\n  \n          [[-0.5177,  0.8067, -1.0028, -0.8629],\n           [-0.0204, -1.0255,  0.3470, -0.1599],\n           [ 0.5380,  0.2188,  0.6557,  1.0228]],\n  \n          [[-0.5287,  0.8303, -1.0314, -0.8852],\n           [-0.0166, -1.0601,  0.3584, -0.1844],\n           [ 0.5453,  0.2298,  0.6730,  1.0696]]], grad_fn=<StackBackward>),\n  tensor([[[-3.4784e-01,  2.7698e-01, -5.0003e-01, -4.3069e-01],\n           [ 4.7243e-02, -2.6405e-01,  1.4668e-01,  8.3713e-02],\n           [ 3.0059e-01, -1.2928e-02,  3.5336e-01,  3.4698e-01]],\n  \n          [[-3.8013e-01,  4.2071e-01, -6.1627e-01, -5.1825e-01],\n           [-9.9401e-03, -4.2075e-01,  1.4455e-01,  4.5956e-02],\n           [ 3.9007e-01,  3.5505e-05,  4.7172e-01,  4.7229e-01]],\n  \n          [[-4.0812e-01,  5.1558e-01, -7.0209e-01, -5.8322e-01],\n           [-4.4621e-02, -5.2324e-01,  1.4336e-01,  1.8077e-02],\n           [ 4.5274e-01,  7.6588e-03,  5.5874e-01,  5.6514e-01]],\n  \n          [[-4.3308e-01,  5.8609e-01, -7.7151e-01, -6.3588e-01],\n           [-6.8862e-02, -5.9810e-01,  1.4241e-01, -4.7655e-03],\n           [ 5.0194e-01,  1.2010e-02,  6.2911e-01,  6.4065e-01]],\n  \n          [[-4.5553e-01,  6.4237e-01, -8.3036e-01, -6.8053e-01],\n           [-8.7833e-02, -6.5726e-01,  1.4145e-01, -2.4700e-02],\n           [ 5.4337e-01,  1.4895e-02,  6.8891e-01,  7.0523e-01]],\n  \n          [[-4.7599e-01,  6.8929e-01, -8.8179e-01, -7.1952e-01],\n           [-1.0382e-01, -7.0640e-01,  1.4043e-01, -4.2729e-02],\n           [ 5.7981e-01,  1.7114e-02,  7.4136e-01,  7.6224e-01]],\n  \n          [[-4.9485e-01,  7.2958e-01, -9.2769e-01, -7.5430e-01],\n           [-1.1794e-01, -7.4858e-01,  1.3931e-01, -5.9397e-02],\n           [ 6.1279e-01,  1.8999e-02,  7.8838e-01,  8.1369e-01]],\n  \n          [[-5.1244e-01,  7.6491e-01, -9.6933e-01, -7.8583e-01],\n           [-1.3082e-01, -7.8559e-01,  1.3808e-01, -7.5032e-02],\n           [ 6.4325e-01,  2.0687e-02,  8.3125e-01,  8.6086e-01]],\n  \n          [[-5.2897e-01,  7.9639e-01, -1.0076e+00, -8.1477e-01],\n           [-1.4280e-01, -8.1862e-01,  1.3673e-01, -8.9847e-02],\n           [ 6.7178e-01,  2.2230e-02,  8.7084e-01,  9.0461e-01]],\n  \n          [[-5.4464e-01,  8.2478e-01, -1.0430e+00, -8.4160e-01],\n           [-1.5412e-01, -8.4843e-01,  1.3526e-01, -1.0399e-01],\n           [ 6.9876e-01,  2.3650e-02,  9.0777e-01,  9.4559e-01]],\n  \n          [[-5.5956e-01,  8.5065e-01, -1.0762e+00, -8.6667e-01],\n           [-1.6493e-01, -8.7561e-01,  1.3366e-01, -1.1756e-01],\n           [ 7.2449e-01,  2.4954e-02,  9.4250e-01,  9.8423e-01]]],\n         grad_fn=<StackBackward>),\n  tensor([[[-3.3572e-01,  1.7737e-01, -4.3847e-01, -3.7493e-01],\n           [ 1.0489e-01, -1.9932e-01,  1.4023e-01,  6.7837e-02],\n           [ 2.3083e-01,  2.1950e-02,  2.9824e-01,  3.0709e-01]],\n  \n          [[-3.9630e-01,  3.1854e-01, -5.7574e-01, -4.7857e-01],\n           [ 1.2475e-01, -3.3922e-01,  1.6351e-01,  3.9604e-02],\n           [ 2.7155e-01,  2.0687e-02,  4.1222e-01,  4.3897e-01]],\n  \n          [[-4.3894e-01,  4.1624e-01, -6.7141e-01, -5.4997e-01],\n           [ 1.5632e-01, -4.2824e-01,  1.7417e-01,  9.1075e-03],\n           [ 2.8263e-01,  1.1994e-02,  4.9724e-01,  5.4087e-01]],\n  \n          [[-4.7342e-01,  4.9023e-01, -7.4619e-01, -6.0549e-01],\n           [ 1.9338e-01, -4.8921e-01,  1.7827e-01, -2.1383e-02],\n           [ 2.8004e-01, -1.0255e-03,  5.6792e-01,  6.2687e-01]],\n  \n          [[-5.0269e-01,  5.4995e-01, -8.0808e-01, -6.5124e-01],\n           [ 2.3215e-01, -5.3409e-01,  1.7832e-01, -5.1309e-02],\n           [ 2.7054e-01, -1.5859e-02,  6.2976e-01,  7.0255e-01]],\n  \n          [[-5.2833e-01,  6.0020e-01, -8.6122e-01, -6.9039e-01],\n           [ 2.7075e-01, -5.6899e-01,  1.7561e-01, -8.0426e-02],\n           [ 2.5758e-01, -3.1214e-02,  6.8560e-01,  7.7081e-01]],\n  \n          [[-5.5129e-01,  6.4370e-01, -9.0802e-01, -7.2476e-01],\n           [ 3.0826e-01, -5.9722e-01,  1.7090e-01, -1.0862e-01],\n           [ 2.4304e-01, -4.6479e-02,  7.3712e-01,  8.3339e-01]],\n  \n          [[-5.7223e-01,  6.8211e-01, -9.5002e-01, -7.5556e-01],\n           [ 3.4422e-01, -6.2073e-01,  1.6464e-01, -1.3584e-01],\n           [ 2.2801e-01, -6.1379e-02,  7.8538e-01,  8.9140e-01]],\n  \n          [[-5.9157e-01,  7.1656e-01, -9.8828e-01, -7.8358e-01],\n           [ 3.7843e-01, -6.4076e-01,  1.5717e-01, -1.6206e-01],\n           [ 2.1314e-01, -7.5804e-02,  8.3111e-01,  9.4565e-01]],\n  \n          [[-6.0964e-01,  7.4783e-01, -1.0235e+00, -8.0939e-01],\n           [ 4.1083e-01, -6.5810e-01,  1.4873e-01, -1.8728e-01],\n           [ 1.9881e-01, -8.9729e-02,  8.7481e-01,  9.9667e-01]],\n  \n          [[-6.2667e-01,  7.7648e-01, -1.0563e+00, -8.3340e-01],\n           [ 4.4144e-01, -6.7332e-01,  1.3952e-01, -2.1150e-01],\n           [ 1.8522e-01, -1.0317e-01,  9.1683e-01,  1.0449e+00]]],\n         grad_fn=<StackBackward>)],\n [tensor([[ 0.0303,  0.0303, -0.0606],\n          [-0.0080,  0.1123, -0.1044],\n          [-0.0369,  0.1749, -0.1380],\n          [-0.0600,  0.2263, -0.1663],\n          [-0.0793,  0.2708, -0.1915],\n          [-0.0961,  0.3107, -0.2147],\n          [-0.1108,  0.3475, -0.2366],\n          [-0.1241,  0.3817, -0.2577],\n          [-0.1361,  0.4141, -0.2780],\n          [-0.1470,  0.4449, -0.2979],\n          [-0.1571,  0.4745, -0.3173]], grad_fn=<StackBackward>),\n  tensor([[ 0.1212,  0.0303, -0.1515],\n          [ 0.0707,  0.1133, -0.1840],\n          [ 0.0346,  0.1707, -0.2053],\n          [ 0.0065,  0.2157, -0.2222],\n          [-0.0167,  0.2542, -0.2375],\n          [-0.0367,  0.2888, -0.2521],\n          [-0.0542,  0.3208, -0.2665],\n          [-0.0699,  0.3510, -0.2810],\n          [-0.0841,  0.3798, -0.2957],\n          [-0.0971,  0.4076, -0.3105],\n          [-0.1090,  0.4345, -0.3255]], grad_fn=<StackBackward>),\n  tensor([[ 0.2121, -0.0606, -0.1515],\n          [ 0.1612, -0.0107, -0.1505],\n          [ 0.1319,  0.0141, -0.1460],\n          [ 0.1115,  0.0287, -0.1403],\n          [ 0.0957,  0.0391, -0.1347],\n          [ 0.0825,  0.0474, -0.1299],\n          [ 0.0711,  0.0547, -0.1258],\n          [ 0.0611,  0.0615, -0.1225],\n          [ 0.0520,  0.0681, -0.1200],\n          [ 0.0437,  0.0745, -0.1182],\n          [ 0.0360,  0.0810, -0.1170]], grad_fn=<StackBackward>),\n  tensor([[ 0.1212, -0.0606, -0.0606],\n          [ 0.0780, -0.0445, -0.0335],\n          [ 0.0513, -0.0394, -0.0119],\n          [ 0.0324, -0.0375,  0.0051],\n          [ 0.0178, -0.0358,  0.0180],\n          [ 0.0061, -0.0335,  0.0275],\n          [-0.0038, -0.0304,  0.0342],\n          [-0.0123, -0.0264,  0.0387],\n          [-0.0197, -0.0217,  0.0414],\n          [-0.0262, -0.0165,  0.0426],\n          [-0.0319, -0.0107,  0.0426]], grad_fn=<StackBackward>),\n  tensor([[ 0.0303,  0.0303, -0.0606],\n          [-0.0251,  0.0930, -0.0679],\n          [-0.0644,  0.1420, -0.0775],\n          [-0.0945,  0.1842, -0.0897],\n          [-0.1190,  0.2231, -0.1041],\n          [-0.1396,  0.2602, -0.1206],\n          [-0.1575,  0.2960, -0.1385],\n          [-0.1731,  0.3306, -0.1575],\n          [-0.1869,  0.3643, -0.1773],\n          [-0.1993,  0.3969, -0.1976],\n          [-0.2103,  0.4286, -0.2183]], grad_fn=<StackBackward>)])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lppl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.5903,  0.7133, -0.9852, -0.7813],\n        [ 0.3766, -0.6380,  0.1562, -0.1611],\n        [ 0.2136, -0.0753,  0.8291,  0.9424]], requires_grad=True)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lppl[0].fc1.weight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5427, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5180, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4922, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4534, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4337, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4220, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4114, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3932, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3852, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3779, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3710, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3646, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3586, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "[tensor(0.5427, grad_fn=<NllLossBackward>),\n tensor(0.5180, grad_fn=<NllLossBackward>),\n tensor(0.4922, grad_fn=<NllLossBackward>),\n tensor(0.4711, grad_fn=<NllLossBackward>),\n tensor(0.4534, grad_fn=<NllLossBackward>),\n tensor(0.4471, grad_fn=<NllLossBackward>),\n tensor(0.4337, grad_fn=<NllLossBackward>),\n tensor(0.4220, grad_fn=<NllLossBackward>),\n tensor(0.4114, grad_fn=<NllLossBackward>),\n tensor(0.4019, grad_fn=<NllLossBackward>),\n tensor(0.3932, grad_fn=<NllLossBackward>),\n tensor(0.3852, grad_fn=<NllLossBackward>),\n tensor(0.3779, grad_fn=<NllLossBackward>),\n tensor(0.3710, grad_fn=<NllLossBackward>),\n tensor(0.3646, grad_fn=<NllLossBackward>),\n tensor(0.3586, grad_fn=<NllLossBackward>)]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoge.transition(k=3,train_x=data_train,train_y=label_train,transition_x=data_test,transition_y=label_test,model=model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}