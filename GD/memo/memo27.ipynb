{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ML2_lib import format_data\n",
    "from ML2_lib import RV_SGD_Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:62: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = format_data.MNIST_data().return_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "hoge = RV_SGD_Torch.RVSGDByTorch(lr = 0.001)\n",
    "model_list = hoge.learn(k=5, x=X_train, y=y_train,model_type=\"FF_L1\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[FF_L1(\n   (fc1): Linear(in_features=784, out_features=512, bias=True)\n   (fc2): Linear(in_features=512, out_features=10, bias=True)\n   (relu): ReLU()\n ),\n FF_L1(\n   (fc1): Linear(in_features=784, out_features=512, bias=True)\n   (fc2): Linear(in_features=512, out_features=10, bias=True)\n   (relu): ReLU()\n ),\n FF_L1(\n   (fc1): Linear(in_features=784, out_features=512, bias=True)\n   (fc2): Linear(in_features=512, out_features=10, bias=True)\n   (relu): ReLU()\n ),\n FF_L1(\n   (fc1): Linear(in_features=784, out_features=512, bias=True)\n   (fc2): Linear(in_features=512, out_features=10, bias=True)\n   (relu): ReLU()\n ),\n FF_L1(\n   (fc1): Linear(in_features=784, out_features=512, bias=True)\n   (fc2): Linear(in_features=512, out_features=10, bias=True)\n   (relu): ReLU()\n )]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108.44144439697266, 109.7315902709961, 84.83683776855469, 74.83685302734375, 68.34386444091797]\n",
      "[96.45659637451172, 99.00220489501953, 69.05790710449219, 53.41676330566406, 47.37433624267578]\n",
      "[94.83191680908203, 109.91207885742188, 84.6991958618164, 66.40987396240234, 62.43042755126953]\n",
      "[104.50121307373047, 101.82775115966797, 74.17781829833984, 59.13737106323242, 63.975929260253906]\n",
      "[108.04930877685547, 108.9394302368164, 82.36002349853516, 47.3016242980957, 49.361297607421875]\n",
      "[108.44144439697266, 96.45659637451172, 94.83191680908203, 101.82775115966797, 108.04930877685547]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "selected = hoge.valid(model_candidates=model_list,k=5,valid_x=X_test,valid_y=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 936    0    1    2    2   17   13    3    4    2]\n",
      " [   0 1045   26   31    0    5    2    0   23    3]\n",
      " [  33    9  867   17   14    7   25   13   40    7]\n",
      " [  19    5   33  824    5   56    4    3   37   24]\n",
      " [   5    4   11    2  831    1   30    2   10   86]\n",
      " [  40    1    5   46   16  701   17    6   51    9]\n",
      " [  22    1    5    2   21   13  887    1    6    0]\n",
      " [   8    9   45   30   14    5    3  801   19   94]\n",
      " [  32    7   24   35   17   23   16    2  782   36]\n",
      " [  22    3    4   14  108    6    2   15   24  811]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       980\n",
      "           1       0.96      0.92      0.94      1135\n",
      "           2       0.85      0.84      0.84      1032\n",
      "           3       0.82      0.82      0.82      1010\n",
      "           4       0.81      0.85      0.83       982\n",
      "           5       0.84      0.79      0.81       892\n",
      "           6       0.89      0.93      0.91       958\n",
      "           7       0.95      0.78      0.85      1028\n",
      "           8       0.79      0.80      0.79       974\n",
      "           9       0.76      0.80      0.78      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "正解率 : 0.8485\n",
      "test loss : 89.23812103271484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/RV_SGD_Torch.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(x).float())\n",
      "/Users/naoki/ML2/GD/ML2_lib/RV_SGD_Torch.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(x).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 856    0    5    2    2   63   42    1    6    3]\n",
      " [   0 1096    2   10    2    7    2    1   14    1]\n",
      " [  11   24  831   30   25   16   25   13   50    7]\n",
      " [   6    2   20  815    0   89    7   11   42   18]\n",
      " [   1    4   11    0  814   13   29    2   35   73]\n",
      " [  10    4    5   26    8  788   15    3   24    9]\n",
      " [   4    5    4    5   15   29  883    1   11    1]\n",
      " [   3   15   34    9   10   12    1  825   12  107]\n",
      " [   3   12    2   24    9   82   13    6  799   24]\n",
      " [   7    5    2    4   41   30    5   12   30  873]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91       980\n",
      "           1       0.94      0.97      0.95      1135\n",
      "           2       0.91      0.81      0.85      1032\n",
      "           3       0.88      0.81      0.84      1010\n",
      "           4       0.88      0.83      0.85       982\n",
      "           5       0.70      0.88      0.78       892\n",
      "           6       0.86      0.92      0.89       958\n",
      "           7       0.94      0.80      0.87      1028\n",
      "           8       0.78      0.82      0.80       974\n",
      "           9       0.78      0.87      0.82      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "正解率 : 0.858\n",
      "test loss : 73.06155395507812\n",
      "[[ 933    0    9    4    2    4   18    2    7    1]\n",
      " [   0 1005   11   18    3    2   11    2   82    1]\n",
      " [  10    8  856   30   19    1   33   16   55    4]\n",
      " [  13    1   36  862    2    4    4   14   64   10]\n",
      " [   1    0    3    5  842    1   35    4   32   59]\n",
      " [  31    1   19   77   16  554   44   16  120   14]\n",
      " [  15    2   22    1   26    7  876    0    8    1]\n",
      " [   4    8   19   19   16    2    1  892   26   41]\n",
      " [  13    3   15   25    7    8   23    8  866    6]\n",
      " [  10    3    1   17   55    3    5   36   28  851]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       980\n",
      "           1       0.97      0.89      0.93      1135\n",
      "           2       0.86      0.83      0.85      1032\n",
      "           3       0.81      0.85      0.83      1010\n",
      "           4       0.85      0.86      0.85       982\n",
      "           5       0.95      0.62      0.75       892\n",
      "           6       0.83      0.91      0.87       958\n",
      "           7       0.90      0.87      0.88      1028\n",
      "           8       0.67      0.89      0.77       974\n",
      "           9       0.86      0.84      0.85      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "正解率 : 0.8537\n",
      "test loss : 83.65670013427734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/RV_SGD_Torch.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(x).float())\n",
      "/Users/naoki/ML2/GD/ML2_lib/RV_SGD_Torch.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(x).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 833    0    6    8    1  101    8    2   15    6]\n",
      " [   0 1035    3   14    0   15    4    1   62    1]\n",
      " [  11    8  840   31   11   19   18   11   72   11]\n",
      " [   5    2   21  801    0  102    4    7   52   16]\n",
      " [   3    4    7    6  778   15   13    4   55   97]\n",
      " [   4    0    7   24    2  805    9    1   35    5]\n",
      " [  10    4   24    0   14   56  811    3   31    5]\n",
      " [   1    9   38   21    9   15    0  814   23   98]\n",
      " [   2    5   12   18    7   43    6    5  869    7]\n",
      " [   1    6   12   13   26   33    2   14   45  857]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       980\n",
      "           1       0.96      0.91      0.94      1135\n",
      "           2       0.87      0.81      0.84      1032\n",
      "           3       0.86      0.79      0.82      1010\n",
      "           4       0.92      0.79      0.85       982\n",
      "           5       0.67      0.90      0.77       892\n",
      "           6       0.93      0.85      0.88       958\n",
      "           7       0.94      0.79      0.86      1028\n",
      "           8       0.69      0.89      0.78       974\n",
      "           9       0.78      0.85      0.81      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.86      0.84      0.85     10000\n",
      "weighted avg       0.86      0.84      0.85     10000\n",
      "\n",
      "正解率 : 0.8443\n",
      "test loss : 80.72401428222656\n",
      "[[ 943    0    2    4    2   15    4    1    5    4]\n",
      " [   0 1098    5   11    3    2    3    2   10    1]\n",
      " [  16   21  808   78   17   12   14   22   36    8]\n",
      " [  11    5   13  899    1   42    1   12    5   21]\n",
      " [   3    3    5    7  832    3    9    6   11  103]\n",
      " [  31    7    4   73   13  641    7   17   70   29]\n",
      " [  21    7    8    2   12   41  849    0   15    3]\n",
      " [   2   15   28    8   14    1    2  877    9   72]\n",
      " [   5   18   11   86   11   17   12    8  745   61]\n",
      " [   9    5    4   20   36    7    1   32   10  885]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       980\n",
      "           1       0.93      0.97      0.95      1135\n",
      "           2       0.91      0.78      0.84      1032\n",
      "           3       0.76      0.89      0.82      1010\n",
      "           4       0.88      0.85      0.87       982\n",
      "           5       0.82      0.72      0.77       892\n",
      "           6       0.94      0.89      0.91       958\n",
      "           7       0.90      0.85      0.87      1028\n",
      "           8       0.81      0.76      0.79       974\n",
      "           9       0.75      0.88      0.81      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.85      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "正解率 : 0.8577\n",
      "test loss : 79.20234680175781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/RV_SGD_Torch.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(x).float())\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    hoge.prediction(x=X_test,y=y_test,model=model_list[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/RV_SGD_Torch.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(x).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 933    0    9    4    2    4   18    2    7    1]\n",
      " [   0 1005   11   18    3    2   11    2   82    1]\n",
      " [  10    8  856   30   19    1   33   16   55    4]\n",
      " [  13    1   36  862    2    4    4   14   64   10]\n",
      " [   1    0    3    5  842    1   35    4   32   59]\n",
      " [  31    1   19   77   16  554   44   16  120   14]\n",
      " [  15    2   22    1   26    7  876    0    8    1]\n",
      " [   4    8   19   19   16    2    1  892   26   41]\n",
      " [  13    3   15   25    7    8   23    8  866    6]\n",
      " [  10    3    1   17   55    3    5   36   28  851]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       980\n",
      "           1       0.97      0.89      0.93      1135\n",
      "           2       0.86      0.83      0.85      1032\n",
      "           3       0.81      0.85      0.83      1010\n",
      "           4       0.85      0.86      0.85       982\n",
      "           5       0.95      0.62      0.75       892\n",
      "           6       0.83      0.91      0.87       958\n",
      "           7       0.90      0.87      0.88      1028\n",
      "           8       0.67      0.89      0.77       974\n",
      "           9       0.86      0.84      0.85      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "正解率 : 0.8537\n",
      "test loss : 83.65670013427734\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor(83.6567), 0.8537)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hoge.prediction(x=X_test,y=y_test,model=selected)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}