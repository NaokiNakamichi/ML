{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ML2_lib import format_data\n",
    "from ML2_lib import RV_SGD_Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:62: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = format_data.MNIST_data().return_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "hoge = RV_SGD_Torch.RVSGDByTorch(lr = 0.1)\n",
    "model_list = hoge.learn(k=5, x=X_train, y=y_train,model_type=\"linear\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[LinearClassification(\n   (fc1): Linear(in_features=784, out_features=10, bias=True)\n ),\n LinearClassification(\n   (fc1): Linear(in_features=784, out_features=10, bias=True)\n ),\n LinearClassification(\n   (fc1): Linear(in_features=784, out_features=10, bias=True)\n ),\n LinearClassification(\n   (fc1): Linear(in_features=784, out_features=10, bias=True)\n ),\n LinearClassification(\n   (fc1): Linear(in_features=784, out_features=10, bias=True)\n )]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9654154777526855, 3.0850141048431396, 2.418632984161377, 1.8567800521850586, 1.8651409149169922]\n",
      "[2.363844871520996, 2.6188619136810303, 1.880303978919983, 1.7127183675765991, 1.5447534322738647]\n",
      "[2.071988582611084, 2.1247150897979736, 1.7371656894683838, 1.4733234643936157, 1.1853609085083008]\n",
      "[2.9915289878845215, 3.1473681926727295, 2.390923023223877, 1.7740559577941895, 1.7085728645324707]\n",
      "[3.2043232917785645, 3.1549365520477295, 2.5720629692077637, 1.613629937171936, 1.6277743577957153]\n",
      "[2.9654154777526855, 2.363844871520996, 2.071988582611084, 2.9915289878845215, 3.1549365520477295]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "selected = hoge.valid(model_candidates=model_list,k=5,valid_x=X_test,valid_y=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[923   0   0   6   1  25  10   1  13   1]\n",
      " [  0 961   3  80   0  11   2   0  69   9]\n",
      " [ 31   6 725 129  11   5  18   9  77  21]\n",
      " [ 14   0   5 885   2  52   2   3  24  23]\n",
      " [  5   0   4   3 789   1   9   4  38 129]\n",
      " [ 20   1   5  57   7 667  17   3  92  23]\n",
      " [ 27   4  10   3  18  23 840   2  24   7]\n",
      " [  3   6  15  50   6   2   0 773  31 142]\n",
      " [ 11   2  11  76   8  20   8   1 791  46]\n",
      " [ 10   1   2  17  36   9   0  12  40 882]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       980\n",
      "           1       0.98      0.85      0.91      1135\n",
      "           2       0.93      0.70      0.80      1032\n",
      "           3       0.68      0.88      0.76      1010\n",
      "           4       0.90      0.80      0.85       982\n",
      "           5       0.82      0.75      0.78       892\n",
      "           6       0.93      0.88      0.90       958\n",
      "           7       0.96      0.75      0.84      1028\n",
      "           8       0.66      0.81      0.73       974\n",
      "           9       0.69      0.87      0.77      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.84      0.82      0.83     10000\n",
      "weighted avg       0.84      0.82      0.83     10000\n",
      "\n",
      "正解率 : 0.8236\n",
      "test loss : 2.4381964206695557\n",
      "[[ 912    0   10    6    0   30   15    3    4    0]\n",
      " [   0 1108    8    9    1    4    3    0    2    0]\n",
      " [  12    7  870   67   13   11   19   11   19    3]\n",
      " [   7    2   22  873    1   75    3   12   11    4]\n",
      " [   1    7   17    1  897    7   20    1   12   19]\n",
      " [  10    8   15   44   16  731   33    3   28    4]\n",
      " [  10    5   11    5    7   20  896    1    3    0]\n",
      " [   3   17   45   19   14   11    3  899    1   16]\n",
      " [   6   26   48   56    9  130   34   16  647    2]\n",
      " [   6    9    7   12  112   76    6   91   29  661]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       980\n",
      "           1       0.93      0.98      0.95      1135\n",
      "           2       0.83      0.84      0.83      1032\n",
      "           3       0.80      0.86      0.83      1010\n",
      "           4       0.84      0.91      0.87       982\n",
      "           5       0.67      0.82      0.74       892\n",
      "           6       0.87      0.94      0.90       958\n",
      "           7       0.87      0.87      0.87      1028\n",
      "           8       0.86      0.66      0.75       974\n",
      "           9       0.93      0.66      0.77      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "正解率 : 0.8494\n",
      "test loss : 2.0240964889526367\n",
      "[[ 942    0    5    5    1    3   16    2    6    0]\n",
      " [   0 1080    8    9    1    1    4    1   30    1]\n",
      " [   8    1  892   25   15    2   41    5   30   13]\n",
      " [   5    0   22  900    4   20    9   10   31    9]\n",
      " [   1    2    8    2  841    1   29    1   18   79]\n",
      " [  22   10   14   59   13  629   42    8   84   11]\n",
      " [  12    1    7    2   18    4  906    0    8    0]\n",
      " [   5   11   31   18   13    1    0  874   10   65]\n",
      " [  10   16   15   35   10   19   22    5  830   12]\n",
      " [  13    3    9   16   48    8    3   11   37  861]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       980\n",
      "           1       0.96      0.95      0.96      1135\n",
      "           2       0.88      0.86      0.87      1032\n",
      "           3       0.84      0.89      0.86      1010\n",
      "           4       0.87      0.86      0.86       982\n",
      "           5       0.91      0.71      0.80       892\n",
      "           6       0.85      0.95      0.89       958\n",
      "           7       0.95      0.85      0.90      1028\n",
      "           8       0.77      0.85      0.81       974\n",
      "           9       0.82      0.85      0.84      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.87      0.87     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "正解率 : 0.8755\n",
      "test loss : 1.7185105085372925\n",
      "[[ 798    0   14   47    0   98   18    0    5    0]\n",
      " [   0 1052   25   15    0    8    1    2   28    4]\n",
      " [   6    5  866   67    4   21   15    7   36    5]\n",
      " [   0    0   21  928    0   44    0    4   12    1]\n",
      " [   1    1   18   16  802   47   12    5   20   60]\n",
      " [   5    1    7  107    3  736    4    3   23    3]\n",
      " [   4    3   22   15   11   64  824    1   13    1]\n",
      " [   4    7   41   86    6   17    0  787   10   70]\n",
      " [   2    5   20  124    8  140    9    4  655    7]\n",
      " [   6    4   22   58   51   53    2   25   20  768]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88       980\n",
      "           1       0.98      0.93      0.95      1135\n",
      "           2       0.82      0.84      0.83      1032\n",
      "           3       0.63      0.92      0.75      1010\n",
      "           4       0.91      0.82      0.86       982\n",
      "           5       0.60      0.83      0.69       892\n",
      "           6       0.93      0.86      0.89       958\n",
      "           7       0.94      0.77      0.84      1028\n",
      "           8       0.80      0.67      0.73       974\n",
      "           9       0.84      0.76      0.80      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.84      0.82      0.82     10000\n",
      "weighted avg       0.84      0.82      0.83     10000\n",
      "\n",
      "正解率 : 0.8216\n",
      "test loss : 2.4024899005889893\n",
      "[[ 965    1    1    1    1    7    3    1    0    0]\n",
      " [   0 1095    0   23    1    1    4    0    9    2]\n",
      " [  39   33  723  144   14   12   15   10   31   11]\n",
      " [   4    2    9  922    4   44    5    6    4   10]\n",
      " [   9    3    2    3  795    5   28    1   13  123]\n",
      " [  27    7    1   77   29  674   16    5   39   17]\n",
      " [  35    5    6    0   14   36  852    3    5    2]\n",
      " [   7    9   25   34   14    5    1  806    4  123]\n",
      " [  25   29    7  141   18   82   11    9  604   48]\n",
      " [  19    6    0   25   43    5    5   13    3  890]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91       980\n",
      "           1       0.92      0.96      0.94      1135\n",
      "           2       0.93      0.70      0.80      1032\n",
      "           3       0.67      0.91      0.77      1010\n",
      "           4       0.85      0.81      0.83       982\n",
      "           5       0.77      0.76      0.76       892\n",
      "           6       0.91      0.89      0.90       958\n",
      "           7       0.94      0.78      0.86      1028\n",
      "           8       0.85      0.62      0.72       974\n",
      "           9       0.73      0.88      0.80      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n",
      "正解率 : 0.8326\n",
      "test loss : 2.4345455169677734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/RV_SGD_Torch.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(x).float())\n",
      "/Users/naoki/ML2/GD/ML2_lib/RV_SGD_Torch.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(x).float())\n",
      "/Users/naoki/ML2/GD/ML2_lib/RV_SGD_Torch.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(x).float())\n",
      "/Users/naoki/ML2/GD/ML2_lib/RV_SGD_Torch.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(x).float())\n",
      "/Users/naoki/ML2/GD/ML2_lib/RV_SGD_Torch.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(x).float())\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    hoge.prediction(x=X_test,y=y_test,model=model_list[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/RV_SGD_Torch.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = model(torch.tensor(x).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 942    0    5    5    1    3   16    2    6    0]\n",
      " [   0 1080    8    9    1    1    4    1   30    1]\n",
      " [   8    1  892   25   15    2   41    5   30   13]\n",
      " [   5    0   22  900    4   20    9   10   31    9]\n",
      " [   1    2    8    2  841    1   29    1   18   79]\n",
      " [  22   10   14   59   13  629   42    8   84   11]\n",
      " [  12    1    7    2   18    4  906    0    8    0]\n",
      " [   5   11   31   18   13    1    0  874   10   65]\n",
      " [  10   16   15   35   10   19   22    5  830   12]\n",
      " [  13    3    9   16   48    8    3   11   37  861]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       980\n",
      "           1       0.96      0.95      0.96      1135\n",
      "           2       0.88      0.86      0.87      1032\n",
      "           3       0.84      0.89      0.86      1010\n",
      "           4       0.87      0.86      0.86       982\n",
      "           5       0.91      0.71      0.80       892\n",
      "           6       0.85      0.95      0.89       958\n",
      "           7       0.95      0.85      0.90      1028\n",
      "           8       0.77      0.85      0.81       974\n",
      "           9       0.82      0.85      0.84      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.87      0.87     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "正解率 : 0.8755\n",
      "test loss : 1.7185105085372925\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor(1.7185), 0.8755)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hoge.prediction(x=X_test,y=y_test,model=selected)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from ML2_lib import valid\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "2.0"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.median_of_means(np.array([1,2,3,4,5]),n_blocks=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}