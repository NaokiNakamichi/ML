{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import optuna\n",
    "\n",
    "mnist_data = MNIST('data/MNIST',download=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:62: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]],\n\n        [[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]],\n\n        [[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]],\n\n        ...,\n\n        [[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]],\n\n        [[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]],\n\n        [[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mnist_data.train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([5, 0, 4,  ..., 5, 6, 8])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mnist_data.train_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ML2_lib import models\n",
    "from ML2_lib import SGDByTorch\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from ML2_lib import format_data\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = mnist_data.train_data.reshape(-1,784)\n",
    "X_test = mnist_data.test_data.reshape(-1,784)\n",
    "y_train = mnist_data.train_labels\n",
    "y_test = mnist_data.test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "w_dim = X_train.shape[1]\n",
    "class_num = int(max(y_train) + 1)\n",
    "unit_num = 3\n",
    "model = models.LinearClassification(w_num=w_dim,c_num=class_num)\n",
    "model.parameter_init()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "hoge = SGDByTorch.SGDTorchCheck(lr=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).float()\n",
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0\n",
      "OrderedDict([('fc1.weight', tensor([[ 2.4402,  2.8421, -2.9758,  ...,  3.6914,  3.9722,  2.1049],\n",
      "        [ 4.1362,  3.3909,  1.5667,  ..., -2.3789,  3.1523,  4.7185],\n",
      "        [-3.8923,  4.3601,  0.0909,  ...,  4.8018,  3.7035,  1.4217],\n",
      "        ...,\n",
      "        [ 2.0312,  2.4968,  4.1081,  ..., -3.1753,  2.0090,  1.1899],\n",
      "        [ 3.4057,  3.9673, -2.6706,  ..., -2.2297, -2.5674, -2.8378],\n",
      "        [ 3.1741,  1.0887,  4.0196,  ..., -1.3685, -3.8843,  4.2623]])), ('fc1.bias', tensor([-0.1000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000]))])\n",
      "[[  49  113  116 1944 2705  244  177  539    2   34]\n",
      " [1033  150  333   80   30 3942  519  577    2   76]\n",
      " [ 668 1268  353 1399  367  639  657  395   35  177]\n",
      " [ 173  225 1074 1301  279  597 2091  229    7  155]\n",
      " [ 278   73   11 1726  924  195 1192  533   17  893]\n",
      " [ 302  202  419 1116  392  808 1883  238    1   60]\n",
      " [ 828  858  171  671  682  369  288 1075    4  972]\n",
      " [ 370   49  324 2368  181  987  314 1055   48  569]\n",
      " [ 325   58  195 1502  139  483 2567  493   22   67]\n",
      " [ 351   36   54 1987  484  956  730  795    9  547]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.01      0.01      5923\n",
      "           1       0.05      0.02      0.03      6742\n",
      "           2       0.12      0.06      0.08      5958\n",
      "           3       0.09      0.21      0.13      6131\n",
      "           4       0.15      0.16      0.15      5842\n",
      "           5       0.09      0.15      0.11      5421\n",
      "           6       0.03      0.05      0.04      5918\n",
      "           7       0.18      0.17      0.17      6265\n",
      "           8       0.15      0.00      0.01      5851\n",
      "           9       0.15      0.09      0.12      5949\n",
      "\n",
      "    accuracy                           0.09     60000\n",
      "   macro avg       0.10      0.09      0.08     60000\n",
      "weighted avg       0.10      0.09      0.08     60000\n",
      "\n",
      "正解率 : 0.09161666666666667\n",
      "test loss : 8358.603515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 1000\n",
      "OrderedDict([('fc1.weight', tensor([[ 2.4402,  2.8421, -2.9758,  ...,  3.6914,  3.9722,  2.1049],\n",
      "        [ 4.1362,  3.3909,  1.5667,  ..., -2.3789,  3.1523,  4.7185],\n",
      "        [-3.8923,  4.3601,  0.0909,  ...,  4.8018,  3.7035,  1.4217],\n",
      "        ...,\n",
      "        [ 2.0312,  2.4968,  4.1081,  ..., -3.1753,  2.0090,  1.1899],\n",
      "        [ 3.4057,  3.9673, -2.6706,  ..., -2.2297, -2.5674, -2.8378],\n",
      "        [ 3.1741,  1.0887,  4.0196,  ..., -1.3685, -3.8843,  4.2623]])), ('fc1.bias', tensor([-0.7000,  0.9000, -0.2000, -0.4000,  0.7000, -0.1000, -0.4000,  0.8000,\n",
      "        -0.4000, -0.3000]))])\n",
      "[[4086    2   42  926   76  188  294  174   22  113]\n",
      " [   3 5863   53  245    8   44  112  234   79  101]\n",
      " [ 101  392 2649 1352  149   23  556  429  177  130]\n",
      " [  45   80   65 5384   16  129   40  240   36   96]\n",
      " [  12   32   17  210 3925   18  298  218   35 1077]\n",
      " [ 204  195   22 2320  238 1333  381  230  133  365]\n",
      " [ 117  153  104  138  166   75 4878  128   17  142]\n",
      " [  45   58   16  157  131   30   29 5374   27  398]\n",
      " [  50  262   17 1905  124  146  364  432 1809  742]\n",
      " [  30   26   33  362  678   77   79 1538   16 3110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77      5923\n",
      "           1       0.83      0.87      0.85      6742\n",
      "           2       0.88      0.44      0.59      5958\n",
      "           3       0.41      0.88      0.56      6131\n",
      "           4       0.71      0.67      0.69      5842\n",
      "           5       0.65      0.25      0.36      5421\n",
      "           6       0.69      0.82      0.75      5918\n",
      "           7       0.60      0.86      0.70      6265\n",
      "           8       0.77      0.31      0.44      5851\n",
      "           9       0.50      0.52      0.51      5949\n",
      "\n",
      "    accuracy                           0.64     60000\n",
      "   macro avg       0.69      0.63      0.62     60000\n",
      "weighted avg       0.69      0.64      0.63     60000\n",
      "\n",
      "正解率 : 0.6401833333333333\n",
      "test loss : 1893.354248046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 2000\n",
      "OrderedDict([('fc1.weight', tensor([[ 2.4402,  2.8421, -2.9758,  ...,  3.6914,  3.9722,  2.1049],\n",
      "        [ 4.1362,  3.3909,  1.5667,  ..., -2.3789,  3.1523,  4.7185],\n",
      "        [-3.8923,  4.3601,  0.0909,  ...,  4.8018,  3.7035,  1.4217],\n",
      "        ...,\n",
      "        [ 2.0312,  2.4968,  4.1081,  ..., -3.1753,  2.0090,  1.1899],\n",
      "        [ 3.4057,  3.9673, -2.6706,  ..., -2.2297, -2.5674, -2.8378],\n",
      "        [ 3.1741,  1.0887,  4.0196,  ..., -1.3685, -3.8843,  4.2623]])), ('fc1.bias', tensor([-0.7000,  0.8924,  0.3000, -1.0001,  1.1021,  0.5000, -0.6000,  0.7000,\n",
      "        -0.6860, -0.7000]))])\n",
      "[[5371    0   44   85   29  185   58   15  114   22]\n",
      " [   5 5506  298  176    8  400   44   15  224   66]\n",
      " [  83   54 4937  209   88   63  104  102  280   38]\n",
      " [ 117   64  224 4237   26  990   27  183  182   81]\n",
      " [  28   27  111   17 4530  158   60   76  315  520]\n",
      " [ 244   51   68  392  137 3896  190   37  302  104]\n",
      " [ 182   45  355   24  147  342 4704   10   73   36]\n",
      " [  76   80  148   63  121   89    8 4953  130  597]\n",
      " [  58  137  187  309   97  988  117   66 3600  292]\n",
      " [  71   32  128   93  763  498    8  625  355 3376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88      5923\n",
      "           1       0.92      0.82      0.86      6742\n",
      "           2       0.76      0.83      0.79      5958\n",
      "           3       0.76      0.69      0.72      6131\n",
      "           4       0.76      0.78      0.77      5842\n",
      "           5       0.51      0.72      0.60      5421\n",
      "           6       0.88      0.79      0.84      5918\n",
      "           7       0.81      0.79      0.80      6265\n",
      "           8       0.65      0.62      0.63      5851\n",
      "           9       0.66      0.57      0.61      5949\n",
      "\n",
      "    accuracy                           0.75     60000\n",
      "   macro avg       0.76      0.75      0.75     60000\n",
      "weighted avg       0.76      0.75      0.75     60000\n",
      "\n",
      "正解率 : 0.7518333333333334\n",
      "test loss : 1041.2451171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 3000\n",
      "OrderedDict([('fc1.weight', tensor([[ 2.4402,  2.8421, -2.9758,  ...,  3.6914,  3.9722,  2.1049],\n",
      "        [ 4.1362,  3.3909,  1.5667,  ..., -2.3789,  3.1523,  4.7185],\n",
      "        [-3.8923,  4.3601,  0.0909,  ...,  4.8018,  3.7035,  1.4217],\n",
      "        ...,\n",
      "        [ 2.0312,  2.4968,  4.1081,  ..., -3.1753,  2.0090,  1.1899],\n",
      "        [ 3.4057,  3.9673, -2.6706,  ..., -2.2297, -2.5674, -2.8378],\n",
      "        [ 3.1741,  1.0887,  4.0196,  ..., -1.3685, -3.8843,  4.2623]])), ('fc1.bias', tensor([-1.1000,  1.0924,  0.3000, -1.1002,  1.3021,  0.6000, -0.6000,  0.8000,\n",
      "        -0.9860, -0.5000]))])\n",
      "[[4041    1  250  153   90  170   59   14  938  207]\n",
      " [   1 5745  171  152   11   20   29    4  541   68]\n",
      " [  18   62 4964  152  107    6   65   48  461   75]\n",
      " [  23   63  282 4724   35  133   25   53  615  178]\n",
      " [   3   17   97   25 4654    6   31   20  199  790]\n",
      " [  57   56  104  605  262 2324  152   18 1456  387]\n",
      " [  66   58  390   27  270  136 4619    3  257   92]\n",
      " [  18   71  155  136  193   19   11 3376  129 2157]\n",
      " [   2   88  115  227   83   48   43    3 4860  382]\n",
      " [  12   17   81  114  669   26    5   98  227 4700]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.68      0.80      5923\n",
      "           1       0.93      0.85      0.89      6742\n",
      "           2       0.75      0.83      0.79      5958\n",
      "           3       0.75      0.77      0.76      6131\n",
      "           4       0.73      0.80      0.76      5842\n",
      "           5       0.80      0.43      0.56      5421\n",
      "           6       0.92      0.78      0.84      5918\n",
      "           7       0.93      0.54      0.68      6265\n",
      "           8       0.50      0.83      0.63      5851\n",
      "           9       0.52      0.79      0.63      5949\n",
      "\n",
      "    accuracy                           0.73     60000\n",
      "   macro avg       0.78      0.73      0.73     60000\n",
      "weighted avg       0.78      0.73      0.74     60000\n",
      "\n",
      "正解率 : 0.73345\n",
      "test loss : 1166.0814208984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-16-db54668dc0fc>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0msgd_model\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_stack\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_loss_stack\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0maccuracy_stack\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhoge\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlearn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mclass_num\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mclass_num\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mY_test\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ML2/GD/ML2_lib/SGDByTorch.py\u001B[0m in \u001B[0;36mlearn\u001B[0;34m(self, x, y, model, class_num, X_test, Y_test)\u001B[0m\n\u001B[1;32m    144\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 146\u001B[0;31m                     \u001B[0my_test_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    147\u001B[0m                     \u001B[0mtestloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnll_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m                     \u001B[0mprediction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my_test_pred\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "sgd_model, loss_stack, test_loss_stack,accuracy_stack = hoge.learn(x=X_train, y=y_train, model=model,class_num=class_num,X_test=X_test,Y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10.0, 8.0))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.set_title(\"train data NLL Loss\")\n",
    "\n",
    "ax1.plot(loss_stack)\n",
    "ax1.set_xlabel(\"step\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10.0, 8.0))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_title(\"test data NLL Loss\")\n",
    "\n",
    "ax1.plot(test_loss_stack)\n",
    "ax1.set_xlabel(\"step\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10.0, 8.0))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_title(\"test data accuracy\")\n",
    "\n",
    "ax1.plot(accuracy_stack)\n",
    "ax1.set_xlabel(\"step\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "accuracy_stack\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}