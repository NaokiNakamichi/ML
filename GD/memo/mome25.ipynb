{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import optuna\n",
    "\n",
    "mnist_data = MNIST('data/MNIST',download=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:62: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]],\n\n        [[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]],\n\n        [[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]],\n\n        ...,\n\n        [[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]],\n\n        [[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]],\n\n        [[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mnist_data.train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([5, 0, 4,  ..., 5, 6, 8])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mnist_data.train_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ML2_lib import models\n",
    "from ML2_lib import SGDByTorch\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from ML2_lib import format_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "name_path = \"data/adult/adult_classification.names\"\n",
    "train_path = \"data/adult/adult_classification.csv\"\n",
    "test_path = \"data/adult/adult_classification.test\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:62: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/Users/naoki/.pyenv/versions/ML2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = mnist_data.train_data.reshape(-1,784)\n",
    "X_test = mnist_data.test_data.reshape(-1,784)\n",
    "y_train = mnist_data.train_labels\n",
    "y_test = mnist_data.test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "w_dim = X_train.shape[1]\n",
    "class_num = int(max(y_train) + 1)\n",
    "unit_num = 3\n",
    "model = models.LinearClassification(w_num=w_dim,c_num=class_num)\n",
    "model.parameter_init()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "hoge = SGDByTorch.SGDTorchCheck(lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).float()\n",
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0\n",
      "OrderedDict([('fc1.weight', tensor([[-0.1504, -0.0060, -4.4531,  ...,  2.3889,  1.6819,  0.3525],\n",
      "        [-3.3188, -0.4711,  3.5692,  ...,  4.6080,  2.0190,  1.4397],\n",
      "        [ 4.6700, -2.5355, -3.6030,  ..., -3.2431,  3.7220, -1.3104],\n",
      "        ...,\n",
      "        [-0.8333,  4.5004, -3.3021,  ..., -2.9220, -4.4829,  2.2170],\n",
      "        [-0.4725,  2.1637, -0.6565,  ..., -2.2385,  0.7619, -0.3093],\n",
      "        [ 4.2147, -1.2455, -0.6154,  ..., -4.4324,  1.5115, -2.5477]])), ('fc1.bias', tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0010,  0.0000, -0.0010,\n",
      "         0.0000,  0.0000]))])\n",
      "[[ 427    0    1   20 1472 2941   84    2  851  125]\n",
      " [ 470    0 1635  209 1195 2826    0   50    1  356]\n",
      " [1226    1  205  122 1944 2040   24    9  136  251]\n",
      " [ 875    6  219   58 1059 3203   51    5  159  496]\n",
      " [1467   20  196  652 1203  677   86   29  272 1240]\n",
      " [1179    8   86  241  629 2000  325    4  276  673]\n",
      " [ 818   31  375  100  935 3122  250   14   99  174]\n",
      " [3019    4  303 1017  653  216    3  101  117  832]\n",
      " [1263    1  149   40  649 2038   11    5   54 1641]\n",
      " [1060   12  804 1142  964 1043    4   17  103  800]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.07      0.05      5923\n",
      "           1       0.00      0.00      0.00      6742\n",
      "           2       0.05      0.03      0.04      5958\n",
      "           3       0.02      0.01      0.01      6131\n",
      "           4       0.11      0.21      0.15      5842\n",
      "           5       0.10      0.37      0.16      5421\n",
      "           6       0.30      0.04      0.07      5918\n",
      "           7       0.43      0.02      0.03      6265\n",
      "           8       0.03      0.01      0.01      5851\n",
      "           9       0.12      0.13      0.13      5949\n",
      "\n",
      "    accuracy                           0.08     60000\n",
      "   macro avg       0.12      0.09      0.06     60000\n",
      "weighted avg       0.12      0.08      0.06     60000\n",
      "\n",
      "正解率 : 0.08496666666666666\n",
      "test loss : 11158.78515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 1000\n",
      "OrderedDict([('fc1.weight', tensor([[-0.1504, -0.0060, -4.4531,  ...,  2.3889,  1.6819,  0.3525],\n",
      "        [-3.3188, -0.4711,  3.5692,  ...,  4.6080,  2.0190,  1.4397],\n",
      "        [ 4.6700, -2.5355, -3.6030,  ..., -3.2431,  3.7220, -1.3104],\n",
      "        ...,\n",
      "        [-0.8333,  4.5004, -3.3021,  ..., -2.9220, -4.4829,  2.2170],\n",
      "        [-0.4725,  2.1637, -0.6565,  ..., -2.2385,  0.7619, -0.3093],\n",
      "        [ 4.2147, -1.2455, -0.6154,  ..., -4.4324,  1.5115, -2.5477]])), ('fc1.bias', tensor([-8.0000e-03,  1.1000e-02, -3.0000e-03, -5.0000e-03, -4.8894e-09,\n",
      "         4.0000e-03,  2.0000e-03,  9.0052e-03, -9.0052e-03, -1.0000e-03]))])\n",
      "[[5298    3   47   50    7  108   36  249  108   17]\n",
      " [   1 5941   49    9    2   27    3  416  292    2]\n",
      " [ 108  224 4435  217   28   18  244  408  251   25]\n",
      " [  88   96  361 3967    8  682   15  519  370   25]\n",
      " [  42  160  155   49 3364   93  155  571   86 1167]\n",
      " [ 292   81  106  368  100 3050  177  268  855  124]\n",
      " [ 124  115  141   17  150  148 5006   97  109   11]\n",
      " [  51   57   71   60   37    9    5 5842   29  104]\n",
      " [  73  300  203  204   43  279   53  554 4002  140]\n",
      " [  28   89  141  141  152  159   17 2566  154 2502]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      5923\n",
      "           1       0.84      0.88      0.86      6742\n",
      "           2       0.78      0.74      0.76      5958\n",
      "           3       0.78      0.65      0.71      6131\n",
      "           4       0.86      0.58      0.69      5842\n",
      "           5       0.67      0.56      0.61      5421\n",
      "           6       0.88      0.85      0.86      5918\n",
      "           7       0.51      0.93      0.66      6265\n",
      "           8       0.64      0.68      0.66      5851\n",
      "           9       0.61      0.42      0.50      5949\n",
      "\n",
      "    accuracy                           0.72     60000\n",
      "   macro avg       0.74      0.72      0.72     60000\n",
      "weighted avg       0.74      0.72      0.72     60000\n",
      "\n",
      "正解率 : 0.72345\n",
      "test loss : 1280.0841064453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 2000\n",
      "OrderedDict([('fc1.weight', tensor([[-0.1504, -0.0060, -4.4531,  ...,  2.3889,  1.6819,  0.3525],\n",
      "        [-3.3188, -0.4711,  3.5692,  ...,  4.6080,  2.0190,  1.4397],\n",
      "        [ 4.6700, -2.5355, -3.6030,  ..., -3.2431,  3.7220, -1.3104],\n",
      "        ...,\n",
      "        [-0.8333,  4.5004, -3.3021,  ..., -2.9220, -4.4829,  2.2170],\n",
      "        [-0.4725,  2.1637, -0.6565,  ..., -2.2385,  0.7619, -0.3093],\n",
      "        [ 4.2147, -1.2455, -0.6154,  ..., -4.4324,  1.5115, -2.5477]])), ('fc1.bias', tensor([-9.1754e-03,  1.1000e-02, -1.8246e-03, -3.0000e-03, -4.8894e-09,\n",
      "         8.0000e-03,  3.0000e-03,  6.0052e-03, -1.4005e-02, -2.3283e-10]))])\n",
      "[[5023    0   45  240    1  383  193    4   25    9]\n",
      " [   1 5752   92  136    2  138  195   12  411    3]\n",
      " [  43   17 5096  227   20   41  314   22  151   27]\n",
      " [   6   12  345 5085    3  477   52   29  111   11]\n",
      " [  38   40  201  194 3340  441  593    7  278  710]\n",
      " [  73   27   73  398   43 4196  365   10  189   47]\n",
      " [  26    8  112   23   17   87 5615    3   24    3]\n",
      " [  57   53  458  491   22  126   16 4634  164  244]\n",
      " [  15  107  321  499    7  735  269    9 3838   51]\n",
      " [  65   58  266  530   69  884   72  322  447 3236]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89      5923\n",
      "           1       0.95      0.85      0.90      6742\n",
      "           2       0.73      0.86      0.79      5958\n",
      "           3       0.65      0.83      0.73      6131\n",
      "           4       0.95      0.57      0.71      5842\n",
      "           5       0.56      0.77      0.65      5421\n",
      "           6       0.73      0.95      0.83      5918\n",
      "           7       0.92      0.74      0.82      6265\n",
      "           8       0.68      0.66      0.67      5851\n",
      "           9       0.75      0.54      0.63      5949\n",
      "\n",
      "    accuracy                           0.76     60000\n",
      "   macro avg       0.78      0.76      0.76     60000\n",
      "weighted avg       0.79      0.76      0.76     60000\n",
      "\n",
      "正解率 : 0.7635833333333333\n",
      "test loss : 1129.9569091796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 3000\n",
      "OrderedDict([('fc1.weight', tensor([[-0.1504, -0.0060, -4.4531,  ...,  2.3889,  1.6819,  0.3525],\n",
      "        [-3.3188, -0.4711,  3.5692,  ...,  4.6080,  2.0190,  1.4397],\n",
      "        [ 4.6700, -2.5355, -3.6030,  ..., -3.2431,  3.7220, -1.3104],\n",
      "        ...,\n",
      "        [-0.8333,  4.5004, -3.3021,  ..., -2.9220, -4.4829,  2.2170],\n",
      "        [-0.4725,  2.1637, -0.6565,  ..., -2.2385,  0.7619, -0.3093],\n",
      "        [ 4.2147, -1.2455, -0.6154,  ..., -4.4324,  1.5115, -2.5477]])), ('fc1.bias', tensor([-0.0092,  0.0120, -0.0028, -0.0060, -0.0010,  0.0120,  0.0030,  0.0080,\n",
      "        -0.0180,  0.0020]))])\n",
      "[[5540    0   12   88    2  102   58    1   47   73]\n",
      " [   0 6009   39  112    2   66   38  213  234   29]\n",
      " [ 104   39 4484  301   78   40  379  134  242  157]\n",
      " [  58   12  133 5241    3  274   44  124  110  132]\n",
      " [  57   28    9   46 4052   51  186   38  132 1243]\n",
      " [ 192   30    9  388   36 3856  213   39  445  213]\n",
      " [ 103   19   29   16   28   75 5506    7  101   34]\n",
      " [  63   18   74  175   26   22   11 5179   28  669]\n",
      " [  36   97   57  357   11  527  145  114 3944  563]\n",
      " [  41    8    5  146   82   78   25  297   64 5203]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      5923\n",
      "           1       0.96      0.89      0.92      6742\n",
      "           2       0.92      0.75      0.83      5958\n",
      "           3       0.76      0.85      0.81      6131\n",
      "           4       0.94      0.69      0.80      5842\n",
      "           5       0.76      0.71      0.73      5421\n",
      "           6       0.83      0.93      0.88      5918\n",
      "           7       0.84      0.83      0.83      6265\n",
      "           8       0.74      0.67      0.70      5851\n",
      "           9       0.63      0.87      0.73      5949\n",
      "\n",
      "    accuracy                           0.82     60000\n",
      "   macro avg       0.83      0.81      0.82     60000\n",
      "weighted avg       0.83      0.82      0.82     60000\n",
      "\n",
      "正解率 : 0.8169\n",
      "test loss : 856.50244140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 4000\n",
      "OrderedDict([('fc1.weight', tensor([[-0.1504, -0.0060, -4.4531,  ...,  2.3889,  1.6819,  0.3525],\n",
      "        [-3.3188, -0.4711,  3.5692,  ...,  4.6080,  2.0190,  1.4397],\n",
      "        [ 4.6700, -2.5355, -3.6030,  ..., -3.2431,  3.7220, -1.3104],\n",
      "        ...,\n",
      "        [-0.8333,  4.5004, -3.3021,  ..., -2.9220, -4.4829,  2.2170],\n",
      "        [-0.4725,  2.1637, -0.6565,  ..., -2.2385,  0.7619, -0.3093],\n",
      "        [ 4.2147, -1.2455, -0.6154,  ..., -4.4324,  1.5115, -2.5477]])), ('fc1.bias', tensor([-0.0102,  0.0140, -0.0018, -0.0060, -0.0010,  0.0150,  0.0020,  0.0090,\n",
      "        -0.0220,  0.0010]))])\n",
      "[[5530    0   74   32   10  104   46    3   56   68]\n",
      " [   2 6444   72    5    2   51    2    8  121   35]\n",
      " [  29   80 5093   76   78   44  123   99  216  120]\n",
      " [  37   57  386 4519    4  517   31   51  287  242]\n",
      " [  18   42   31    1 4730   47   84   16  112  761]\n",
      " [ 165   33   83  133   53 4256   83    6  389  220]\n",
      " [  54   37  158    2  115  138 5240    6  158   10]\n",
      " [  56   74  141   50   55   32    7 4204   28 1618]\n",
      " [  46  201  135  144   22  605   39   13 4263  383]\n",
      " [  51   22   11   47  146   54   13  101   97 5407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      5923\n",
      "           1       0.92      0.96      0.94      6742\n",
      "           2       0.82      0.85      0.84      5958\n",
      "           3       0.90      0.74      0.81      6131\n",
      "           4       0.91      0.81      0.86      5842\n",
      "           5       0.73      0.79      0.76      5421\n",
      "           6       0.92      0.89      0.90      5918\n",
      "           7       0.93      0.67      0.78      6265\n",
      "           8       0.74      0.73      0.74      5851\n",
      "           9       0.61      0.91      0.73      5949\n",
      "\n",
      "    accuracy                           0.83     60000\n",
      "   macro avg       0.84      0.83      0.83     60000\n",
      "weighted avg       0.84      0.83      0.83     60000\n",
      "\n",
      "正解率 : 0.8281\n",
      "test loss : 829.564208984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 5000\n",
      "OrderedDict([('fc1.weight', tensor([[-0.1504, -0.0060, -4.4531,  ...,  2.3889,  1.6819,  0.3525],\n",
      "        [-3.3188, -0.4711,  3.5692,  ...,  4.6080,  2.0190,  1.4397],\n",
      "        [ 4.6700, -2.5355, -3.6030,  ..., -3.2431,  3.7220, -1.3104],\n",
      "        ...,\n",
      "        [-0.8333,  4.5004, -3.3021,  ..., -2.9220, -4.4829,  2.2170],\n",
      "        [-0.4725,  2.1637, -0.6565,  ..., -2.2385,  0.7619, -0.3093],\n",
      "        [ 4.2147, -1.2455, -0.6154,  ..., -4.4324,  1.5115, -2.5477]])), ('fc1.bias', tensor([-1.2176e-02,  1.5000e-02,  1.7543e-04, -4.0104e-03,  1.0381e-05,\n",
      "         2.0000e-02,  2.0002e-03,  1.0005e-02, -2.9005e-02, -2.0000e-03]))])\n",
      "[[5129    0  204  204   11  226   75   27   35   12]\n",
      " [   1 6487   67   99    3   31    4   28   20    2]\n",
      " [  14  104 4887  570   69   30   84   84  103   13]\n",
      " [   4   38  242 5601    5   91   17   54   44   35]\n",
      " [   9   99  113   49 4968   69  115   46   97  277]\n",
      " [ 103   50  256  738   59 3754  156   49  203   53]\n",
      " [  34   44  364   14   41   71 5325    2   22    1]\n",
      " [  21  113  145  229   45   14    8 5553   24  113]\n",
      " [  23  288  473  836   17  437   92   46 3597   42]\n",
      " [  21  102   41  293  279  100   22  498  153 4440]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      5923\n",
      "           1       0.89      0.96      0.92      6742\n",
      "           2       0.72      0.82      0.77      5958\n",
      "           3       0.65      0.91      0.76      6131\n",
      "           4       0.90      0.85      0.88      5842\n",
      "           5       0.78      0.69      0.73      5421\n",
      "           6       0.90      0.90      0.90      5918\n",
      "           7       0.87      0.89      0.88      6265\n",
      "           8       0.84      0.61      0.71      5851\n",
      "           9       0.89      0.75      0.81      5949\n",
      "\n",
      "    accuracy                           0.83     60000\n",
      "   macro avg       0.84      0.83      0.83     60000\n",
      "weighted avg       0.84      0.83      0.83     60000\n",
      "\n",
      "正解率 : 0.8290166666666666\n",
      "test loss : 882.215087890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 6000\n",
      "OrderedDict([('fc1.weight', tensor([[-0.1504, -0.0060, -4.4531,  ...,  2.3889,  1.6819,  0.3525],\n",
      "        [-3.3188, -0.4711,  3.5692,  ...,  4.6080,  2.0190,  1.4397],\n",
      "        [ 4.6700, -2.5355, -3.6030,  ..., -3.2431,  3.7220, -1.3104],\n",
      "        ...,\n",
      "        [-0.8333,  4.5004, -3.3021,  ..., -2.9220, -4.4829,  2.2170],\n",
      "        [-0.4725,  2.1637, -0.6565,  ..., -2.2385,  0.7619, -0.3093],\n",
      "        [ 4.2147, -1.2455, -0.6154,  ..., -4.4324,  1.5115, -2.5477]])), ('fc1.bias', tensor([-1.2131e-02,  1.3000e-02, -2.8246e-03, -5.0104e-03,  1.0385e-05,\n",
      "         2.7580e-02,  2.0002e-03,  1.2005e-02, -3.4005e-02, -6.2452e-04]))])\n",
      "[[5139    4   12   53    6  463  137   26   66   17]\n",
      " [   2 6487   12   69    5   65   14   12   76    0]\n",
      " [  37  179 3686  683   84   80  459  166  477  107]\n",
      " [  24   54   25 5345    5  346   50   89  132   61]\n",
      " [   4   77    2   21 4900  208  139   43   62  386]\n",
      " [  89   57    7  247   18 4544  164   29  219   47]\n",
      " [  25   35    8    8   49  148 5603    3   32    7]\n",
      " [  13  125   27  107   58   36    7 5720   34  138]\n",
      " [  12  323   13  342   26  592   89   48 4305  101]\n",
      " [  13  128    2   95  453  320   13  502   73 4350]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      5923\n",
      "           1       0.87      0.96      0.91      6742\n",
      "           2       0.97      0.62      0.76      5958\n",
      "           3       0.77      0.87      0.82      6131\n",
      "           4       0.87      0.84      0.86      5842\n",
      "           5       0.67      0.84      0.74      5421\n",
      "           6       0.84      0.95      0.89      5918\n",
      "           7       0.86      0.91      0.89      6265\n",
      "           8       0.79      0.74      0.76      5851\n",
      "           9       0.83      0.73      0.78      5949\n",
      "\n",
      "    accuracy                           0.83     60000\n",
      "   macro avg       0.84      0.83      0.83     60000\n",
      "weighted avg       0.84      0.83      0.83     60000\n",
      "\n",
      "正解率 : 0.83465\n",
      "test loss : 824.2634887695312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 7000\n",
      "OrderedDict([('fc1.weight', tensor([[-0.1504, -0.0060, -4.4531,  ...,  2.3889,  1.6819,  0.3525],\n",
      "        [-3.3188, -0.4711,  3.5692,  ...,  4.6080,  2.0190,  1.4397],\n",
      "        [ 4.6700, -2.5355, -3.6030,  ..., -3.2431,  3.7220, -1.3104],\n",
      "        ...,\n",
      "        [-0.8333,  4.5004, -3.3021,  ..., -2.9220, -4.4829,  2.2170],\n",
      "        [-0.4725,  2.1637, -0.6565,  ..., -2.2385,  0.7619, -0.3093],\n",
      "        [ 4.2147, -1.2455, -0.6154,  ..., -4.4324,  1.5115, -2.5477]])), ('fc1.bias', tensor([-1.4131e-02,  1.1000e-02, -8.2457e-04, -7.0104e-03,  1.0104e-03,\n",
      "         3.1580e-02,  1.7858e-07,  1.3005e-02, -3.5005e-02,  3.7548e-04]))])\n",
      "[[5730    0   38    2   10   42   24    9   65    3]\n",
      " [   2 5746  113   20    6   95   12   22  726    0]\n",
      " [  79    8 4976   82   78   45  167   85  421   17]\n",
      " [  68   17  314 3736    5  953   24   82  865   67]\n",
      " [  69   11   34    1 5129   45  119   34  244  156]\n",
      " [ 231    8   97   56   37 4443   91   27  400   31]\n",
      " [ 159    4  145    1   67   64 5350    0  126    2]\n",
      " [  54   44  199   16   88   20    7 5599  117  121]\n",
      " [  71   52   89   29   39  332   38   22 5148   31]\n",
      " [ 112   27   21   17  390  180   11  428  417 4346]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      5923\n",
      "           1       0.97      0.85      0.91      6742\n",
      "           2       0.83      0.84      0.83      5958\n",
      "           3       0.94      0.61      0.74      6131\n",
      "           4       0.88      0.88      0.88      5842\n",
      "           5       0.71      0.82      0.76      5421\n",
      "           6       0.92      0.90      0.91      5918\n",
      "           7       0.89      0.89      0.89      6265\n",
      "           8       0.60      0.88      0.72      5851\n",
      "           9       0.91      0.73      0.81      5949\n",
      "\n",
      "    accuracy                           0.84     60000\n",
      "   macro avg       0.85      0.84      0.84     60000\n",
      "weighted avg       0.86      0.84      0.84     60000\n",
      "\n",
      "正解率 : 0.8367166666666667\n",
      "test loss : 810.9402465820312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/ML2/GD/ML2_lib/SGDByTorch.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_pred = self.model(torch.tensor(X_test).float())\n"
     ]
    }
   ],
   "source": [
    "sgd_model, loss_stack, test_loss_stack,accuracy_stack = hoge.learn(x=X_train, y=y_train, model=model,class_num=class_num,X_test=X_test,Y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10.0, 8.0))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.set_title(\"train data NLL Loss\")\n",
    "\n",
    "ax1.plot(loss_stack)\n",
    "ax1.set_xlabel(\"step\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10.0, 8.0))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_title(\"test data NLL Loss\")\n",
    "\n",
    "ax1.plot(test_loss_stack)\n",
    "ax1.set_xlabel(\"step\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10.0, 8.0))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_title(\"test data accuracy\")\n",
    "\n",
    "ax1.plot(accuracy_stack)\n",
    "ax1.set_xlabel(\"step\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "accuracy_stack\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}